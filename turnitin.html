
    
<!DOCTYPE html>
<html lang="en-us">

<meta http-equiv="X-UA-Compatible" content="IE=7" />

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="author" content="Turnitin, LLC" />
    <meta name="keywords" content="" /> 
    <meta name="description" content="" />
<title>Turnitin - Originality Report - Thesis-3035637917.pdf </title>

<base href="http://www.turnitin.com">
<style type="text/css">
body {
    color: #333;
    background: #C0C7CC;
    padding: 0;
    border: 0;
    font: 13px Verdana, arial, sans-serif;
    margin: 0;
}

form {
    padding: 0;
    margin: 0;
}

body#display {
}

body#bodysource {
    width: 520px;
    background: #F0F4FA;
}

p {
    padding: 10px 18px;
    margin: 0;
}

img {
    border: 0;
    padding: 0;
}

div {
    padding: 0;
    border: 0;
}

iframe {
    border: 0;
    margin: 0;
    padding: 0;
}

strong {
    font-weight: bold;
}

ul {
    padding: 0;
    margin: 0;
    list-style-type: none;
    font-size: 13px;
}

ul li {
    padding: 0;
    margin: 0;
    line-height: 16px;
}

#index span#exclude {
    margin: 0 50px 0 23px;
}

#index a {
    font-size: 11px;
    padding: 0 8px;
}

#index select {
    font-size: 12px;
    border: 1px solid #888;
}

#index input.small {
    margin: 0 0 0 5px;
    width: 30px;
    color: #D10A0A;
    font-weight: bold;
    font-size: 13px;
    border: 1px solid #888;
    vertical-align: baseline;
}

div.links {
    width: 85%;
    margin: 0 auto;
    border-left: 1px solid #888;
    border-right: 1px solid #888;
    padding-top: 8px;
    background: #E8EEF7;
    text-align: left;
}

.links div {
    padding: 5px 13px 10px 20px;
    border-bottom: 1px dotted #888;
}

.links div p {
    padding: 2px 0 0 40px;
}

div#body {
    line-height: 17px;
    width: 85%;
    margin: auto;
    padding: 20px 0;
    background: #fff;
    border-bottom: 1px solid #888;
    border-right: 1px solid #888;
    border-left: 1px solid #888;
    text-align: left;
}

#body p {
    color: #000;
    padding-top: 10 0;
    margin: 0 40px;
}

#actions {
    display: none;
}

a.exclude {
    float: right;
    margin: 0;
    padding: 0;
    position: relative;
    bottom: 20px;
}

/*= SMALL MATCHES POPUP
=== === === === === === === === === === === === === === === === === === === === === === === === === === === === === === */
div#small_matches_prefs {
    visibility: hidden;
    position: absolute;
    top: 0;
    left: 400px;
    background-color: #FFF;
    border: 1px solid #999;
    text-align: right;
}

div#small_matches_prefs p {
    padding: 7px;
}

div#small_matches_prefs li {
    padding: 10px 40px 10px 0;
    border-bottom: 1px solid #999;
    cursor: pointer;
    text-align: left;
}

div#small_matches_prefs li.selected {
    background-color: #87A3C0;
}

div#small_matches_prefs li input {
    text-align: center;
    border: 1px solid #999;
}

div#small_matches_prefs li.disabled input {
    color: #878787;
    background-color: #E6E5E6;
}

div#small_matches_prefs ul label {
    width: 100px;
    text-align: right;
    display: inline-block;
    margin-left: 10px;
    margin-right: 10px;
}
/*= GENERAL
=== === === === === === === === === === === === === === === === === === === === === === === === === === === === === === */

body #top_bar {
    display: none !important;
}

body #index #exclude,
#download_button,
#print_button,
#index .right {
    display: inline-block;
}

body #index {
    width: 85%;
    margin-left: auto;
    margin-right: auto;
    border: 1px solid #999;
    background: #ececec url(new_dynamic/images/22bd7a01a025b8de122259e42762f0a7cb_ug_toolbar_bg.gif) repeat-x center left;
}

#toolbar_wrapper {
    padding-left: 45px;
}

body #top {
    width: 85%;
    background-color: #FFF;
    margin-left: auto;
    margin-right: auto;
    border: 1px solid #999;
    border-bottom: none;
    height: 210px;
}

body #content {
    padding: 10px 60px;
}

body div#prefs {
    display: none;
}

body #top h1 {
    font-size: 20px;
    font-weight: normal;
}

body #top h1 strong {
    font-weight: normal;
}

body #top h1 em {
    font-style: normal;
}


/*body #top h2 {*/
/*    font-size: 20px;*/
/*    font-weight: normal;*/
/*}*/

/*body #top h2 strong {*/
/*    font-weight: normal;*/
/*}*/

/*body #top h2 em {*/
/*    font-style: normal;*/
/*}*/


body #top h2 {
    font-size: 16px;
    font-weight: normal;
}

body #top h2 strong {
    font-weight: normal;
}

body #top h2 em {
    font-style: normal;
}


body #top_body li { /*Paper info li*/
    padding: 0;
    margin: 0px 0px 2px 0px;
    font-size: 10px;
}

#top_body #print_wrapper {
    float: left;
    width: 50%;
}

#top_body .similarity_print_wrapper {
    width: 45%;
    min-width: 283px;
}

#top_body .similarity_box { /*Similarity Box w/ Similarity by Source */
    float: right;
    border: solid 1px #666;
    margin-top: 60px;
    min-width: 350px;
}

#top_body .similarity_box .overall_similarity {
    float: left;
    border-right: solid 1px #666;
}

#top_body .similarity_box .overall_similarity .color_box {
    font-size: 14px;
    min-width: 140px;
}

#top_body .color_box.green {
    background-color: green;
}

#top_body .color_box.blue {
    background-color: blue;
}

#top_body .color_box.yellow {
    background-color: yellow;
}

#top_body .color_box.orange {
    background-color: orange;
}

#top_body .color_box.red {
    background-color: red;
}

#top_body .similarity_box .overall_similarity .similarity_title {
    font-size: 13px;
    font-weight: normal;
    padding: 5px 5px 5px;
    text-align: center;
}

#top_body .similarity_box .overall_similarity .similarity_percent {
    font-size: 25px;
    font-family: georgia, times, serif;
    padding: 5px 0px 15px;
    text-align: center;
}

#top_body .similarity_box .overall_similarity a {
    display: none;
}

#top_body .similarity_box .similarity_by_source {
    float: right;
    font-size: 10px;
}

#top_body .similarity_box .similarity_by_source .similarity_title {
    padding: 6px 0px 0px 10px;
    font-weight: bold;
    text-align: left;
}

#top_body .similarity_box .similarity_by_source dl {
    padding-left: 10px;
    margin: 14px 7px 0px 0px;
}

#top_body .similarity_box .similarity_by_source dt {
    float: left;
    width: 160px;
}

#top_body .similarity_box .similarity_by_source dd {
    float: left;
    margin: 0px;
}


#index span#exclude {
    margin: 0 50px 0 23px;
}

#index a {
    font-size: 11px;
    padding: 0 8px;
}

#index select {
    font-size: 12px;
    border: 1px solid #888;
}

#index input.small {
    margin: 0 0 0 5px;
    width: 30px;
    color: #D10A0A;
    font-weight: bold;
    font-size: 13px;
    border: 1px solid #888;
    vertical-align: baseline;
}

div.links {
    width: 85%;
    margin: 0 auto;
    border-left: 1px solid #888;
    border-right: 1px solid #888;
    padding-top: 8px;
    background: #E8EEF7;
    text-align: left;
}

.links div {
    padding: 5px 13px 10px 20px;
    border-bottom: 1px dotted #888;
}

.links div p {
    padding: 2px 0 0 40px;
}

div#body {
    line-height: 17px;
    width: 85%;
    margin: auto;
    padding: 20px 0;
    background: #fff;
    border-bottom: 1px solid #888;
    border-right: 1px solid #888;
    border-left: 1px solid #888;
    text-align: left;
}

#body p {
    color: #000;
    padding-top: 10 0;
    margin: 0 40px;
}

#actions {
    display: none;
}

button.exclude {
    float: right;
    margin: 0;
    padding: 0;
    border: none;
}

#small_matches_prefs {
    display: none;
}

/*
Copyright (c) 2009, Yahoo! Inc. All rights reserved.
Code licensed under the BSD License:
http://developer.yahoo.net/yui/license.txt
version: 2.7.0
*/
.yui-button{display:-moz-inline-box;display:inline-block;vertical-align:text-bottom;}.yui-button .first-child{display:block;*display:inline-block;}.yui-button button,.yui-button a{display:block;*display:inline-block;border:none;margin:0;}.yui-button button{background-color:transparent;*overflow:visible;cursor:pointer;}.yui-button a{text-decoration:none;}.yui-skin-sam .yui-button{border-width:1px 0;border-style:solid;border-color:#808080;background:url(../images/yui270/build/assets/skins/sam/96b257a32a932f7739d7dab52b38ee8fcb_sprite.png) repeat-x 0 0;margin:auto .25em;}.yui-skin-sam .yui-button .first-child{border-width:0 1px;border-style:solid;border-color:#808080;margin:0 -1px;_margin:0;}.yui-skin-sam .yui-button button,.yui-skin-sam .yui-button a{padding:0 10px;font-size:93%;line-height:2;*line-height:1.7;min-height:2em;*min-height:auto;color:#000;}.yui-skin-sam .yui-button a{*line-height:1.875;*padding-bottom:1px;}.yui-skin-sam .yui-split-button button,.yui-skin-sam .yui-menu-button button{padding-right:20px;background-position:right center;background-repeat:no-repeat;}.yui-skin-sam .yui-menu-button button{background-image:url(yui270/build/button/assets/skins/sam/6305efb37fa05af65c79b58b9d4c1b03cb_menu-button-arrow.png);}.yui-skin-sam .yui-split-button button{background-image:url(yui270/build/button/assets/skins/sam/ced974d5c685e5dfa0a37b824a6b5d48cb_split-button-arrow.png);}.yui-skin-sam .yui-button-focus{border-color:#7D98B8;background-position:0 -1300px;}.yui-skin-sam .yui-button-focus .first-child{border-color:#7D98B8;}.yui-skin-sam .yui-button-focus button,.yui-skin-sam .yui-button-focus a{color:#000;}.yui-skin-sam .yui-split-button-focus button{background-image:url(yui270/build/button/assets/skins/sam/36e66540d2feba76b8991e18b76fe93bcb_split-button-arrow-focus.png);}.yui-skin-sam .yui-button-hover{border-color:#7D98B8;background-position:0 -1300px;}.yui-skin-sam .yui-button-hover .first-child{border-color:#7D98B8;}.yui-skin-sam .yui-button-hover button,.yui-skin-sam .yui-button-hover a{color:#000;}.yui-skin-sam .yui-split-button-hover button{background-image:url(yui270/build/button/assets/skins/sam/36e66540d2feba76b8991e18b76fe93bcb_split-button-arrow-hover.png);}.yui-skin-sam .yui-button-active{border-color:#7D98B8;background-position:0 -1700px;}.yui-skin-sam .yui-button-active .first-child{border-color:#7D98B8;}.yui-skin-sam .yui-button-active button,.yui-skin-sam .yui-button-active a{color:#000;}.yui-skin-sam .yui-split-button-activeoption{border-color:#808080;background-position:0 0;}.yui-skin-sam .yui-split-button-activeoption .first-child{border-color:#808080;}.yui-skin-sam .yui-split-button-activeoption button{background-image:url(yui270/build/button/assets/skins/sam/890272b241c1d8a0db3ce5680b71fab0cb_split-button-arrow-active.png);}.yui-skin-sam .yui-radio-button-checked,.yui-skin-sam .yui-checkbox-button-checked{border-color:#304369;background-position:0 -1400px;}.yui-skin-sam .yui-radio-button-checked .first-child,.yui-skin-sam .yui-checkbox-button-checked .first-child{border-color:#304369;}.yui-skin-sam .yui-radio-button-checked button,.yui-skin-sam .yui-checkbox-button-checked button{color:#fff;}.yui-skin-sam .yui-button-disabled{border-color:#ccc;background-position:0 -1500px;}.yui-skin-sam .yui-button-disabled .first-child{border-color:#ccc;}.yui-skin-sam .yui-button-disabled button,.yui-skin-sam .yui-button-disabled a{color:#A6A6A6;cursor:default;}.yui-skin-sam .yui-menu-button-disabled button{background-image:url(yui270/build/button/assets/skins/sam/4df7235ca027f2546b2a216e59f81fb0cb_menu-button-arrow-disabled.png);}.yui-skin-sam .yui-split-button-disabled button{background-image:url(yui270/build/button/assets/skins/sam/db73dce6da2f5c5f02399c93488ce69ecb_split-button-arrow-disabled.png);}

</style>



</head>

<body onload="">



<link rel="stylesheet" type="text/css" href="/r/build/css/tii/88ee4ccd3555f2b759921fb5d58d83e5cb_container.css" media="all" />




<script type="text/javascript" src="/r/build/js/tii/8b608684a5f4aec1b540987c93498c01cb_tii_anonymous_marking.js"></script>




<script type="text/javascript">

function initAnonymousMarking () {
    // initialize panel.  
    var config = {
            zindex: 4,
            underlay: 'none',
            modal: true,
            visible: false,
            draggable: false,
            close: false,
            fixedcenter: true
    };
    if ($('disable_anonymous_marking')) {
        disableAnonymousMarkingPanel = new IP.widget.Panel($('disable_anonymous_marking'), config);
        if($D.hasClass('disable_anonymous_marking', 'app')) {
            disableAnonymousMarkingPanel.center = function () {
                var nViewportOffset = 20,
                    elementWidth = this.element.offsetWidth,
                    elementHeight = this.element.offsetHeight,
                    viewPortWidth = $D.getViewportWidth(),
                    viewPortHeight = $D.getViewportHeight(),
                    x,
                    y;

                if (elementWidth < viewPortWidth) {
                    x = (viewPortWidth / 2) - (elementWidth / 2) + $D.getDocumentScrollLeft();
                } else {
                    x = nViewportOffset + $D.getDocumentScrollLeft();
                }

				if (browser == 'Internet Explorer') {
					x = 0;
				}
                y = 2 + $D.getDocumentScrollTop();

                this.cfg.setProperty("xy", [parseInt(x, 10), parseInt(y, 10)]);
                this.cfg.refireEvent("iframe");
            };
        }
        disableAnonymousMarkingPanel.render(document.body);
        disableAnonymousMarkingPanel.hideEvent.subscribe(function () { $('anonymous_error').innerHTML = ''; }, false);
        disableAnonymousMarkingPanel.hide();
        Element.show($('disable_anonymous_marking'));
    }
}

function disableAM (data) {
    $('anonymous_title').innerHTML = data.title;
    document.disable_anonymous_marking_form.objectid.value = data.oid;
    disableAnonymousMarkingPanel.show();
}

function checkDisableAM () {
    var form = document.disable_anonymous_marking_form;
    if (form.reason.value.length <= 5) {
        $('anonymous_error').innerHTML = "Please provide a reason for turning anonymous marking off. Your reason must be more than 10 characters in length.";
    }
    else {
        form.submit();
    }
    return;
}

YAHOO.util.Event.onDOMReady(initAnonymousMarking);

</script>

<div id="disable_anonymous_marking" class="app" style="display: none;">
<div class="anonymous_frames">
<form method="post" name="disable_anonymous_marking_form">
    <input type="hidden" name="objectid" value=""/>
    <input type="hidden" name="disable_anonymous_marking" value="1"/> 
    <div class="anonymous_header">
    	<h1>turn off anonymous marking</h1>
		<p>Please state reason for turning off Anonymous Marking for: <span id="anonymous_title"></span><br />
			<strong>Warning: Administrator has access to this information. This setting is permanent.</strong>
        
            </p>
        
    </div>
    <div class="anonymous_body">
        <textarea name="reason" cols="30" rows="3"></textarea>
        <p id="anonymous_error"></p>
    </div>
    <div class="anonymous_footer">
		<div class="anonymous_footer_buttons">
            <span class="submit_form_button"><input type="button" onClick="checkDisableAM();" value="Submit"></span><br>
        	<span class="submit_form_button"><input type="button" value="Cancel" onClick="disableAnonymousMarkingPanel.hide();"></span>
		</div>
    </div>
</form>
</div>
</div>
<div id="actions">
<p>This is a preview of the print version of your report. Please click "print" to continue or "done" to close this window.</p>
<script type="text/javascript" language="javascript">
	var browserName=navigator.appName;
	var browserVer=parseInt(navigator.appVersion);
	if ((navigator.appVersion.indexOf("Mac")!=-1) && (browserName == "Microsoft Internet Explorer")) {
		document.write('<span class="AR10">Type COMMAND-P to print.</span><br><br>');
	} else {
		document.write('<button onclick="window.print();">print</button>&nbsp;&nbsp;');
	}
</script>
<button onclick="window.close();">done</button>
</div>


<!-- ########################### Preferences pop-up ##########################--> 

<div name="top" id="header">

<div id="prefs" role="dialog" style="display:none" aria-labelledby="prefs_link" aria-describedby="prefs_link" aria-owns="prefs_link">
<div class="padding">
<form name="prefs_form" method="post" accept-charset="utf-8">
<script type="text/javascript" language="javascript">
function savePrefs(){
	if (document.prefs_form.changed.value == 1){
		document.prefs_form.submit();
	}else{
        hidePrefsPane();
	}
}

function handlePrefsPaneKeyUp (evt) {
    // first check for IME compositions and ignore
    if (evt.isComposing || evt.keyCode === 229) {
        return;
    }
    if (evt.key === "Escape") {
        evt.preventDefault();
        evt.stopPropagation();
        hidePrefsPane();
    }
}

function showPrefsPane(){
    const prefsDiv = document.getElementById('prefs');
    prefsDiv.style.display='block';
    prefsDiv.addEventListener('keyup', handlePrefsPaneKeyUp);
    document.getElementById('use_colors').focus();
}

function hidePrefsPane(){
    const prefsDiv = document.getElementById('prefs');
    prefsDiv.style.display='none';
    prefsDiv.removeEventListener('keyup', handlePrefsPaneKeyUp);
    document.getElementById('prefs_link').focus();
}

var overlay, $D, $;

function handleSmallMatchesPrefKeyUp (evt) {
    // first check for IME compositions and ignore
    if (evt.isComposing || evt.keyCode === 229) {
        return;
    }
    if (evt.key === "Escape") {
        evt.preventDefault();
        evt.stopPropagation();
        hideSmallMatchExclusions();
    }
}

function showSmallMatchExclusions(left) {
    $D = YAHOO.util.Dom;
    $E = YAHOO.util.Event;
    $ = $D.get;

    $D.setStyle('small_matches_prefs', 'top', $D.getDocumentScrollTop() + 187 + 'px');
    $D.setStyle('small_matches_prefs', 'left', left + 'px');

    $D.setStyle('small_matches_prefs', 'display', 'block');
    $D.setStyle('small_matches_prefs', 'visibility', 'visible');

        // focus the field
    $D.hasClass('exclude_by_percent_row', 'selected') ? $('exclude_by_percent_value').focus() : $('exclude_by_words_value').focus();
    $E.on(window, 'scroll', repositionDialog);



/*
A problem occurs: when the focus moves from the wordcount field to the percentage field
the existing percentage is floored. So even if the value is "correct", it gets incorrect,
because the floored percentage is different from the word count. Especially in bigger texts and smaller matches
this becomes an issue. So, the percentage displayed when updated from the word count should be the rounded one.
only when the input itself is given manually, should this override the exclusionPercent value.

This can be done as long as we use the functions below as actual keyboard handlers, so we can filter between numerical
values entered and other keys (such as tab). Moreover, we could do up and down to increase or decrease the value.

Because we will need to keep a state of the unrounded percentage, it is better to have that percentage value
closed over.

*/

    let rawPercentage = 0;
    function updateExcludePercentage(evt) {
        // prevent symbol composing to interfere, 229 is a special code for the composition key
        if (evt.isComposing || evt.keyCode === 229) {
            return;
        }
        if (evt.key === "Escape") {
            evt.preventDefault();
            evt.stopPropagation();
            hideSmallMatchExclusions();
        }
        else if (/[0-9]/.exec(evt.key) || evt.key === 'Backspace' || evt.key === 'Delete') { //only recalculate when the entered keys represent numbers
            // only when entering or changing the value in the input field, it is clear that the user
            // intended to use this specific exclusion method
            selectSmallExclusionMethod('words');
            const wordCount = this.value;

            rawPercentage = wordCount / 29663 * 100;
            $('exclude_by_percent_value').value = Math.floor(rawPercentage); // only display floored value
        }
    }

    function updateExcludeWordCount(evt) {
        // prevent symbol composing to interfere, 229 is a special code for the composition key
        if (evt.isComposing || evt.keyCode === 229) {
            return;
        }
        if (evt.key === "Escape") {
            evt.preventDefault();
            evt.stopPropagation();
            hideSmallMatchExclusions();
        }
        else if (/[0-9]/.exec(evt.key) || evt.key === 'Backspace' || evt.key === 'Delete') { //only recalculate when the entered keys represent numbers
            // only when entering or changing the value in the input field, it is clear that the user
            // intended to use this specific exclusion method
            selectSmallExclusionMethod('percent');

            const percent = this.value;
            var wordCount = Math.floor((percent/100) * 29663);

            $('exclude_by_words_value').value = wordCount;
        }
    }
    // set to global name space so hideSmallMatchesExclusions can also remove the listeners.
    if (!window.updateExcludePercentage) window.updateExcludePercentage = updateExcludePercentage;
    if (!window.updateExcludeWordCount) window.updateExcludeWordCount = updateExcludeWordCount;

    document.getElementById('small_matches_prefs').addEventListener('keyup', handleSmallMatchesPrefKeyUp);
    document.getElementById('exclude_by_words_value').addEventListener('keyup', updateExcludePercentage);
    document.getElementById('exclude_by_percent_value').addEventListener('keyup', updateExcludeWordCount);

}

function repositionDialog() {
    $D.setStyle('small_matches_prefs', 'top', $D.getDocumentScrollTop() + 187 + 'px');
}

function hideSmallMatchExclusions() {
    document.getElementById('small_matches_prefs').removeEventListener('keyup', handleSmallMatchesPrefKeyUp);
    document.getElementById('exclude_by_words_value').removeEventListener('keyup', updateExcludePercentage);
    document.getElementById('exclude_by_percent_value').removeEventListener('keyup', updateExcludeWordCount);

    $D.setStyle('small_matches_prefs', 'display', 'none');
    $E.removeListener(window, 'scroll', repositionDialog);
    document.getElementById('exclude_small_matches_link').focus();
}

function selectSmallExclusionMethod(enableType) {
    if(enableType == 'words') {
        $('exclude_by_words_value').focus();
        
        $D.addClass('exclude_by_words_row', 'selected');
        $D.removeClass('exclude_by_percent_row', 'selected');
        $D.removeClass('exclude_by_words_row', 'disabled');
        $D.addClass('exclude_by_percent_row', 'disabled');
    }
    else {
        $('exclude_by_percent_value').focus();
        
        $D.removeClass('exclude_by_words_row', 'selected');
        $D.addClass('exclude_by_percent_row', 'selected');
        $D.addClass('exclude_by_words_row', 'disabled');
        $D.removeClass('exclude_by_percent_row', 'disabled');
    }
}

function submitSmallMatchesChange() {
    var excludeBy = $D.hasClass('exclude_by_percent_row', 'selected') ? 'percent' : 'words';
    var excludeValue = excludeBy == 'percent' ? $('exclude_by_percent_value').value : $('exclude_by_words_value').value;
    
    changeSmallMatchExclusion(excludeBy, parseInt(excludeValue), 29663);
}


</script>
<input type="hidden" name="changed" value="0">
        <div class="pref_rows">
                <label for="use_colors">color-code matches:</label>
                <select id="use_colors" name="use_colors" onchange="document.prefs_form.changed.value=1">
                    <option value="1">yes
                    <option value="0">no
                </select>
                <div class="clear"></div>
        </div>
        <div class="pref_rows">
                <label for="def_report_mode">default mode:</label>
                <select id="def_report_mode" name="def_report_mode" onchange="document.prefs_form.changed.value=1">
                    <option value="0">show highest matches together
                    <option value="1">show matches one at a time
                    <option value="2">quickview (classic) report
                </select>
                <div class="clear"></div>
        </div>
        <div class="pref_rows">
                <label for="report_scrolling">auto-navigation:</label>
                <select id="report_scrolling" name="report_scrolling" onchange="document.prefs_form.changed.value=1">
                    <option value="0">jump to next match
                    <option value="1">scroll to next match
                </select>
                <div class="clear"></div>
        </div>
        
        <div id="prefs_confirm">
            <button onClick="savePrefs()" >Save</button>  
            <button onClick="hidePrefsPane();">Cancel</button>
        </div>
</form>
</div>
</div>
</div>
<!-- ########################### END Preferences pop-up  ##########################--> 

<!-- ########################### BEGIN small matches pop-up  ##########################--> 
<div id="small_matches_prefs" role="dialog" aria-labelledby="exclude_small_matches_link" aria-describedby="exclude_small_matches_link" aria-owns="exclude_small_matches_link">
    <form onsubmit="submitSmallMatchesChange(); return false;">
        <ul>
            <li id="exclude_by_words_row" class="selected">
                <label for="exclude_by_words_value">Word Count: </label>
                <input type="text" id="exclude_by_words_value" size="3" value="" onkeyup="updateExcludePercentage"> words
            </li>
            <li id="exclude_by_percent_row" class="disabled">
                <label for="exclude_by_percent_value">Percentage: </label>
                <input type="text" id="exclude_by_percent_value" size="3" value="" max-length="3" onkeyup="updateExcludeWordCount"> %
            </li>
        </ul>
        <p><input type='submit' value="submit"> or <button onclick="hideSmallMatchExclusions()">Cancel</button></p>
    </form>
</div>

<!-- ########################### END small matches pop-up  ##########################-->

<!-- ########################### Top of Report  ##########################--> 
<div id="top">
    <div id="content" role="banner">
    
        <!-- ######### Top Bar  ##########################--> 
        <div id="top_bar">
                <ul id="top_bar_list1">
                      <!-- Preferences --><li><button id="prefs_link" onclick="showPrefsPane(); aria-haspopup="dialog">preferences</button></li>
                </ul>
                <ul id="top_bar_list2">
                      
                </ul>
                <div class="clear"></div>
        </div>   
        <!-- ######### END Top Bar  ##########################--> 
        
        
        <!-- ######### Top Body  ##########################--> 
        <div id="top_body">
        
            <div id="print_wrapper">
                <div class="general_info" role="region" aria-label="Paper Information">
                    <!-- Logo --> 
                    <h1>
                        <span class=""></span>
                        <strong>Turnitin</strong>
                        <em>Originality Report</em>
                     </h1>
                 
                     <!-- Paper Info -->               
                     <ul>
                         <li>Processed on: 28-Oct-2025 15:04 HKT</li>
                         <li>ID: 2787500303 </li>
                         <li>Word Count: 29663</li>
                         <li>Submitted: 5</li>
                     </ul>
                </div>

                 <!-- Paper Title --> 
                <h2>
                    <strong>Thesis-3035637917.pdf</strong> 
                    
                    <em>By Songlin Huang</em>
                    
                </h2>
            </div>
            
            <div id="similarity_print_wrapper">
                <div class="similarity_box" role="region" aria-labelledby="similarity_index_title" aria-describedby="similarity_index_title">
                    <div class="overall_similarity">
                        <div class="color_box green">&nbsp;</div>
                        <div id="similarity_index_title" class="similarity_title">Similarity Index</div>
                        <div class="similarity_percent">8%</div>
                    </div>
                    <div class="similarity_by_source" role="region" aria-labelledby="similarity_by_source_title" aria-describedby="similarity_by_source_title">
                        <div id="similarity_by_source_title" class="similarity_title">Similarity by Source</div>
                        <dl>
                            <dt>Internet&nbsp;Sources:</dt>
                            <dd>7%</dd>
                            <div class="clear"></div>
                            <dt>Publications:</dt>
                            <dd>5%</dd>
                            <div class="clear"></div>
                            <dt>Student&nbsp;Papers:</dt>
                            <dd>5%</dd>
                            <div class="clear"></div>
                        </dl>
                    </div>
                </div>
            </div>
            <div class="clear"></div>
                                 
        </div>
        <!-- ######### END Top Body  ##########################--> 
        
        
    </div>
</div>
<!-- ########################### END Top of Report  ##########################--> 



<!-- ########################### TOOLBAR  ##########################--> 
<div id="index">
	<div id="toolbar_wrapper" role="toolbar">
        
	</div>
</div>
<!-- ########################### END TOOLBAR  ##########################--> 


<div class="links" role="region" aria-label="Match Overview">
    <div role="list">
	<div role="listitem" aria-setsize="104" aria-posinset="1">
	    <p>
	        < 1% match (Internet from 02-Oct-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2509.25853v1" target="_blank" style="color:#D10A0A">https://arxiv.org/html/2509.25853v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="2">
	    <p>
	        < 1% match (Internet from 28-Jun-2025)
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/pdf/2506.20686" target="_blank" style="color:#287B28">http://arxiv.org/pdf/2506.20686</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="3">
	    <p>
	        < 1% match (Internet from 11-Apr-2024)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2404.06114v1" target="_blank" style="color:blue">https://arxiv.org/html/2404.06114v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="4">
	    <p>
	        < 1% match (Internet from 05-Jun-2025)
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/pdf/2505.24298" target="_blank" style="color:brown">http://arxiv.org/pdf/2505.24298</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="5">
	    <p>
	        < 1% match (Internet from 16-Sep-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2509.10371v1" target="_blank" style="color:#B64B01">https://arxiv.org/html/2509.10371v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="6">
	    <p>
	        < 1% match (Internet from 28-Feb-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2408.14158v1" target="_blank" style="color:#630000">https://arxiv.org/html/2408.14158v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="7">
	    <p>
	        < 1% match (Internet from 08-Jun-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2506.05007v1" target="_blank" style="color:#0270B6">https://arxiv.org/html/2506.05007v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="8">
	    <p>
	        < 1% match (Internet from 12-Jul-2025)
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/pdf/2507.06608" target="_blank" style="color:#330099">http://arxiv.org/pdf/2507.06608</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="9">
	    <p>
	        < 1% match (Internet from 09-May-2025)
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/pdf/2505.03531" target="_blank" style="color:#227967">http://arxiv.org/pdf/2505.03531</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="10">
	    <p>
	        < 1% match (Internet from 17-Sep-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/pdf/2509.10694" target="_blank" style="color:#CB0099">https://arxiv.org/pdf/2509.10694</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="11">
	    <p>
	        < 1% match (Internet from 24-Jan-2024)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/pdf/2301.04020.pdf" target="_blank" style="color:#006331">https://arxiv.org/pdf/2301.04020.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="12">
	    <p>
	        < 1% match (Internet from 24-Sep-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/pdf/2509.16857" target="_blank" style="color:#795AB9">https://arxiv.org/pdf/2509.16857</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="13">
	    <p>
	        < 1% match (Internet from 23-Feb-2024)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2402.13499v1" target="_blank" style="color:#935F32">https://arxiv.org/html/2402.13499v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="14">
	    <p>
	        < 1% match (student papers from 26-Jul-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3302804630,1,'0')" target="_blank" style="color:#ce0031">Submitted to University of Hong Kong on 2025-07-26</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="15">
	    <p>
	        < 1% match (student papers from 27-Jun-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3285974792,1,'0')" target="_blank" style="color:#866712">Submitted to University of Hong Kong on 2025-06-27</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="16">
	    <p>
	        < 1% match (student papers from 30-Oct-2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2432738625,1,'0')" target="_blank" style="color:#63009c">Submitted to University of Hong Kong on 2022-10-30</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="17">
	    <p>
	        < 1% match (student papers from 23-Feb-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3163213557,1,'0')" target="_blank" style="color:#A85503">Submitted to University of Hong Kong on 2025-02-23</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="18">
	    <p>
	        < 1% match (student papers from 22-Aug-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3318268931,1,'0')" target="_blank" style="color:#cc0066">Submitted to University of Hong Kong on 2025-08-22</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="19">
	    <p>
	        < 1% match (student papers from 29-Feb-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2838819828,1,'0')" target="_blank" style="color:#21785B">Submitted to University of Hong Kong on 2024-02-29</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="20">
	    <p>
	        < 1% match (student papers from 22-May-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3257050767,1,'0')" target="_blank" style="color:#336699">Submitted to University of Hong Kong on 2025-05-22</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="21">
	    <p>
	        < 1% match (student papers from 23-Feb-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2524211404,1,'0')" target="_blank" style="color:#D10A0A">Submitted to University of Hong Kong on 2023-02-23</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="22">
	    <p>
	        < 1% match (student papers from 18-Apr-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2890319192,1,'0')" target="_blank" style="color:#287B28">Submitted to University of Hong Kong on 2024-04-18</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="23">
	    <p>
	        < 1% match (student papers from 15-Jun-2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2068328302,1,'0')" target="_blank" style="color:blue">Submitted to University of Hong Kong on 2021-06-15</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="24">
	    <p>
	        < 1% match (student papers from 27-Jul-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3303207720,1,'0')" target="_blank" style="color:brown">Submitted to University of Hong Kong on 2025-07-27</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="25">
	    <p>
	        < 1% match (Internet from 20-Oct-2025)
	    </p>
        
        
 
	    <p><a href="https://github.com/open-neutrino/neutrino" target="_blank" style="color:#B64B01">https://github.com/open-neutrino/neutrino</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="26">
	    <p>
	        < 1% match (Internet from 15-Dec-2022)
	    </p>
        
        
 
	    <p><a href="https://github.com/openai/triton/issues/441" target="_blank" style="color:#630000">https://github.com/openai/triton/issues/441</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="27">
	    <p>
	        < 1% match (Internet from 25-Mar-2025)
	    </p>
        
        
 
	    <p><a href="https://ses.library.usyd.edu.au/bitstream/handle/2123/33717/Final_Thesis%20%2810%29.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#0270B6">https://ses.library.usyd.edu.au/bitstream/handle/2123/33717/Final_Thesis%20%2810%29.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="28">
	    <p>
	        < 1% match (Internet from 17-Jun-2025)
	    </p>
        
        
 
	    <p><a href="https://ses.library.usyd.edu.au/bitstream/handle/2123/33986/Thesis_Lyu%2c%20Qingcheng%20520326323.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#330099">https://ses.library.usyd.edu.au/bitstream/handle/2123/33986/Thesis_Lyu%2c%20Qingcheng%20520326323.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="29">
	    <p>
	        < 1% match (Internet from 07-Nov-2024)
	    </p>
        
        
 
	    <p><a href="https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html" target="_blank" style="color:#227967">https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="30">
	    <p>
	        < 1% match (Internet from 14-Oct-2022)
	    </p>
        
        
 
	    <p><a href="https://deepai.org/publication/breaking-the-computation-and-communication-abstraction-barrier-in-distributed-machine-learning-workloads" target="_blank" style="color:#CB0099">https://deepai.org/publication/breaking-the-computation-and-communication-abstraction-barrier-in-distributed-machine-learning-workloads</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="31">
	    <p>
	        < 1% match (Internet from 09-Oct-2023)
	    </p>
        
        
 
	    <p><a href="https://api.drum.lib.umd.edu/server/api/core/bitstreams/a2c5e70d-17b7-44b5-a797-2ecf14df57f2/content" target="_blank" style="color:#006331">https://api.drum.lib.umd.edu/server/api/core/bitstreams/a2c5e70d-17b7-44b5-a797-2ecf14df57f2/content</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="32">
	    <p>
	        < 1% match (Internet from 11-Oct-2025)
	    </p>
        
        
 
	    <p><a href="https://mediatum.ub.tum.de/doc/1775107/1775107.pdf" target="_blank" style="color:#795AB9">https://mediatum.ub.tum.de/doc/1775107/1775107.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="33">
	    <p>
	        < 1% match (Ng, Kelvin K. W.. "Resource Sharing for Machine Learning Serving", University of Pennsylvania, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(841521083,917,'0')" target="_blank" style="color:#935F32">Ng, Kelvin K. W.. "Resource Sharing for Machine Learning Serving", University of Pennsylvania, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="34">
	    <p>
	        < 1% match (Internet from 25-Jul-2025)
	    </p>
        
        
 
	    <p><a href="https://elib.uni-stuttgart.de/server/api/core/bitstreams/d6db3876-262a-464b-bed8-6aaba66d7e7b/content" target="_blank" style="color:#ce0031">https://elib.uni-stuttgart.de/server/api/core/bitstreams/d6db3876-262a-464b-bed8-6aaba66d7e7b/content</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="35">
	    <p>
	        < 1% match (Renzo Andri, Beatrice Bussolino, Antonio Cipolletta, Lukas Cavigelli, Zhe Wang. "Going Further With Winograd Convolutions: Tap-Wise Quantization for Efficient Inference on 4x4 Tiles", 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(779290747,37,'0')" target="_blank" style="color:#866712">Renzo Andri, Beatrice Bussolino, Antonio Cipolletta, Lukas Cavigelli, Zhe Wang. "Going Further With Winograd Convolutions: Tap-Wise Quantization for Efficient Inference on 4x4 Tiles", 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="36">
	    <p>
	        < 1% match (Internet from 20-Oct-2025)
	    </p>
        
        
 
	    <p><a href="https://csd.cs.cmu.edu/sites/default/files/phd-thesis/CMU-CS-24-135.pdf" target="_blank" style="color:#63009c">https://csd.cs.cmu.edu/sites/default/files/phd-thesis/CMU-CS-24-135.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="37">
	    <p>
	        < 1% match (Internet from 16-Sep-2024)
	    </p>
        
        
 
	    <p><a href="https://d-nb.info/1341835669/34" target="_blank" style="color:#A85503">https://d-nb.info/1341835669/34</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="38">
	    <p>
	        < 1% match (Internet from 31-Jan-2020)
	    </p>
        
        
 
	    <p><a href="https://www.scribd.com/document/393623513/sistemas-operativos-pdf" target="_blank" style="color:#cc0066">https://www.scribd.com/document/393623513/sistemas-operativos-pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="39">
	    <p>
	        < 1% match (student papers from 12-Jun-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(811286824,2,'0')" target="_blank" style="color:#21785B">Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="40">
	    <p>
	        < 1% match (István-Attila Császár, Radu Razvan Slavescu. "Building fast and reliable reverse engineering tools with Frida and Rust", 2022 IEEE 18th International Conference on Intelligent Computer Communication and Processing (ICCP), 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(788920839,37,'0')" target="_blank" style="color:#336699">István-Attila Császár, Radu Razvan Slavescu. "Building fast and reliable reverse engineering tools with Frida and Rust", 2022 IEEE 18th International Conference on Intelligent Computer Communication and Processing (ICCP), 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="41">
	    <p>
	        < 1% match (Internet from 16-Apr-2025)
	    </p>
        
        
 
	    <p><a href="https://www.coursehero.com/file/63001382/g40docx/" target="_blank" style="color:#D10A0A">https://www.coursehero.com/file/63001382/g40docx/</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="42">
	    <p>
	        < 1% match (Internet from 27-May-2020)
	    </p>
        
        
 
	    <p><a href="https://www.coursehero.com/file/34861224/CHAPTER-1pdf/" target="_blank" style="color:#287B28">https://www.coursehero.com/file/34861224/CHAPTER-1pdf/</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="43">
	    <p>
	        < 1% match (student papers from 14-Oct-2018)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(1019459859,1,'0')" target="_blank" style="color:blue">Submitted to University of Colorado, Colorado Springs on 2018-10-14</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="44">
	    <p>
	        < 1% match (Internet from 25-Dec-2022)
	    </p>
        
        
 
	    <p><a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-217.pdf" target="_blank" style="color:brown">https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-217.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="45">
	    <p>
	        < 1% match (Konstantin Levit-Gurevich, Alex Skaletsky, Michael Berezalsky, Yulia Kuznetcova, Hila Yakov. "Profiling Intel Graphics Architecture with Long Instruction Traces", 2022 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(770867629,37,'0')" target="_blank" style="color:#B64B01">Konstantin Levit-Gurevich, Alex Skaletsky, Michael Berezalsky, Yulia Kuznetcova, Hila Yakov. "Profiling Intel Graphics Architecture with Long Instruction Traces", 2022 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="46">
	    <p>
	        < 1% match (student papers from 26-Aug-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2990970781,1,'0')" target="_blank" style="color:#630000">Submitted to Vrije Universiteit Brussel on 2024-08-26</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="47">
	    <p>
	        < 1% match (Internet from 20-Jan-2023)
	    </p>
        
        
 
	    <p><a href="https://www.microsoft.com/en-us/research/uploads/prod/2021/03/gebara21panama.pdf" target="_blank" style="color:#0270B6">https://www.microsoft.com/en-us/research/uploads/prod/2021/03/gebara21panama.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="48">
	    <p>
	        < 1% match (Internet from 19-Mar-2019)
	    </p>
        
        
 
	    <p><a href="https://dspace.cuni.cz/bitstream/handle/20.500.11956/83719/140052848.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#330099">https://dspace.cuni.cz/bitstream/handle/20.500.11956/83719/140052848.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="49">
	    <p>
	        < 1% match (Internet from 06-Aug-2023)
	    </p>
        
        
 
	    <p><a href="https://escholarship.org/content/qt7ht7g77k/qt7ht7g77k.pdf?t=rytc5x" target="_blank" style="color:#227967">https://escholarship.org/content/qt7ht7g77k/qt7ht7g77k.pdf?t=rytc5x</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="50">
	    <p>
	        < 1% match (Internet from 12-Feb-2023)
	    </p>
        
        
 
	    <p><a href="https://escholarship.org/content/qt8vb1s8zz/qt8vb1s8zz.pdf?t=rpt73c" target="_blank" style="color:#CB0099">https://escholarship.org/content/qt8vb1s8zz/qt8vb1s8zz.pdf?t=rpt73c</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="51">
	    <p>
	        < 1% match (Internet from 28-Aug-2022)
	    </p>
        
        
 
	    <p><a href="https://spiral.imperial.ac.uk/bitstream/10044/1/79631/1/WanAHamid-WLH-2019-PhD-Thesis.pdf" target="_blank" style="color:#006331">https://spiral.imperial.ac.uk/bitstream/10044/1/79631/1/WanAHamid-WLH-2019-PhD-Thesis.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="52">
	    <p>
	        < 1% match (Internet from 22-Oct-2024)
	    </p>
        
        
 
	    <p><a href="https://ar5iv.labs.arxiv.org/html/2407.20018" target="_blank" style="color:#795AB9">https://ar5iv.labs.arxiv.org/html/2407.20018</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="53">
	    <p>
	        < 1% match (Internet from 17-Sep-2020)
	    </p>
        
        
 
	    <p><a href="https://minds.wisconsin.edu/bitstream/handle/1793/80527/DESIGNING%20EFFICIENT%20BARRIERS%20AND%20SEMAPHORES%20-%20Rohan%20Mahapatra.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#935F32">https://minds.wisconsin.edu/bitstream/handle/1793/80527/DESIGNING%20EFFICIENT%20BARRIERS%20AND%20SEMAPHORES%20-%20Rohan%20Mahapatra.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="54">
	    <p>
	        < 1% match (Internet from 20-Sep-2025)
	    </p>
        
        
 
	    <p><a href="https://theses.hal.science/tel-04913269/file/126758_FORCIOLI_2024_archivage.pdf" target="_blank" style="color:#ce0031">https://theses.hal.science/tel-04913269/file/126758_FORCIOLI_2024_archivage.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="55">
	    <p>
	        < 1% match (Internet from 03-Oct-2025)
	    </p>
        
        
 
	    <p><a href="https://theses.hal.science/tel-03420197v1/file/BEILLAHI_Sidi_Mohamed_va2.pdf" target="_blank" style="color:#866712">https://theses.hal.science/tel-03420197v1/file/BEILLAHI_Sidi_Mohamed_va2.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="56">
	    <p>
	        < 1% match (Internet from 21-Dec-2022)
	    </p>
        
        
 
	    <p><a href="https://www.engineering.pitt.edu/people/faculty/jun-yang/" target="_blank" style="color:#63009c">https://www.engineering.pitt.edu/people/faculty/jun-yang/</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="57">
	    <p>
	        < 1% match (Cong Guo, Rui Zhang, Jiale Xu, Jingwen Leng, Zihan Liu, Ziyu Huang, Minyi Guo, Hao Wu, Shouren Zhao, Junping Zhao, Ke Zhang. "GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching", Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(819067283,37,'0')" target="_blank" style="color:#A85503">Cong Guo, Rui Zhang, Jiale Xu, Jingwen Leng, Zihan Liu, Ziyu Huang, Minyi Guo, Hao Wu, Shouren Zhao, Junping Zhao, Ke Zhang. "GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching", Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="58">
	    <p>
	        < 1% match (Internet from 17-Dec-2022)
	    </p>
        
        
 
	    <p><a href="https://ece.northeastern.edu/groups/nucar/publications/Xiang_Gong_thesis.pdf" target="_blank" style="color:#cc0066">https://ece.northeastern.edu/groups/nucar/publications/Xiang_Gong_thesis.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="59">
	    <p>
	        < 1% match (student papers from 26-Apr-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2901024345,1,'0')" target="_blank" style="color:#21785B">Submitted to Georgia Institute of Technology Main Campus on 2024-04-26</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="60">
	    <p>
	        < 1% match (student papers from 12-May-2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2043662935,1,'0')" target="_blank" style="color:#336699">Submitted to Associatie K.U.Leuven on 2021-05-12</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="61">
	    <p>
	        < 1% match (student papers from 28-Sep-2006)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(30506786,1,'0')" target="_blank" style="color:#D10A0A">Submitted to Graz University of Technology on 2006-09-28</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="62">
	    <p>
	        < 1% match (Numerical Computations with GPUs, 2014.)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(54202421,37,'0')" target="_blank" style="color:#287B28">Numerical Computations with GPUs, 2014.</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="63">
	    <p>
	        < 1% match (Internet from 11-Sep-2025)
	    </p>
        
        
 
	    <p><a href="https://hal.science/hal-04683563v2/document" target="_blank" style="color:blue">https://hal.science/hal-04683563v2/document</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="64">
	    <p>
	        < 1% match ()
	    </p>
        
        
 
	    <p><a href="http://hdl.handle.net/10019.1/53570" target="_blank" style="color:brown">Andrag, Walter H.. "Reinforcement learning for routing in communication networks", Stellenbosch : Stellenbosch University, 2003</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="65">
	    <p>
	        < 1% match (Internet from 24-Jun-2025)
	    </p>
        
        
 
	    <p><a href="https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf" target="_blank" style="color:#B64B01">https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="66">
	    <p>
	        < 1% match (student papers from 08-Oct-2010)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(7529796,2,'0')" target="_blank" style="color:#630000">Submitted to Birkbeck College  on 2010-10-08</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="67">
	    <p>
	        < 1% match (student papers from 24-Aug-2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(670378999,2,'0')" target="_blank" style="color:#0270B6">Submitted to Royal Holloway and Bedford New College  on 2021-08-24</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="68">
	    <p>
	        < 1% match (Ascia, G.. "Performance evaluation of efficient multi-objective evolutionary     algorithms for design space exploration of embedded computer systems", Applied Soft Computing Journal, 201101)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(30339825,37,'0')" target="_blank" style="color:#330099">Ascia, G.. "Performance evaluation of efficient multi-objective evolutionary     algorithms for design space exploration of embedded computer systems", Applied Soft Computing Journal, 201101</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="69">
	    <p>
	        < 1% match (Internet from 13-Jan-2010)
	    </p>
        
        
 
	    <p><a href="http://www.lib.ncsu.edu/theses/available/etd-05152008-145809/unrestricted/etd.pdf" target="_blank" style="color:#227967">http://www.lib.ncsu.edu/theses/available/etd-05152008-145809/unrestricted/etd.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="70">
	    <p>
	        < 1% match (Internet from 24-Nov-2022)
	    </p>
        
        
 
	    <p><a href="https://www.mi.tj.chiba-u.jp/~tsumura/Tsumura/papers/BSPIJ2017kiyomitsu.pdf" target="_blank" style="color:#CB0099">https://www.mi.tj.chiba-u.jp/~tsumura/Tsumura/papers/BSPIJ2017kiyomitsu.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="71">
	    <p>
	        < 1% match (Ding, Ruyi. "Towards Robust and Secure Deep Learning: From Training Through Deployment to Inference.", Northeastern University)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(839345153,917,'0')" target="_blank" style="color:#006331">Ding, Ruyi. "Towards Robust and Secure Deep Learning: From Training Through Deployment to Inference.", Northeastern University</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="72">
	    <p>
	        < 1% match (Internet from 08-Dec-2022)
	    </p>
        
        
 
	    <p><a href="https://digitallibrary.usc.edu/asset-management/2A3BF1Q9MEUD" target="_blank" style="color:#795AB9">https://digitallibrary.usc.edu/asset-management/2A3BF1Q9MEUD</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="73">
	    <p>
	        < 1% match (Internet from 05-Jul-2024)
	    </p>
        
        
 
	    <p><a href="https://patents.justia.com/patent/11467960" target="_blank" style="color:#935F32">https://patents.justia.com/patent/11467960</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="74">
	    <p>
	        < 1% match (Abhishek Bhattacharjee, Daniel Lustig. "Architectural and Operating System Support for Virtual Memory", Springer Science and Business Media LLC, 2018)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(787551191,37,'0')" target="_blank" style="color:#ce0031">Abhishek Bhattacharjee, Daniel Lustig. "Architectural and Operating System Support for Virtual Memory", Springer Science and Business Media LLC, 2018</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="75">
	    <p>
	        < 1% match (Gwilliam, Matthew. "Understanding and Modeling Explicit and Implicit Representations of the Visual World", University of Maryland, College Park, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(841510876,917,'0')" target="_blank" style="color:#866712">Gwilliam, Matthew. "Understanding and Modeling Explicit and Implicit Representations of the Visual World", University of Maryland, College Park, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="76">
	    <p>
	        < 1% match (Liu, Zirui. "Lossy Computation for Large-Scale Machine Learning", Rice University)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837690624,917,'0')" target="_blank" style="color:#63009c">Liu, Zirui. "Lossy Computation for Large-Scale Machine Learning", Rice University</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="77">
	    <p>
	        < 1% match (Simin Peng, Tianzhu Huang, Yali Peng, Pengfei Zhang, Luyan Liao, Weiguo Wu. "Combining GC-MS and chemometrics to assess the quality of camellia seed oils", CyTA - Journal of Food, 2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(750121833,37,'0')" target="_blank" style="color:#A85503">Simin Peng, Tianzhu Huang, Yali Peng, Pengfei Zhang, Luyan Liao, Weiguo Wu. "Combining GC-MS and chemometrics to assess the quality of camellia seed oils", CyTA - Journal of Food, 2021</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="78">
	    <p>
	        < 1% match (Internet from 22-Oct-2023)
	    </p>
        
        
 
	    <p><a href="https://codeclimate.com/github/tensorflow/tensorflow/third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc/source" target="_blank" style="color:#cc0066">https://codeclimate.com/github/tensorflow/tensorflow/third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc/source</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="79">
	    <p>
	        < 1% match (Internet from 03-Sep-2025)
	    </p>
        
        
 
	    <p><a href="https://harmony.cs.cornell.edu/book/" target="_blank" style="color:#21785B">https://harmony.cs.cornell.edu/book/</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="80">
	    <p>
	        < 1% match (Internet from 14-Jul-2025)
	    </p>
        
        
 
	    <p><a href="https://inria.hal.science/hal-04984000v1/file/KV_Cache_Characterization_IPDPS25.pdf" target="_blank" style="color:#336699">https://inria.hal.science/hal-04984000v1/file/KV_Cache_Characterization_IPDPS25.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="81">
	    <p>
	        < 1% match (Internet from 28-Apr-2025)
	    </p>
        
        
 
	    <p><a href="https://jscholarship.library.jhu.edu/server/api/core/bitstreams/fc220554-fcf7-4d51-a355-829cfbc47626/content" target="_blank" style="color:#D10A0A">https://jscholarship.library.jhu.edu/server/api/core/bitstreams/fc220554-fcf7-4d51-a355-829cfbc47626/content</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="82">
	    <p>
	        < 1% match (Internet from 25-Nov-2020)
	    </p>
        
        
 
	    <p><a href="https://stackoverflow.com/questions/8877666/how-is-a-javascript-hash-map-implemented" target="_blank" style="color:#287B28">https://stackoverflow.com/questions/8877666/how-is-a-javascript-hash-map-implemented</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="83">
	    <p>
	        < 1% match (Bao, Qinyang. "MPBRQ - A Framework for Mixed-Precision Quantization for Large Language Models.", University of Toronto (Canada), 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(831273016,917,'0')" target="_blank" style="color:blue">Bao, Qinyang. "MPBRQ - A Framework for Mixed-Precision Quantization for Large Language Models.", University of Toronto (Canada), 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="84">
	    <p>
	        < 1% match (Hongzheng Chen, Jiahao Zhang, Yixiao Du, Shaojie Xiang, Zichao Yue, Niansong Zhang, Yaohui Cai, Zhiru Zhang. "Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference", ACM Transactions on Reconfigurable Technology and Systems, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(817509911,37,'0')" target="_blank" style="color:brown">Hongzheng Chen, Jiahao Zhang, Yixiao Du, Shaojie Xiang, Zichao Yue, Niansong Zhang, Yaohui Cai, Zhiru Zhang. "Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference", ACM Transactions on Reconfigurable Technology and Systems, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="85">
	    <p>
	        < 1% match (publications)
	    </p>
        
        
 
	    <p><a href="https://doi.org/10.1201/9781003077688" target="_blank" style="color:#B64B01">I.K. Gavich. "Hydrogeodynamics", A.A. Balkema, Rotterdam, 2020</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="86">
	    <p>
	        < 1% match (Lu, Xiaoyang. "Utilizing Concurrent Data Accesses for Data-Driven and AI Applications", Illinois Institute of Technology, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(821582960,917,'0')" target="_blank" style="color:#630000">Lu, Xiaoyang. "Utilizing Concurrent Data Accesses for Data-Driven and AI Applications", Illinois Institute of Technology, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="87">
	    <p>
	        < 1% match (Luk Van Ertvelde. "Dispersing proprietary applications as benchmarks through code mutation", ACM SIGARCH Computer Architecture News, 3/25/2008)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3625292,37,'0')" target="_blank" style="color:#0270B6">Luk Van Ertvelde. "Dispersing proprietary applications as benchmarks through code mutation", ACM SIGARCH Computer Architecture News, 3/25/2008</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="88">
	    <p>
	        < 1% match (Qiangyu Pei, Yongjie Yuan, Haichuan Hu, Qiong Chen, Fangming Liu. "AsyFunc", Proceedings of the 2023 ACM Symposium on Cloud Computing, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(811084790,37,'0')" target="_blank" style="color:#330099">Qiangyu Pei, Yongjie Yuan, Haichuan Hu, Qiong Chen, Fangming Liu. "AsyFunc", Proceedings of the 2023 ACM Symposium on Cloud Computing, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="89">
	    <p>
	        < 1% match (Rajeev Barua. "Segment protection for embedded systems using run-time checks", Proceedings of the 2005 international conference on Compilers architectures and synthesis for embedded systems - CASES 05 CASES 05, 2005)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(5891077,37,'0')" target="_blank" style="color:#227967">Rajeev Barua. "Segment protection for embedded systems using run-time checks", Proceedings of the 2005 international conference on Compilers architectures and synthesis for embedded systems - CASES 05 CASES 05, 2005</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="90">
	    <p>
	        < 1% match (Size Zheng, Renze Chen, Yicheng Jin, Anjiang Wei, Bingyang Wu, Xiuhong Li, Shengen Yan, Yun Liang. "NeoFlow: A Flexible Framework for Enabling Efficient Compilation for High Performance DNN Training", IEEE Transactions on Parallel and Distributed Systems, 2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(767558592,37,'0')" target="_blank" style="color:#CB0099">Size Zheng, Renze Chen, Yicheng Jin, Anjiang Wei, Bingyang Wu, Xiuhong Li, Shengen Yan, Yun Liang. "NeoFlow: A Flexible Framework for Enabling Efficient Compilation for High Performance DNN Training", IEEE Transactions on Parallel and Distributed Systems, 2021</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="91">
	    <p>
	        < 1% match (Tyler Sorensen, Lucas F. Salvador, Harmit Raval, Hugues Evrard, John Wickerson, Margaret Martonosi, Alastair F. Donaldson. "Specifying and testing GPU workgroup progress models", Proceedings of the ACM on Programming Languages, 2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(750976313,37,'0')" target="_blank" style="color:#006331">Tyler Sorensen, Lucas F. Salvador, Harmit Raval, Hugues Evrard, John Wickerson, Margaret Martonosi, Alastair F. Donaldson. "Specifying and testing GPU workgroup progress models", Proceedings of the ACM on Programming Languages, 2021</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="92">
	    <p>
	        < 1% match (Yi Yang, Chao Li, Huiyang Zhou. "CUDA-NP: Realizing Nested Thread-Level Parallelism in GPGPU Applications", Journal of Computer Science and Technology, 2015)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(53353502,37,'0')" target="_blank" style="color:#795AB9">Yi Yang, Chao Li, Huiyang Zhou. "CUDA-NP: Realizing Nested Thread-Level Parallelism in GPGPU Applications", Journal of Computer Science and Technology, 2015</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="93">
	    <p>
	        < 1% match (Internet from 02-Sep-2025)
	    </p>
        
        
 
	    <p><a href="https://amsdottorato.unibo.it/id/eprint/11919/1/ficarelli.pdf" target="_blank" style="color:#935F32">https://amsdottorato.unibo.it/id/eprint/11919/1/ficarelli.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="94">
	    <p>
	        < 1% match (Internet from 17-Feb-2025)
	    </p>
        
        
 
	    <p><a href="https://backoffice.biblio.ugent.be/download/8716104/8716146" target="_blank" style="color:#ce0031">https://backoffice.biblio.ugent.be/download/8716104/8716146</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="95">
	    <p>
	        < 1% match (Internet from 03-Jun-2024)
	    </p>
        
        
 
	    <p><a href="https://conservancy.umn.edu/server/api/core/bitstreams/d6dda029-0d76-4b74-a560-54a3d01136cd/content" target="_blank" style="color:#866712">https://conservancy.umn.edu/server/api/core/bitstreams/d6dda029-0d76-4b74-a560-54a3d01136cd/content</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="96">
	    <p>
	        < 1% match (Internet from 13-Aug-2024)
	    </p>
        
        
 
	    <p><a href="https://docslib.org/doc/3881914/download-nvidia-com-pdf-tegra-tegra-x1-whitepaper" target="_blank" style="color:#63009c">https://docslib.org/doc/3881914/download-nvidia-com-pdf-tegra-tegra-x1-whitepaper</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="97">
	    <p>
	        < 1% match (Internet from 21-Jan-2025)
	    </p>
        
        
 
	    <p><a href="https://ftp.cs.wisc.edu/sohi/theses/moshovos.pdf" target="_blank" style="color:#A85503">https://ftp.cs.wisc.edu/sohi/theses/moshovos.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="98">
	    <p>
	        < 1% match (Internet from 15-Oct-2018)
	    </p>
        
        
 
	    <p><a href="https://hal.inria.fr/tel-01597752/file/MONDELLI_Andrea.pdf" target="_blank" style="color:#cc0066">https://hal.inria.fr/tel-01597752/file/MONDELLI_Andrea.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="99">
	    <p>
	        < 1% match (Internet from 25-Aug-2023)
	    </p>
        
        
 
	    <p><a href="https://repository.kaust.edu.sa/bitstream/handle/10754/693744/Tackling_the_Communication_Bottlenecks_of_Distributed_Deep_Learning_Training_Workloads.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#21785B">https://repository.kaust.edu.sa/bitstream/handle/10754/693744/Tackling_the_Communication_Bottlenecks_of_Distributed_Deep_Learning_Training_Workloads.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="100">
	    <p>
	        < 1% match (Internet from 07-Nov-2013)
	    </p>
        
        
 
	    <p><a href="http://www.itworld.com/nl/lnx_tip/05112001/" target="_blank" style="color:#336699">http://www.itworld.com/nl/lnx_tip/05112001/</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="101">
	    <p>
	        < 1% match (Internet from 26-Sep-2022)
	    </p>
        
        
 
	    <p><a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/537004/dissertation-salvo.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#D10A0A">https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/537004/dissertation-salvo.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="102">
	    <p>
	        < 1% match ("Applied Parallel and Scientific Computing", Springer Science and Business Media LLC, 2013)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(583189560,37,'0')" target="_blank" style="color:#287B28">"Applied Parallel and Scientific Computing", Springer Science and Business Media LLC, 2013</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="103">
	    <p>
	        < 1% match (V. Petric, A. Bracy, A. Roth. "Three extensions to register integration", 35th Annual IEEE/ACM International Symposium on Microarchitecture, 2002. (MICRO-35). Proceedings., 2002)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(11583153,37,'0')" target="_blank" style="color:blue">V. Petric, A. Bracy, A. Roth. "Three extensions to register integration", 35th Annual IEEE/ACM International Symposium on Microarchitecture, 2002. (MICRO-35). Proceedings., 2002</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="104" aria-posinset="104">
	    <p>
	        < 1% match (student papers from 21-Sep-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3346125768,1,'0')" target="_blank" style="color:brown">Submitted to National University of Singapore on 2025-09-21</a>

    
    </p>
    </div></div></div></div><div id="body" tabIndex="0" role="main"><p>UNIVERSITY OF HONG KONG MASTER THESIS Understanding Machine Learning Kernel Performance via Fine-grained and Programmable Profiling Author: Songlin HUANG Primary Supervisor: Prof. Chenshu WU Secondary Supervisor: Prof. Chuan WU <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 17 in source list: Submitted to University of Hong Kong on 2025-02-23"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3163213557&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">A thesis submitted in fulfillment of the requirements for the degree of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Master <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 17 in source list: Submitted to University of Hong Kong on 2025-02-23"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3163213557&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">of Philosophy in the Department of Computer Science School of Computing and Data Science</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> October 27, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 17 in source list: Submitted to University of Hong Kong on 2025-02-23"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3163213557&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">2025 Abstract of thesis entitled</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Understanding Machine Learning Kernel Performance via Fine-grained and Programmable Profiling <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">Submitted by</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Songlin <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">HUANG for the degree of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Master <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">of Philosophy at The University of Hong Kong in</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> October, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">2025</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> With <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> emergence <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> artificial intelligence and large language models under the scaling law in parameters and computation, the underlying computer system and net- work centralized with GPU, the parallel-oriented heterogeneous computing device, have been scaling rapidly. Therefore, observing and optimizing the GPU runtime be- havior is more crucial than ever. However, existing GPU kernel profilers, which are typ- ically either kernel-exclusive or hardware-dependent, often fail to capture fine-grained measurements. The lack of performance tools leads to two critical challenges in large- scale GPU system research: ❶ GPU kernels, the computing code executed on GPUs, are vital for performance but hard to profile with little system support; ❷ Scale-Up net- works connecting multiple GPUs via hardware interconnects, rather than traditional NICs/Switches, becomes critical but hard to profile with little network support. Based on these observations, this thesis demonstrates two research efforts to un- derstand and optimize the computation and communication performance of machine learning kernels using the fine-grained and programmable probing approach: The first effort is NEUTRINO, a programmable interface for GPU kernel profiling that leverages assembly-layer probing to achieve instruction-level fine granularity, pro- filing versatility across time and value domains, and hardware independence. To better visualize the rich details captured by NEUTRINO, we introduce the Densified Memory Access Timeline (DMAT), a novel representation that offers new insights into GPU run- time behavior. We implement NEUTRINO in Linux for both NVIDIA and AMD GPUs and conduct extensive evaluations and analyses. The results demonstrate NEUTRINO ’s superior capabilities in GPU kernel profiling with low overhead. The second effort is MECCL, a MEasurement toolkit for Collective Communica- tion Libraries over the Scale-Up networks that extends NEUTRINO probes for network observation without hardware (NIC/Switch) support. MECCL formulates a compre- hensive theoretical model to analyze Scale-Up network and conduct practical measure- ments to explores the inefficiency of existing communication kernels like NCCL in poor cache usage, channel imbalance, etc. Based on these observations, we plan to build a Memory Efficient Collective Communication Libraries with better performance and lower resource usage. [325 Words] Understanding Machine Learning Kernel Performance via Fine-grained and Programmable Profiling by Songlin HUANG <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 16 in source list: Submitted to University of Hong Kong on 2022-10-30"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:2432738625&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">B.Eng. HKU A Thesis Submitted in Partial</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Fulfillment <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 16 in source list: Submitted to University of Hong Kong on 2022-10-30"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:2432738625&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">of the Requirements for the Degree of Master of Philosophy at University of Hong Kong October</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, 2025 <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 16 in source list: Submitted to University of Hong Kong on 2022-10-30"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:2432738625&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">COPYRIGHT</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> ©2025, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 16 in source list: Submitted to University of Hong Kong on 2022-10-30"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:2432738625&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">BY</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> SONGLIN HUANG <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 16 in source list: Submitted to University of Hong Kong on 2022-10-30"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:2432738625&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">ALL RIGHTS RESERVED. i Declaration I</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, Songlin HUANG, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 16 in source list: Submitted to University of Hong Kong on 2022-10-30"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:2432738625&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">declare that this thesis titled</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, “Understanding Machine Learn- ing Kernel Performance via Fine-grained and Programmable Profiling”, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 14 in source list: Submitted to University of Hong Kong on 2025-07-26"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3302804630&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">which is sub- mitted in fulfillment of the requirements for the Degree of Master of Philosophy, rep- resents my own work except where due</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> acknowledgment <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 14 in source list: Submitted to University of Hong Kong on 2025-07-26"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3302804630&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">have been made. I further declared that it has not been previously included in a thesis, dissertation, or report submitted to this University or to any other institution for a degree, diploma or other qualifications. Signed: Date</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">: October 27, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 14 in source list: Submitted to University of Hong Kong on 2025-07-26"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3302804630&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">2025 { AFor Mama and Papas } ii Acknowledgements I would like to</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> thank... Songlin <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">HUANG University of Hong Kong</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> October 27, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">2025 iii List of Publications</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> CONFERENCES: [<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">1</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">] Songlin <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 18 in source list: Submitted to University of Hong Kong on 2025-08-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3318268931&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">Huang</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 104 in source list: Submitted to National University of Singapore on 2025-09-21"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3346125768&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">and Chenshu Wu</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, “Neutrino: Fine-grained GPU Kernel Profiling via Programmable Probing” <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 104 in source list: Submitted to National University of Singapore on 2025-09-21"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3346125768&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">in</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> the Proccedings <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 10 in source list: https://arxiv.org/pdf/2509.10694"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=3727628255&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">of the 19th USENIX Symposium on Operating Systems Design and Implementation (OSDI ’25</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">), July 7-9th, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 10 in source list: https://arxiv.org/pdf/2509.10694"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=3727628255&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">Boston MA, USA</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 19 in source list: Submitted to University of Hong Kong on 2024-02-29"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:2838819828&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">v Contents Abstract Declaration Acknowledgements List of Publications List of Figures List of Tables List of Algorithms List of Abbreviations 1 Introduction 1.1</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Computer System under the Scaling Law . . . . . . . . . . . . . . . . . . 1.2 Performance Engineering GPU Kernels . . . . . . . . . . . . . . . . . . . <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 69 in source list: http://www.lib.ncsu.edu/theses/available/etd-05152008-145809/unrestricted/etd.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=586773196&n=304&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">1.3 Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.4 Thesis Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Background 2.1</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 2.2 2.3 GPU and Computer System . . . . . . . . . . . . . . . . . . . . . . . . . . 2.1.1 Parallel Program Model . . . . . . . . . . . . . . . . . . . . . . . . <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 61 in source list: Submitted to Graz University of Technology on 2006-09-28"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:30506786&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">2.1.2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Hierarchical <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 61 in source list: Submitted to Graz University of Technology on 2006-09-28"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:30506786&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">Architecture . . . . . . . . . . . . . . . . . . . . . . . 2.1.3 Memory</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> and Cache System . . . . . . . . . . . . . . . . . . . . . . <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 61 in source list: Submitted to Graz University of Technology on 2006-09-28"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:30506786&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">2.1.4 Memory</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Ordering and Fences . . . . . . . . . . . . . . . . . . . . <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 61 in source list: Submitted to Graz University of Technology on 2006-09-28"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:30506786&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.1.5 GPU Thread Synchronization . . . . . . . . . . . . . . . . . . . . . 2.1.6 Position within OS Paradigm . . . . . . . . . . . . . . . . . . . . . Background and Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2.1 GPU and Networking: Scale-Up and Scale-Out . . . . . . . . . . . 2.2.2 Interconnects and NICs . . . . . . . . . . . . . . . . . . . . . . . . 2.2.3 Communication Kernels . . . . . . . . . . . . . . . . . . . . . . . . 2.2.4 Computation and Communication Overlapping . . . . . . . . . . Performance Engineering GPU Systems . . . . . . . . . . . . . . . . . . . 2.3.1 Profiling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 15 in source list: Submitted to University of Hong Kong on 2025-06-27"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3285974792&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">i i ii</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> iii ix <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 15 in source list: Submitted to University of Hong Kong on 2025-06-27"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3285974792&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">xiii xv xvii 1 1</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 2 <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 15 in source list: Submitted to University of Hong Kong on 2025-06-27"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3285974792&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">2 3 5 5 5</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 5 <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 15 in source list: Submitted to University of Hong Kong on 2025-06-27"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3285974792&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">6</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 6 <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 15 in source list: Submitted to University of Hong Kong on 2025-06-27"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=68.3394494684748&svr=18&lang=en_us&oid=oid:1:3285974792&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">7</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 8 8 8 9 9 10 11 11 2.3.2 Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 Neutrino 3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 Background and Design Choice . . . . . . . . . . . . . . . . . . . . . . . . 3.2.1 GPU Ecosystem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2.2 Assembly as a Probing Interface . . . . . . . . . . . . . . . . . . . 3.3 NEUTRINO Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.1 Programmable Probing Interface . . . . . . . . . . . . . . . . . . . 3.3.2 Virtualized Probe Execution Model . . . . . . . . . . . . . . . . . 3.3.3 Structured Map for Persistence . . . . . . . . . . . . . . . . . . . . 3.3.4 Verification for Security . . . . . . . . . . . . . . . . . . . . . . . . 3.4 NEUTRINO Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . 3.4.1 Hook Driver . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.4.2 Probe Engine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.4.3 Probe DSL and Compiler . . . . . . . . . . . . . . . . . . . . . . . 3.4.4 Utilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.4.5 Extending NEUTRINO to Other Platforms . . . . . . . . . . . . . . 3.4.6 Usage: Putting It All Together . . . . . . . . . . . . . . . . . . . . . 3.5 3.6 NEUTRINO Visualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . NEUTRINO Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.6.1 Correctness Validation . . . . . . . . . . . . . . . . . . . . . . . . . 3.6.2 Profiling Overhead . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.6.3 Extensive Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.7 3.8 3.9 Case Study with NEUTRINO Insights . . . . . . . . . . . . . . . . . . . . . Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.10 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 MECCL 4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2 Background and Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2.1 Algorithms and Protocols in Scale-Up CCLs . . . . . . . . . . . . 4.3 Theoretical Estimation for Communication Kernel’s Memory Behavior . 4.3.1 Communication Kernel Logic and Ideal Memory Traffic . . . . . 4.3.2 Synchronization Overhead . . . . . . . . . . . . . . . . . . . . . . 4.3.3 Cache Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.4 Practical Measurement of Memory Traffic in Communication Kernels . . 4.4.1 Environment Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.4.2 Measurement Tools for Communication Kernels . . . . . . . . . . 4.4.3 Synchronization and Latency . . . . . . . . . . . . . . . . . . . . . 4.4.4 Imbalance of Communication Channels . . . . . . . . . . . . . . . 4.4.5 Cache Efficiency . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 13 13 16 16 16 18 18 19 20 21 22 23 25 25 26 28 29 30 32 33 34 37 37 40 42 43 45 45 46 46 47 47 48 49 50 50 51 51 52 52 4.5 Performance Under the Communication-Computation Overlapping . . 4.5.1 Environment Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Conclusion and Future Works <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 64 in source list: Andrag, Walter H.. "Reinforcement learning for routing in communication networks", Stellenbosch : Stellenbosch University, 2003"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=2987172898&n=3788&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">5.1 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2.1</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Unrevealing GPU Scheduling . . . . . . . . . . . . . . . . . . . . . <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 64 in source list: Andrag, Walter H.. "Reinforcement learning for routing in communication networks", Stellenbosch : Stellenbosch University, 2003"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=2987172898&n=3788&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">5.2.2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Understanding GPU Sharing . . . . . . . . . . . . . . . . . . . . . 5.2.3 Incorporating More Hardware Advances . . . . . . . . . . . . . . 5.3 Vision: Towards a Unified Profiling Framework . . . . . . . . . . . . . . A NEUTRINO <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 5 in source list: https://arxiv.org/html/2509.10371v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=3690798481&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">Artifact Appendix A.1 Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Scope (<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 5 in source list: https://arxiv.org/html/2509.10371v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=3690798481&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">meta-information) . . . . . . . . . . . . . . . . . . . . . . . . . . . A.3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 5 in source list: https://arxiv.org/html/2509.10371v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=3690798481&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">A</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.4 Hosting and Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . Hardware Requirement . . . . . . . . . . . . . . . . . . . . . . . . Software Requirements . . . . . . . . . . . . . . . . . . . . . . . . Installation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.5 Evaluation Workflow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.5.1 Getting Started Instructions . . . . . . . . . . . . . . . . . . . . . . A.5.2 Expected Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.5.3 Further Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . A.5.4 Experiments Added in Shepherding . . . . . . . . . . . . . . . . . Bibliography 53 53 55 55 56 56 57 57 57 59 59 59 60 60 61 61 61 61 61 62 62 62 63 ix <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 94 in source list: https://backoffice.biblio.ugent.be/download/8716104/8716146"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=1820320536&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">List of Figures 2.1 GPU</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Networking Paradigm. ●<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 94 in source list: https://backoffice.biblio.ugent.be/download/8716104/8716146"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=1820320536&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">A</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Hierachical <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 94 in source list: https://backoffice.biblio.ugent.be/download/8716104/8716146"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=1820320536&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">GPU</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Network Overview, in- cluding Scale-Up and Scale-Out network; ●B Data path of Scale-Out Net- work includes two PCIe pass; ●C Data path of Scale-Up Network without PCIe involvement. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.1 NEUTRINO’s Densified Memory Access Timeline Plot. ●A NEUTRINO ex- pands new dimensions from previous ●B hardware-dependent profilers and ●C kernel-exclusive software profilers. Color depth in ●A shows den- sity from parallel threads, profiled from Flash-Attn-v2 [23] (non-causal). 3.2 Complex GPU Ecosystem divided in two branches AOT (left) and JIT (right) unified at parallel assembly layer. . . . . . . . . . . . . . . . . . . . 3.3 Parallel assembly example (PTX) with possible probing positions and corresponding functionalities. . . . . . . . . . . . . . . . . . . . . . . . . . 3.4 NEUTRINO programmable probing interface. Probes consist of snippet, tracepoint and structured map. Snippet can use helpers such as SAVE for storing values to NEUTRINO Map (§3.3.3). Multiple probes at different tracepoints can compose more comprehensive tasks like block_sched. . 3.5 NEUTRINO probe execution model. ●A Probes are executed virtually un- der time and resource (register and global memory) separation; ●B NEU- TRINO’s Probe Map for race-free and metadata-efficient persistence: Each thread finds its segment of map via its threadIdx and blockIdx. . . . . . 3.6 NEUTRINO verification against two unsafe operations: ●A overwrite orig- inal regs; ●B change execution flow. . . . . . . . . . . . . . . . . . . . . . . 3.7 NEUTRINO workflow. Entry loads and JIT compiles (§3.4.3) probes, and injects hook driver. Hook driver (§3.4.1) captures GPU workloads, in- vokes probe engine (§3.4.2), allocates probe buffers, launches probed kernel, and dumps results. . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.8 NEUTRINO hook driver infrastructure. Hook driver catches load and launch API for loading images and launching kernels on GPU, respec- tively. Hook driver maintains two hash-based [39] storage for image (up- per) to map kernel to binary image, and kernel (lower) to avoid repeated probing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 15 17 18 19 21 22 22 23 3.9 NEUTRINO probe engine workflow. Probe engine objdumps and prunes the binary, and finally reassembles it. In probing, it uses map defns to plan probe buffers and tracepoints to match instructions. It also fills helpers in snippets with tokens before injecting them into assemblies. . . . . . . . . 3.10 NEUTRINO Map planning mechanism. . . . . . . . . . . . . . . . . . . . . 3.11 NEUTRINO DSL probe and corresponding IR example. Each warp has 26 26 probe register, e.g., start, and saves a block_sched. . . . . . . . . . . . . 27 3.12 NEUTRINO Codegen Example for NVIDIA (PTX) and AMD (GCN) GPU. 27 3.13 NEUTRINO DMAT plot (captured on RTX3080, Appendix A) for differ- ent attention algorithms, which exhibit distinct memory access patterns. (a) differs from Fig. 3.1 with exclusive SM. By comparing the DMAT of different algorithms, we can visually identify the improvement of (b) FlashAttn-v1 [24] w.r.t. (c) Memory Efficient Attention [82] comes from I/O efficiency, while the gain of (a) FlashAttn-v2 (Fig. 3.1) comes from better pipelining, both consistent with their respective claims. . . . . . . 31 3.14 NEUTRINO DMAT aligned to the GPU-local clock. Left: The overview; Right: the Zoom-in view of selected small proportions highlighted in the red rectangles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 3.15 NEUTRINO Mirco-benchmarking example for verifying profiling accuracy. 33 3.16 NEUTRINO DMAT Slowdown versus kernels and sampling frequency. . 35 3.17 Max probe memory usage of NEUTRINO in profiling model forward. Probe memory usage is log-scaled to original memory usage ((labeled in purple). gmem_bytes and tensorop_count have the same map defini- tion and the same usage. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 3.18 Exposed latency comparison: NEUTRINO and Nsight Compute [69]. NEU- TRINO latency is decomposed into prologue (<1%), kernel and epilogue latency. ...................................... 36 3.19 ●A CDF of elapsed latency in exclusive blocks; ●B CDF of elapsed latency in shared blocks; ●C GFLOP/s distribution w.r.t. execution progress from left to right; ●D Progress timeline of shared blocks, with slope denoting speed. Every warp in shared blocks first experiences a slow stage (∼ 1.8 TFLOP/s) then jumps into a fast stage (∼ 2.2 TFLOP/s). . . . . . . . . . 38 3.20 ●A CDF of elapsed latency in exclusive blocks; ●B CDF of elapsed latency in shared blocks; ●C GFLOP/s distribution w.r.t. execution progress from 4.1 4.2 left to right; ●D Progress timeline of shared blocks. . . . . . . . . . . . . . 39 Communication Kernel Logic includes both network buffer and user buffer, and read (blue) and write (red) flow. ●A SendRecv and AlltoAll logic; ●B AllGather logic under ring algorithm, having 1x read and 3x write flow; ●C ReduceScatter logic under ring algorithm, having 2x read and 2x write flow. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Existing Communication Protocols in Scale-Up Network. . . . . . . . . . 47 49 4.3 Averaged Spins Count v.s. No.SMs Used and Network Bandwidth. Spins count increases exactly as the network bandwidth. . . . . . . . . . . . . 4.4 Spin counts distribution v.s. No.SMs Used. Noticed that the distribution is imbalanced with blocks of extremely high latency. . . . . . . . . . . . 4.5 LLC Hit Rate of Read and Write v.s. No.SMs Used. With more SMs used, the cache performance decreased dramatically. Simple protocol even have ≈ 0% hit rate for read and write. . . . . . . . . . . . . . . . . . 52 53 54 xiii List of Tables 3.1 NEUTRINO vs. other GPU Profilers. NEUTRINO is the only platform- independent runtime GPU kernel profiler and offers many unique fea- tures, e.g., the DMAT, programmability via Python DSL or TOML, coop- erative probes, eBPF-like maps, etc. PM stands for performance monitor, PC stands for program counter, and PRM stands for thread-local page reference map. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 3.3 DMAT micro-benchmark w.r.t. theoretical metrics. . . . . . . . . . . . . . Kernel slowdown and additional physical register usage of NEUTRINO: Kernel slowdown is normalized to original kernel latency and additional register usages are averaged based on assembler [73] debug informa- tion. NEUTRINO might lead to kernel speedup on lightweight probes, e.g., 0.9868x speedup of gmem_bytes on GEMM, and we discuss this abnor- mal effect in §3.8. dmat probe leads to different degrees of slowdown on different kernels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.4 Exposed stall cycles and reasons of FlashAttn-v2 under exclusive and shared blocks, collected from the Nsight Compute [69] PC Sampling. . . 4.1 4.2 16 34 35 40 Theoretical Model of Memory Traffic from the Communication Kernels. 50 Hardware configuration of the testbed used. L2, DRAM, Interconnect bandwidth are theoretical maximum values from vendors. . . . . . . . . 50 xv List of Algorithms xvii List of Abbreviations CPU GPU NPU SM CU XBAR MTU MC LSU LLC DRAM SRAM MMU PCIe NIC DMA RDMA CC IR DSL CNN LLM <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 73 in source list: https://patents.justia.com/patent/11467960"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=3888603481&n=3808&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">Central Processing Unit Graphics Processing Unit Neural Processing Unit</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Streaming <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 73 in source list: https://patents.justia.com/patent/11467960"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=3888603481&n=3808&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">Processor</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Computing Unit Crossbar Maximum Transaction Unit Memory Controller Load Store Unit Last Level <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 41 in source list: https://www.coursehero.com/file/63001382/g40docx/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=198175621&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">Cache Dynamic Random Access Memory Static Random Access Memory</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Memory Management Unit Peripheral Component Interconnectg express Network Interface Card Direct Memory Access Remote Direct Memory Access Congestion Control Intermediate Representation Domain Specific Language Convolutional Neural Network Large Language Model <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 42 in source list: https://www.coursehero.com/file/34861224/CHAPTER-1pdf/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=2130108552&n=3788&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">1 Chapter 1 Introduction 1.1 Computer System</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> under <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 42 in source list: https://www.coursehero.com/file/34861224/CHAPTER-1pdf/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=2130108552&n=3788&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Scaling Law As an effective approach for improving model performance towards artificial general intelligence, the scaling law on model parameters and computations has become the de-facto method in training and serving AI models. However, for computing systems, the scaling does not come with no cost. Bigger dataset means more disk to store, Larger model means more memory to hold, and more amount of compute used in training and inference means more powerful processors to use, leading to more advanced computer systems to be built, observed and optimized. In recent years, with model parameter size scaled to millions, developers have shifted their computing devices to GPUs, the heterogeneous and parallelism-oriented computing devices, rather than the traditional sequential-oriented CPU. For more com- puting power, GPU has made fundamental architectural tradeoffs, as compared with the CPU. For example, GPU groups 32/64 threads together to share one program counter (PC), formulating the unique <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 58 in source list: https://ece.northeastern.edu/groups/nucar/publications/Xiang_Gong_thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=902328234&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">Single-Instruction-Multiple-Thread (SIMT</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">) programming <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 58 in source list: https://ece.northeastern.edu/groups/nucar/publications/Xiang_Gong_thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=902328234&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">model</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, different from <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 58 in source list: https://ece.northeastern.edu/groups/nucar/publications/Xiang_Gong_thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=902328234&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Multi-Instruction-Multi-<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 58 in source list: https://ece.northeastern.edu/groups/nucar/publications/Xiang_Gong_thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=902328234&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">Thread</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> (MIMT) model used in CPU. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 101 in source list: https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/537004/dissertation-salvo.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=68.3394494684748&svr=18&lang=en_us&sid=889567407&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">It is worth noting that</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> the difference <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 101 in source list: https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/537004/dissertation-salvo.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=889567407&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">in</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> programming <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 101 in source list: https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/537004/dissertation-salvo.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=889567407&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">model</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> makes running <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 101 in source list: https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/537004/dissertation-salvo.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=889567407&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> operat- ing system, and lots of mature tech stacks on GPU, limiting the programmability and observability of GPU from the OS perspective. Nowadays, with model parameter size scaling up to billions or more beyond the physical limit of single GPU cards, communities and industries started to connect mul- tiple GPUs via hardware interconnects and communication kernels in software. These multi-GPU systems are mostly formulated in two level, the fast but small (mostly ≤ 8) scale-up network based on hardware interconnects like NvLink and the slow but large (even > 16384) scale-out network based on NICs and Switches like IB/RoCE. For the high bandwidth, hardware interconnects have made fundamental tradeoffs, as com- pared with de-facto networking centralized with NICs. Particularly, hardware inter- connects lacks the modeling of channels and corresponding designs, such as congestion control, and the measurement from the communication perspective. 2 Chapter 1. Introduction 1.2 Performance Engineering GPU Kernels This thesis focuses on the GPU kernels, the crucial part of code running on the GPU, rather than administrative code running on the CPU, an important yet little-studied topic in performance engineering. The heterogeneity from the OS and the parallelism- oriented design in the architecture poses significant challenges in observing its runtime behavior and optimizing its performance. This thesis targets the GPU kernel performance engineering from two particular perspective, the computing and communication kernels, as detailed as follows: • NEUTRINO, a Fine-grained and Programmable Interface for GPU Kernel Pro- filing: NEUTRINO leverages assembly-layer probing to achieve instruction-level fine granularity, profiling versatility across time and value domains, and hard- ware independence. To better visualize the rich details captured by NEUTRINO, we introduce the Densified Memory Access Timeline (DMAT), a novel represen- tation that offers new insights into GPU runtime behavior. We implement NEU- TRINO in Linux for both NVIDIA and AMD GPUs and conduct extensive evalu- ations and analyses. The results demonstrate NEUTRINO ’s superior capabilities in GPU kernel profiling with low overhead. • MECCL, a Measurement toolkit for Collective Communications and a Memory Efficient Communication Kernel Library for Scale-up Network and Commu- nication Computation Overlapping: Having the highest bandwidth per device of TB/s, the scale-up network built on hardware interconnects and communica- tion kernels suffers from contention in the GPU memory subsystem, particularly when computation kernels are co-located. We extend the NEUTRINO to observe the communication kernels and explores the inefficiency of existing communica- tion kernels like NCCL in memory system, e.g., in cache usage, spinning synchro- nization, and channel imbalance. Based on these observation, we are working on an optimized communication kernel libraries with better performance when colocating with computing kernels. 1.3 Contribution <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 50 in source list: https://escholarship.org/content/qt8vb1s8zz/qt8vb1s8zz.pdf?t=rpt73c"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2389033357&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">In summary, this</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> thesis <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 50 in source list: https://escholarship.org/content/qt8vb1s8zz/qt8vb1s8zz.pdf?t=rpt73c"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2389033357&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">makes the following</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> contribution: • NEUTRINO <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 50 in source list: https://escholarship.org/content/qt8vb1s8zz/qt8vb1s8zz.pdf?t=rpt73c"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2389033357&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">1. We present</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> an eBPF-like programming interface for GPU Kernel via Assem- bly (PTX/GCNAsm)-level probing, allowing clients injecting probes to ex- pose valuable runtime information like timestamp and providing eBPF-like Map for convenient, lock-free, metadata-efficient result persistence. 1.4. Thesis Organization 2. We implement a usable (Artifact Available, Functional, Reproducible) run- time probing framework with a hook driver to provide runtime support and a probe engine to instrument probes into assembly. 3. We extend the traditional Page Reference Map/String to Densified Memory Access Timeline (DMAT), introducing physical time to align access across threads, representing the access density across threads as color depth. We hope DMAT can help the community understand GPU kernel, visually. • MECCL 1. We present a theoretical framework to model the memory system behavior of communication kernel across multiple nodes. 2. We extend NEUTRINO to measure the memory performance of communica- tion kernels and identify the inefficiency in cache usage and spinning syn- chronization, which leads to the degraded performance when co-locating with computation kernels. 3. We are working on a memory efficient communication kernel library that optimize the performance of communication-computation overlapping in cutting-edge AI applications. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 21 in source list: Submitted to University of Hong Kong on 2023-02-23"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=88.2690813063473&svr=18&lang=en_us&oid=oid:1:2524211404&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">1.4 Thesis Organization The remainder of this thesis is organized as follows. Chapter 2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> presents <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 21 in source list: Submitted to University of Hong Kong on 2023-02-23"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=88.2690813063473&svr=18&lang=en_us&oid=oid:1:2524211404&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">more back- ground on</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 102 in source list: "Applied Parallel and Scientific Computing", Springer Science and Business Media LLC, 2013"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-642-36803-5', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">the GPU’s</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> program model, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 102 in source list: "Applied Parallel and Scientific Computing", Springer Science and Business Media LLC, 2013"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-642-36803-5', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">architecture, and its</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> position in <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 102 in source list: "Applied Parallel and Scientific Computing", Springer Science and Business Media LLC, 2013"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-642-36803-5', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> system and networking paradigm. Chapter 3 demonstrates the NEUTRINO, the fine-grained and programmable GPU kernel profiler from its design to case studies. Chapter 4 describes the MECCL, the memory-efficient communication kernel libraries, showcasing the ob- servation and proposed optimization. Chapter 5 concludes the thesis with in-depth discussion <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 55 in source list: https://theses.hal.science/tel-03420197v1/file/BEILLAHI_Sidi_Mohamed_va2.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=377816670&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">and future research directions. Chapter 2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Background <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 55 in source list: https://theses.hal.science/tel-03420197v1/file/BEILLAHI_Sidi_Mohamed_va2.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=377816670&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">2.1</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> GPU and Computer System 2.1.1 Parallel Program Model To accelerate computation under massive parallelism, GPUs employ a more simplified yet powerful Single-Instruction-Multiple-Thread (SIMT) program model, rather than CPU’s flexible but less powerful MIMT model. GPU’s SIMT model is centralized with the two-level thread indexing of threads (threadIdx) and blocks (blockIdx), to emu- late a specific thread and a group of concurrent threads. Moreover, to facilitate tensor indexing, these threadIdx and blockIdx are usually defined in three dimension like threadIdx.x/y/z. With the help of indexes, each thread can find their computation workload to execute simultaneously. To be compatible with the long-standing CPU codes, most GPU ecosystems, such as CUDA or ROCm, usually encapsulate the GPU code into a kernel function, mostly defined with __global__ decorator. These GPU codes will be compiled separately and launched via the drivers. Mostly only a kernel will be launched at a time, but driver could also launch kernels concurrently on different streams, similar to OS processes, to achieve better utilization. 2.1.2 Hierarchical Architecture As the thread and memory organization on GPU significantly varies from CPU for paral- lelism, we present some key differences between CPU and GPU below that are related to the following discussion. First, parallelism on GPUs is hierarchical: 32 or 641 threads are grouped into a warp, the scheduling unit of GPU, i.e., these threads share a single PC and must execute the same instruction at the same cycle. Warps are further grouped into blocks, the concurrent execution unit, i.e., threads in the same block are executed in one physical compute unit (CU)2 for communication and synchronization. Finally, 1NVIDIA GPUs group 32 threads into a warp, while AMD GPUs mostly group 64 threads into a wavefront (the different AMD’s name of warp). 2Vendors may use different names for <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 91 in source list: Tyler Sorensen, Lucas F. Salvador, Harmit Raval, Hugues Evrard, John Wickerson, Margaret Martonosi, Alastair F. Donaldson. "Specifying and testing GPU workgroup progress models", Proceedings of the ACM on Programming Languages, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3485508', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">compute unit, e.g</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">., SM (<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 91 in source list: Tyler Sorensen, Lucas F. Salvador, Harmit Raval, Hugues Evrard, John Wickerson, Margaret Martonosi, Alastair F. Donaldson. "Specifying and testing GPU workgroup progress models", Proceedings of the ACM on Programming Languages, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3485508', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">Streaming Multiprocessor</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">) for <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 91 in source list: Tyler Sorensen, Lucas F. Salvador, Harmit Raval, Hugues Evrard, John Wickerson, Margaret Martonosi, Alastair F. Donaldson. "Specifying and testing GPU workgroup progress models", Proceedings of the ACM on Programming Languages, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3485508', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">NVIDIA GPU</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> or EU (Execution Unit) for Intel GPU. Chapter 2. Background blocks are grouped into grids mapped to the same GPU, which is the management unit for host side, and the measurement unit for kernel-exclusive profilers [102]. Similarly, the GPU memory is also hierarchically organized. First, each thread holds private registers (RMEM, at most 255 32-bit regs per thread on A100) as a pri- mary resource. Blocks have CU-level shared memory (SMEM, at most 164KB on A100) as the temporary buffer for results and communications. Finally, there’s GPU-level global memory (GMEM, 80GB on A100) for grid-level synchronization and kernel in- put/output. 2.1.3 Memory and Cache System Similar to CPU, GPU also has <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 68 in source list: Ascia, G.. "Performance evaluation of efficient multi-objective evolutionary     algorithms for design space exploration of embedded computer systems", Applied Soft Computing Journal, 201101"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1016/j.asoc.2009.11.029', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">the processor-level L1 cache</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> (and shared <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 68 in source list: Ascia, G.. "Performance evaluation of efficient multi-objective evolutionary     algorithms for design space exploration of embedded computer systems", Applied Soft Computing Journal, 201101"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1016/j.asoc.2009.11.029', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">memory) and the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> device-level <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 68 in source list: Ascia, G.. "Performance evaluation of efficient multi-objective evolutionary     algorithms for design space exploration of embedded computer systems", Applied Soft Computing Journal, 201101"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1016/j.asoc.2009.11.029', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">L2 cache</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> before the <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 68 in source list: Ascia, G.. "Performance evaluation of efficient multi-objective evolutionary     algorithms for design space exploration of embedded computer systems", Applied Soft Computing Journal, 201101"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1016/j.asoc.2009.11.029', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">memory</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> controller (MC) and DRAM (HBM/GDDR). There are a set of interconnects, named corssbar (XBAR), between streaming processors (SMs) and the L2 cache in charge of dispatching memory requests and returning data. For each memory access, load store unit (LSU) in processor will issue a request to XBAR, who will direct it to the corresponding handlers, such as L1/L2 cache. Handlers buffer requests from different processors in an array and for each cycle, respond to ready requests and issue requests to underlying system, e.g., next-level cache, for non- ready requests. Under the default weak memory consistency model adopted by most GPUs (NVIDIA/AMD), handling of requests are based on the data availability without guarantees in orders, with options like strongly ordered memory requests or fences for particular needs of high consistency handling. To support DMA and RDMA, XBAR is also connected with external fabrics like the PCIe for communication with host, and the NvLink/InfiniteFabrics for cross-device communication. It is worth noting that different from CPU’s IOMMU that maps exter- nal memory requests into MC and bypass caches, GPU’s DMA is management by the XBAR (not MC) and is still cacheable by the L2 cache. 2.1.4 Memory Ordering and Fences With multi-thread programs getting complicated, maintaining the correctness and uni- formity of shared resources becomes challenging since wrapping all accesses in atomics leads to huge inefficiency. Memory ordering is therefore proposed to relax the atomic- ity but provides enough constraint to compilers and hardware for safe reordering. For example, the release ordering prevents all writings before from rearranging and execut- ing afterwards. Therefore, modification on multiple shared variables can be performed safely and efficiently (with one constrained instruction, rather than many atomics) to build complicated synchronization logic like the Barrier and CondVar in pthread. Though more efficient than atomics, memory ordering still incurs runtime costs, particularly for weak consistency machines like GPUs (NVIDIA/AMD), since fence instructions must be inserted in request buffers to ensure the ordering of handlers in 2.1. GPU and Computer System proceeding the requests. For example, a fence inserted in the buffer will postpone the handling of afterwards requests, leading to higher occupancy in the instruction plane and affecting the handlers’ efficiency. Moreover, for cache-enabled hardware, to main- tain the coherence, fences will leads to the invalidation of cache lines and prefetches, and more XBAR bandwidth usage to broadcast the updates. 2.1.5 GPU Thread Synchronization As the core of concurrency control in multi-threading program, synchronization are points that threads must be reached together to maintains the correct state or order for successive cooperation. Built upon the fundamental atomics, synchronization are usually presented in several semantic that can be further composed for high-level APIs, such as the Mutex Locks that preserves the mutual exclusion of critical regions, allowing <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 79 in source list: https://harmony.cs.cornell.edu/book/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2987847354&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">only one thread to execute at a time</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">; the Barrier <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 79 in source list: https://harmony.cs.cornell.edu/book/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2987847354&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">that</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> suspends the thread execution untill all threads in the group reaches the barrier, and wake up all threads since then for parallel execution; and the CondVar that supports the simple yet powerful wait and signal to synchronize between groups of threads programmably. These high-level APis, in general, are implemented in two major ways, i.e.the purely user space spinning including the original CAS, Ticket, MCS and qspinlock, and sleeping locks involving the kernel scheduler to suspend and wake up threads. Spinning can be fast in when the waiting time is small but could be inefficient or even ineffective [22] due to cache invalidation when the world size is large. Quite the oppo- site, sleeping lock is inefficient in small waiting time due to the two syscalls to invoke the kernel but is efficient for long waiting time and large world size. In the host OS, to provide a unified and powerful API like POSIX, typical imple- mentations like glibc’s NPTL MUSL’s thread, and Go’s sync library leverage the futex (Fast Userspace muTEX) syscall that adds a spinning checking before the mode switch for sleeping to automatically classify the fast spinning and the slow sleeping mode. In GPU, most synchronizations are conducted by the hardware primitives pro- vided by vendors, such as the the __syncthreads() that synchronize all threads within the block or the simplified __syncwarp() that synchronize within the warp. These prim- itives are usually exposed in the Barrier semantic and lacks the programmability from CondVars. Moreover, these primitives are restricted to the block level and cannot be easily extended to the device or even system level (multi-device) for more use cases. For these advanced usage, developers often need to handcraft the spinning loops in the the Compare-And-Swap (CAS) manner due to the lack of access to schedulers. This spinning is often simply done by a while loop to read a flag in local DRAM and compare with a pre-agreed value. Moreover, similar to other multi-threading program- ming on multiple shared objects, necessary memory ordering, such as explicit memory fences, shall be applied accordingly to enforce the reliability. 2.1.6 Position within OS Paradigm Positioned as an accelerator that communicates with the host OS via the driver, GPU programs are centralized with kernel functions, the entry for GPU computing whose content will be executed on the GPU while the rest of the program remains on the host CPU. Specifically, GPU kernel is considered atomic to the host OS, i.e., the exe- cution inside the kernel is managed by GPU hardware/firmware and is invisible and untouchable to the host OS, which prohibits observing GPU programs through mature OS technologies like ptrace or eBPF [28]. Apart from the host, profiling on GPU threads is also difficult as the systematic functionalities of GPU threads are highly limited. GPU programs are of direct execution without a management layer like the OS kernel. Particularly, there is no support for timer interrupts, a crucial feature for sampling-based profilers. Therefore, profiling techniques on traditional OSs, e.g., sampling and scanning the stack frame, are not applicable to GPUs. Moreover, there are no commonly supported disk I/Os, making it troublesome to save results. 2.2 Background and Scope 2.2.1 GPU and Networking: Scale-Up and Scale-Out Switch Switch Data Center Network PCIe PCIe Scale-Out GPU NIC GPU Network NIC 50~100GB/s NIC B A C NvLink GPU GPU GPU GPU GPU UALink GPU Scale-Up Network 300+GB/s Figure 2.1: GPU Networking Paradigm. ●A Hierachical GPU Network Overview, in- cluding Scale-Up and Scale-Out network; ●B Data path of Scale-Out Network includes two PCIe pass; ●C Data path of Scale-Up Network without PCIe involvement. As demonstrated in Fig. 2.1A, most GPU network systems are structured in a two- level layout: First, small amount of GPUs (usually 4 or 8) are connected with high speed hardware interconnects to formulate the Scale-Up network, similar to the local area net- work (LAN); Second, multiple Scale-Up networks (can be thousands) are connected with slower speed NICs and Switches to formulate the Scale-Out network, similar to the wide area network (WAN). In practice, the two-level structure fits in the parallelism need of deep learning model training and inference. The Scale-Up network, for its high bandwidth, is mostly used for the tensor parallelism and pipeline parallelism. While the Scale-Out network, 2.2. Background and Scope for its high capacity, is mostly used for the data parallelism and expert parallelism (for Mixture-Of-Expert models). 2.2.2 Interconnects and NICs The biggest difference between Scale-Up and Scale-Out networks is the method of com- munication that leads to the divergence in bandwidths, semantics, and infrastructures. As demonstrated in fig 2.1B, Scale-Out networks leverages the NICs and Switches, mostly made by Optics, to formulate a high capacity Ethernet, with industrial solutions like InfiniBand (IB) or RDMA over Converged Ethernet (RoCE). It is worth noting that in Scale-Out network, data to transfer need to be sent to and received from the NICs through system interconnects like PCIe for networking. Therefore, the bandwidth are strictly bounded by the PCIe protocol, which mostly, is 50GB/s. Moreover, since NICs are used, the native semantic of Scale-Out network is the send and receive of packets in the size of MTU like 4096 bytes (InfiniteBand). Similarly, Scale-Out networks can be monitored by mature network techstacks with profiles read from NICs and Switches performance monitor units. Based on these profiles, communities has adopted many wisdom from data center networking to the Scale-Out setup, such as the Contention, etc. Scale-Up networks simplify the data transmission by replacing the GPU->PCIe- >NIC->PCIe->GPU data path with the GPU->Interconnect->GPU (fig 2.1C), further accelerating the networking bandwidth to 100+GB/s or even TB/s, far beyond the limitation of the PCIe protocol. These hardware interconnects, such as NvLink and AMD’s InfiniteFabrics, are made by Coppers in the way of extended on-chip networks between cores and memories. Therefore, the native semantic of Scale-Up network is the memory’s load and store of addresses of at most 128 bytes (NvLink). Since NICs and Switches are optimized out, Scale-Up networks can not be profiled with the network tech stack. Till now, the community knows very little about its runtime behavior and the optimization of Scale-Up network performance, therefore, is very limited. In MECCL, we mainly focuses on the Scale-Up network, rather than the Scale- Out network, mainly for three reasons: ❶ Scale-up network has the highest bandwidth (300+GB/s) per connection in the communication paradigm, compared with ≈ 50GB/s Scale-Out network, leading to more significant contention; ❷ Scale-up network limits all network traffic in the GPU domain with no host incorporation, helping us sort out the impact of host configuration like CPU, DRAM, PCIe speed; ❸ Scale-Up network is little studied by the community. Therefore, the profiling tools and the measurements poses significant research contribution to the community. 2.2.3 Communication Kernels To bridge the gap between varying underlying network mechanism sand different se- tups, communities have developed many communication kernels to provide API for developers to incorporate in training and inference. There are two widely applied sets of communication kernels, namely the Shared Memory Access (SHMEM) and the Col- lective Communication Library (CCL). SHMEM [18] originates from the shared memory access in operating system that exposes a region of memory shared by multiple processes. Therefore, multiple pro- cesses can exchange data by reading and writing the shared memory as a mean for inter-process communication (IPC). In GPU networking setup, SHMEM allows each GPU to register memories of the same size as symmetric memory, so that others could read and write with rank specified if direct memory access (DMA) is available. To facilitate this, solutions like NVSHMEM [70], rocSHMEM [9], iSHMEM [16] provides fundamental put/get API and necessary synchronizations like signal/wait. Another more mature sets of communication kernels is the Collective Commu- nications that originates from the MPI collectives, which defines many useful primi- tives for multi-process cooperation, such as broadcast that distributes the data to ev- ery rank. These primitives has been proven effective in emerging AI systems, such as the broadcast/reduce used in data parallelism, allreduce used in tensor parallelism, and alltoall used in expert parallelism. Therefore, communities has put best efforts to optimize the collectives, such as the NCCL [68], UCCL [117], MSCCL [88], etc. In MECCL, we mainly focuses on the collective communication (CCL), mainly for two reasons: ❶ CCLs are more well-defined than SHMEM, providing definite commu- nications kernels rather than programmable APIs, making the study more conclusive; ❷ CCLs are more widely used in Scale-Up network. SHMEM are more widely used in Scale-Out network with routed DMA capability provided by PCIe, and could be troublesome in Scale-Up network without full P2P connectivity. 2.2.4 Computation and Communication Overlapping From the computing perspective, communications are often treated as wasted I/O stalls that shall be parallelized with computation as much as possible. This idea orig- inates from the observation that communication kernels uses different hardware re- sources (Interconnects) than the computation kernels (SMs or Cores), and therefore, can be co-located for better resource efficiency. Many research efforts has been put to make this idea an established wisdom in machine learning system. For example, in training, researchers make backward gradient broadcasts in parallel to forward com- putation to minimize the stalls. And in the inference system, embedding exchanges are often pipelined with the attention or MLP computation. This computation-communication overlapping can be conducted explicitly by launch- ing two kernels on two streams for concurrent execution, such as GPipe, and can also be implicit by fusing the communication into the computing kernels, which poses new opportunities to reduce the kernel launch cost. 2.3. Performance Engineering GPU Systems In addition to the proposed algorithms, there are also works for automated finding of overlapping opportunities, such as the Alpa that fuses based on patterns and parti- tioning, and the Centauri that use computation graph for better overlapping. In sum- mary, the computation-communication overlapping has become an established wis- dom and wide applied optimization in the emerging AI systems. 2.3 Performance Engineering GPU Systems 2.3.1 Profiling Profiling builds the roadmap for GPU Performance Engineering. In general, profiling are usually performed in two major approaches, namely sampling and tracing. Sampling, in profiling, envisions a background handler that would be invoked at a fixed interval to sample and scan the performance metrics. These background handlers can be added in programming languages like Python’s cProfile, operating systems like Linux’s top, or even hardware performance units such as Intel’s PM/PC Sampling [43, 98, 22]. Sampling-based profiling could be of low overhead, particularly if a free CPU core is available, but with less granularity under low sampling rate. Tracing, instead, envisions adding some code to the original program that collects the performance metric directly from running the code. Tracing probes can be attached in programming languages like Valgrind [87] or in operating systems like eBPF [28]. Compared with sampling, tracing can be more flexible as probes can be attached only to desired point but is less performant as compared with the sampling. It is worth noting that different from CPU profiling [22, 14] emphasizing sequential execution efficiency like branch prediction, GPU profiling prioritizes parallel execution scalability like compute unit utilization and throughput. Taking memory access as an example, CPU profiling cares about temporal locality like the working set [26], while GPU profiling focuses more on coalescing access among threads to utilize the band- width, opening unique challenges and research opportunities. 2.3.2 Optimization With the help of profiling to diagnosing the performance issues, optimizations can be applied to enhance the system performance. For GPU systems, the performance issue could be any, but mostly in the host-device interaction, memory, and pipelining. Synchronization with the host is mgenerally considered harmful because it forces the device to be idle until the host launches new kernels, leading to low utilization rate, particularly given that GPUs are getting far more powerful than CPUs nowadays. To address this, communities has developed the CUDA/ROCm Graph to record and replay kernels on the host side to reduce the costs. Memory access is the most crucial parts in GPU kernels performance, since it could take ≥ 100 cycles to load the data that would be consumed by cores in ≤ 10 cycles. To address this, architects and developers designed multi-level cache systems to accelerate the memory access based on the locality. Pipelining becomes more important on emerging AI systems since the relentless pursuit for speed has exceeded the capacity of GPU’s SIMT model. Therefore, more domain-specific architectures (DSA), such as tensor cores, has been added to new GPUs and more computation are diverged from the thread execution, making the GPUs more asynchronous than ever. Thus, how to schedule those DSAs into performant pipelines becomes the emerging performance problem for developers. Chapter 3 Neutrino 3.1 Introduction With the emergence of artificial intelligence under the scaling laws [49] in data, param- eters, and computation, the underlying computer systems have been scaling rapidly, primarily driven by GPUs, parallelism-oriented computing devices that are heteroge- neous from the traditional OS running on CPUs. The huge system scale and the unique parallelism-oriented design open many research challenges on GPU systems, such as communication [19, 79, 83, 44], memory efficiency [51, 92], computation pipelining [89, 75, 54, 42, 77], and GPU cluster scheduling [114, 55, 45, 4, 61]. To address these challenges, researchers would greatly benefit from comprehensive measurements and in-depth insights into the runtime behavior of real workloads on GPU systems. De- mystifying the otherwise opaque GPU programs can promise new opportunities for optimizing machine learning (ML) systems. However, profiling real GPU workloads at a fine granularity has been well recog- nized as a significant challenge from previous attempts [64, 6, 8, 69, 27, 108]: ❶ The proprietary and heterogeneous hardware, coupled with the huge system scales (e.g., 10,000+ cores), limits the capability to probe fine-grained information. ❷ GPU ker- nels are treated as atomic to the host OS, which largely prevents profiling GPU kernels through the mature OS profiling techniques [28]. ❸ Many profilers [14, 22, 59, 87, 17] rely on concurrency mechanisms like timer interrupts and locks, which are either un- supported or inefficient on GPUs due to the parallelism-oriented architecture. These challenges are further amplified by the rapid development of GPU systems with many new features introduced over the past few decades, such as matrix core [1, 86] in execution model and asynchronous copy [2] for memory access, which continu- ously introduce new runtime behaviors, performance issues, and profiling needs. These unique challenges make existing GPU profilers either kernel-exclusive [102], only capturing coarse-grained metrics like FLOP/s, or hardware-dependent [64, 6, 8, 69], relying on physical hardware features such as Performance Monitor (PM) counters, as shown in Tab. 3.1. Additionally, these hardware profilers are sampling-based: They use hardware counter readings at certain intervals to capture statistics such as memory Chapter 3. Neutrino throughput, and cannot support more informative profiles like the page reference map [26] for capturing the <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 93 in source list: https://amsdottorato.unibo.it/id/eprint/11919/1/ficarelli.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2949624188&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">spatial and temporal</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> patterns <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 93 in source list: https://amsdottorato.unibo.it/id/eprint/11919/1/ficarelli.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2949624188&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">of memory</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> access. There <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 93 in source list: https://amsdottorato.unibo.it/id/eprint/11919/1/ficarelli.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2949624188&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">are</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> also explorations <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 93 in source list: https://amsdottorato.unibo.it/id/eprint/11919/1/ficarelli.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=2949624188&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">on GPU</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> instrumentation [96, 94, 15, 91], such as NvBit [108] that manip- ulates proprietary machine code or HIPAnalyzer [25] that instruments compilers [52]. Yet these efforts still only focus on statistics such as memory access divergence among threads or reusable distance. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 48 in source list: https://dspace.cuni.cz/bitstream/handle/20.500.11956/83719/140052848.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=1024265251&n=3722&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">To the best of our knowledge, there</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> exist <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 48 in source list: https://dspace.cuni.cz/bitstream/handle/20.500.11956/83719/140052848.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=1024265251&n=3722&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">no tools</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> for <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 48 in source list: https://dspace.cuni.cz/bitstream/handle/20.500.11956/83719/140052848.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=1024265251&n=3722&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">a</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> fine-grained and general-purpose programmable interface of GPU profiling, just like eBPF [28] for Linux Kernel tracing. To bridge this gap, we present NEUTRINO, a GPU assembly probing tool for fine- grained, versatile, and programmable GPU kernel runtime profiling. Inspired by eBPF [28], NEUTRINO’s design aims to attach small snippets (probes) to GPU programs to expose runtime details of program executions. Specifically, NEUTRINO extracts, instru- ments, and reassembles GPU assemblies [72, 5, 34], rather than machine code [66] or compilers [52, 53], allowing fine-granularity, versatility, and programmability in one framework: ■ Fine-granularity: NEUTRINO directly works on assemblies, the lowest software level, to offer the finest granularity at the instruction level <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">that can be</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> effectively <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.2690813063473&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">mapped to particular hardware units</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> such as tensor cores and memory I/Os. ■ Versatility: NEUTRINO supports GPU kernel profiling from both perspectives of value, i.e., capturing runtime values such as memory addresses and of time, i.e., record- ing event timestamps or even intra-kernel micro-benchmarking by differencing times- tamps. By covering these two dimensions, NEUTRINO supports versatile profiling tasks from warp/block scheduling to memory access patterns. ■ Programmability: NEUTRINO extends the programmability of previous GPU instru- mentation frameworks [108, 96, 94, 15, 91, 25] to cooperative probes by leveraging reg- isters as the temporal storage between probes. By doing so, NEUTRINO enables more complicated and flexible profiling tasks by cooperating probes at different tracepoints and time. NEUTRINO excels with its distinct probe design (§3.3) of three key components, namely snippet, tracepoint, and structured map, corresponding to the probe’s target functionality, injection point, and output format, respectively. At runtime, NEUTRINO probes will be injected into tracepoints of the original program, and snippets use log- ically independent registers to place temporal results. This design, together with the GPU SIMT model, ensures the probes are virtual to the original program. Moreover, with eBPF-like structured maps, NEUTRINO probes can flexibly store metrics to one or more buffers via race-free saving without costly metadata. We fully implement (§3.4) NEUTRINO for NVIDIA GPUs with the CUDA driver and AMD GPUs with the ROCm driver on Linux, consisting of three modules: the DSL compiler, the hook driver, and the probe engine. The DSL compiler compiles 3.1. Introduction Figure 3.1: NEUTRINO’s Densified Memory Access Timeline Plot. ●A NEUTRINO ex- pands new dimensions from previous ●B hardware-dependent profilers and ●C kernel- exclusive software profilers. Color depth in ●A shows density from parallel threads, profiled from Flash-Attn-v2 [23] (non-causal). probes written in platform-independent Python Tracing DSL into raw low-level as- sembly probes wrapped in TOML [81]. The hook driver emulates symbolic links to the driver (shared library) to provide runtime support, including capturing GPU calls from the user, allocating probe maps, and saving results to the storage. The core probe en- gine validates, instruments, and reassembles the probed assembly code from wrapped low-level probes. Finally, NEUTRINO is encapsulated into an easy-to-use CLI similar to bpftrace [41] that can be run by neutrino -p <probe> <user/program>. To better visualize the traces captured by NEUTRINO, we introduce a novel plot named Densified Memory Access Timeline (DMAT, §3.5), which improves the previ- ous page reference map (strings) [26, 13] with physical time information and memory access density from parallelism. As illustrated in Fig. 3.1, DMAT expands new di- mensions of observability compared with hardware-dependent profilers (Fig. 3.1B) and kernel-exclusive software profilers (Fig. 3.1C), enabling more comprehensive and intu- itive GPU runtime analysis. For example, by comparing their DMAT profiles (Fig. 3.13), we can visually and quantitatively confirm that FlashAttn-v1 [24] improves memory efficiency and that FlashAttn-v2 [23] benefits from better pipelining. We perform comprehensive evaluations (§3.6) to validate the trustworthiness, over- head, and applicability of NEUTRINO on profiling real GPU workloads. The results demonstrate that NEUTRINO ensures both execution correctness, i.e., probing will not change the original execution flow, and profiling accuracy, i.e., profiles are trustworthy. It also yields low overhead in both kernel slowdown (only 1.04x for most probes) and additional register usage (on average 4.11 more registers) Moreover, our extensive eval- uations spotlight high system efficiency compared to other profilers and the capability to profile the whole model, even for LLMs. To showcase how NEUTRINO-profiled in- sights can help diagnose performance issues in GPU kernels, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">we conduct a case study</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> (§3.7) <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">on the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> impact <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> synchronization on GPU runtime behavior, which reveals an unnoticed tailing effect of shared GPU blocks on one compute unit and helps pinpoint different root causes of the performance bottlenecks. NEUTRINO currently has limitations inherent to assembly-level probing, such as the inability to access unprogrammable hardware like caches. Nonetheless, as a fine- grained, versatile, and programmable framework for GPU kernel profiling, we envi- sion NEUTRINO as a valuable tool for both research and industry communities. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 57 in source list: Cong Guo, Rui Zhang, Jiale Xu, Jingwen Leng, Zihan Liu, Ziyu Huang, Minyi Guo, Hao Wu, Shouren Zhao, Junping Zhao, Ke Zhang. "GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching", Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, 2024"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3620665.3640423', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">We have</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> fully <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 57 in source list: Cong Guo, Rui Zhang, Jiale Xu, Jingwen Leng, Zihan Liu, Ziyu Huang, Minyi Guo, Hao Wu, Shouren Zhao, Junping Zhao, Ke Zhang. "GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching", Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, 2024"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3620665.3640423', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">open-sourced</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> NEUTRINO <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 57 in source list: Cong Guo, Rui Zhang, Jiale Xu, Jingwen Leng, Zihan Liu, Ziyu Huang, Minyi Guo, Hao Wu, Shouren Zhao, Junping Zhao, Ke Zhang. "GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching", Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, 2024"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3620665.3640423', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">at https://github.com</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/open-neutrino/neutrino, and hope to foster a global community for its continuous development. Design Fine-Granularity Versatility Programmability Platform Target Grid Block Thread Instructions Value(Register) Time(Clock) Memory Programmable Persistence Cooperativeness Verification Neutrino NVIDIA/AMD... assembly Nsight Compute [69] ✓ NVIDIA unclear ✓ NvBit [108] NVIDIA machine code ✓ GTPin [94] Intel machine code HIPAnlyzer [25] ✓ AMD compiler ✓ CUPTI [64] NVIDIA - ✓ RGP/GPA [8] AMD - ✓ torch.profiler [102] Independent - - Instrumentation-based GPU Kernel Profilers ✓ ✓ ✓ ✓ ✓ ✓ statistics PC Sample ✓ ✓ ✓ ✓ statistics ✓ - ✓ ✓ ✓ - basic-block ✓ ✓ ✓ - basic-block Hardware-based GPU System Profilers ✓ ✓ - DMAT DSL/TOML - - PRM C++ PRM C++ PRM LLVM - PC <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 77 in source list: Simin Peng, Tianzhu Huang, Yali Peng, Pengfei Zhang, Luyan Liao, Weiguo Wu. "Combining GC-MS and chemometrics to assess the quality of camellia seed oils", CyTA - Journal of Food, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1080/19476337.2021.1933196', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">Sample - PC Sample</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> PM <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 77 in source list: Simin Peng, Tianzhu Huang, Yali Peng, Pengfei Zhang, Luyan Liao, Weiguo Wu. "Combining GC-MS and chemometrics to assess the quality of camellia seed oils", CyTA - Journal of Food, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1080/19476337.2021.1933196', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">Sample - - PC Sample - PC Sample</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> PM <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 77 in source list: Simin Peng, Tianzhu Huang, Yali Peng, Pengfei Zhang, Luyan Liao, Weiguo Wu. "Combining GC-MS and chemometrics to assess the quality of camellia seed oils", CyTA - Journal of Food, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1080/19476337.2021.1933196', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">Sample</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> - CPU-side Software-based Profilers and Benchmarkers - - - - - eBPF-like Map ✓ unknown - atomic - atomic - event buffer - - - - - - - ✓ - - - - - - - Table 3.1: NEUTRINO vs. other GPU Profilers. NEUTRINO is the only platform- independent runtime GPU kernel profiler and offers many unique features, e.g., the DMAT, programmability via Python DSL or TOML, cooperative probes, eBPF-like maps, etc. PM stands for performance monitor, PC stands for program counter, and PRM stands for thread-local page reference map. 3.2 Background and Design Choice 3.2.1 GPU Ecosystem In modern computer systems, GPU has become a general-purpose computing unit (GPGPU) backed by a huge and complicated ecosystem covering numerous computing tasks, such as deep learning training [10, 31, 93] and inference [74, 111, 80]. However, from the perspective of compilation, the complicated ecosystem can roughly be divided into two branches: ❶ Ahead-of-Time (AOT) compiled operator libraries of hand-written codes [62] compiled by C++ compilers [63, 7], e.g., ATen [10]; ❷ Just-in-Time (JIT) com- piled domain-specific languages (DSLs) such as triton [106] compiled by LLVM [52] / MLIR [53]. As shown in Fig. 3.2, these two branches diverge only above the parallel assembly. Consequently, to build a general-purpose profiler, it has to be on or below the parallel assembly layer. 3.2.2 Assembly as a Probing Interface The unique characteristics of GPU programming pose great challenges in building NEUTRINO, a fine-grained, versatile, and programmable GPU profiling tool that is kernel-inclusive and hardware-independent. The key question we need to answer is: at 3.2. Background and Design Choice Figure 3.2: Complex GPU Ecosystem divided in two branches AOT (left) and JIT (right) unified at parallel assembly layer. which layer should NEUTRINO be built and how? In this paper, among all the choices in Fig. 3.2, we choose the parallel assembly, such as PTX/GCNAsm [72, 5] designed to adapt to rapid changes in system and machine code, as the probing interface. Im- portantly, instead of static approaches, such as customizing profiling passes [25] via compilers or naive asm() in C, we employ a more capable but challenging approach, attaching probe(s) at runtime, which minimizes usage overhead (e.g., recompiling) for changing or enabling/disabling probes. This design choice not only allows forward- and backward-compatibility, but also promises distinct advantages in various aspects: ❶ Hardware-Oriented: As a low-level interface, assemblies can capture hardware events that are important for performance analysis but hard to track with high-level languages. For example, there are only four related instructions in PTX for memory access, i.e., ld, st, cp.async, and tensormap. In contrast, with objects and templates in CUDA C++, it is difficult to classify and capture all possible memory access. ❷ Special Registers / Instructions: Special registers of parallel assemblies contain use- ful runtime information for profiling. For instance, hwreg of GCNAsm tells which com- pute unit the thread is scheduled on, while PTX’s special registers %clock (in CU-local clock cycles) and %globaltimer (in GPU-local nanoseconds) are helpful to measure the timestamp and can be used as instruction-level timers as shown in Fig. 3.3. ❸ Compatibility: As shown in Fig. 3.2, parallel assemblies are the highest common layers of the AOT and JIT compilations. For example, PTX is the common output of CUDA C++ compiled by gcc-based nvcc [63] and DSLs, e.g., Triton backed by LLVM [101]. Thus, probing on assemblies can be compatible with most infrastructures, while compiler-based approaches are limited to the specific compiler or IR(s). ❹ Coverage: Compiler-based approaches require source code, assuming that users have located the poor-performing GPU kernel, which is uncommon as most programs Figure 3.3: Parallel assembly example (PTX) with possible probing positions and cor- responding functionalities. have many kernels. Instead, runtime approaches can cover all user codes, capable of scanning poor-performing kernels. The design choice of assembly-layer runtime probing also poses unique challenges, such as securing probes without compiler support, locating GPU code in the runtime, obtaining high-level contexts, etc. We overcome these challenges in NEUTRINO and enable it as a powerful GPU profiler. 3.3 NEUTRINO Design NEUTRINO aims to formulate a simple yet powerful probe design like eBPF probe [28] to profile GPU kernels with the finest granularity to capture instructions, versatility to cover time- and value-profiling, and programmability for users to customize probe(s). Due to the massive parallelism of GPUs, NEUTRINO targets lightweight probes that only operate at tracepoints with the least disturbance to the remaining. 3.3.1 Programmable Probing Interface As shown in Fig. 3.4, NEUTRINO features three key elements in its probe design: snip- pet, tracepoint, and structured map: 3.3. NEUTRINO Design Figure 3.4: NEUTRINO programmable probing interface. Probes consist of snippet, tracepoint and structured map. Snippet can use helpers such as SAVE for storing values to NEUTRINO Map (§3.3.3). Multiple probes at different tracepoints can compose more comprehensive tasks like block_sched. Snippet: Same as the probing target, NEUTRINO’s snippet is assemblies, with some helpers such as SAVE for logging results and OUT/IN1/IN2 for reading registers (instruc- tion operands) for value profiling. Developers can also use other assembly features, especially S_MEMTIME for time profiling. Tracepoint: NEUTRINO formulates probe tracepoints primarily at the finest instruc- tion level, which assures both temporal accuracy and hardware granularity such as wmma/mma for tensor core operation. By grouping instructions, NEUTRINO’s tracepoints can be extended to larger scales such as device function calls and thread start/end. Map: Similar to eBPF [57], NEUTRINO’s map explicitly structures the saving format to address the problem of persistence, a troublesome issue on GPU due to race condi- tions from parallelism and huge metadata from hierarchical organization. NEUTRINO mainly defines maps at two levels (§3.3.3): ❶ thread-level: every thread saves, for value profiling; ❷ warp-level: only warp leader thread saves, for time profiling. Beyond the three components for formulating customizable probes, the key de- sign of NEUTRINO’s programmability is cooperativeness: ❶ NEUTRINO probes of the same thread can cooperate by leveraging registers as temporal storage for advanced profiling tasks while maintaining efficiency as register usage is parallel in GPU cores. ❷ NEUTRINO probes can also cooperate with maps in GMEM, i.e., different probes can contribute to and cooperate through the same map. 3.3.2 Virtualized Probe Execution Model Since the GPU program is static to the OS, i.e., all code (assembly) is loaded and known before execution, we choose to directly place probes in the original assembly without protection, e.g., stack, to achieve cooperativeness. We identify that by doing so, NEU- TRINO probes are still executed virtually from the original program. As shown in Fig. 3.5A, such virtualization is achieved via time and resource separation: Time Separation: The time virtualization of NEUTRINO originates from the SIMT ex- ecution model of GPGPU, where parallelism happens among threads while execution within a thread is generally sequential with one instruction at a cycle. Thus, as probes are directly inserted into assemblies, their time separation from the original program will be guaranteed. Resource Separation: Similar to CPU, GPU threads also have thread-private registers as their primary resources, which contain intermediate results from ALU, addresses of shared or global memories, etc. NEUTRINO virtualizes the probe registers by separating an independent register group, as well as other resources like GMEM. Thus, NEUTRINO probes can avoid affecting the original program’s resources, and the execution flow. It is worth noting that NEUTRINO’s probe register group is declared logically at the as- sembly level rather than physically. Therefore, NEUTRINO may not necessarily intro- duce extra physical register usage (Tab. 3.3) because the declared logical registers will be integrated into physical registers by the assembler in register allocation, with inde- pendence between probes and the original program preserved by dependency tracking algorithms [85, 47]. 3.3.3 Structured Map for Persistence Persistence is a critical challenge for GPU profiling. Although thread executions are parallel and independent, the underlying memory system is shared, leading to race conditions among concurrent savings. Thus, previous solutions [108, 94] widely use atomics for separating persistence spaces, which can become inefficient under massive parallelism. Moreover, the GPU hierarchical organization creates rich metadata such as threadIdx and blockIdx (24 bytes), which is informative for analysis but can be storage- hungry [108]. Inspired by the design of lock-free per-cpu eBPF maps [57] and event buffers of HIPAnalyzer [25], we explicitly structure NEUTRINO map to an ndarray layout, as shown in Fig. 3.5B, with the shape determined by launch configurations (blockDim, gridDim) and the map definitions (level, type, size, cap). This enables race-free saving as each thread has an independent segment and reduces storage pressure as most meta- data can be inferred rather than directly saved. NEUTRINO mainly formulates maps at two levels: Thread-Level: The thread-level map is mainly designed for value profiling where every thread independently saves data. Its layout is in the form of [#Grid, #Block, cap] and each element is of size. #Grid and #Block can be inferred by launch config gridDim and blockDim, respectively. cap specifies the maximum number of savings per thread, 3.3. NEUTRINO Design Figure 3.5: NEUTRINO probe execution model. ●A Probes are executed virtually under time and resource (register and global memory) separation; ●B NEUTRINO’s Probe Map for race-free and metadata-efficient persistence: Each thread finds its segment of map via its threadIdx and blockIdx. which can be set to a suitable value, or measured dynamically by running a counter probe1 in the runtime. Warp-Level: The warp-level map simplifies the thread-level map for time profiling with layout [#Grid, #Warp, cap]. Because threads within the same warp are scheduled together for the same instruction, recording event timestamp only needs one thread inside the warp other than all, which can reduce the memory and storage pressure. Based on these two levels, NEUTRINO can extend different types of maps, such as the array, or advanced ring (ring buffer) and hash to support versatile user needs. 3.3.4 Verification for Security Verification [32, 99] has been proven vital for programmable probes [28] as unsafe probes can break the execution flow of the original program and invalidate the pro- filing. The verifier can also help guide developers in writing correct probes. In NEU- TRINO, we identify and prevent three key security issues: Overwrite Original Registers: As discussed in §3.3.2, GPU threads use registers as primary resources. Thus, modifications of registers used by the original program are unsafe. For example, modifying a register holding address to global memory could lead to illegal memory access (Fig. 3.6A). Thus, NEUTRINO requires probes to use in- dependent register groups, and prohibit probes that modify original registers. Program Misorder: Although the SIMT program model guarantees that instructions within the thread are executed linearly, there are flow control instructions, such as S_BRANCH (GCNAsm) or bra (PTX), that may change the execution order, which are 1A probe of count+=1 attached at tracepoints, and after execution, the value of count can be regarded as cap (only applies to pure kernel functions). Figure 3.6: NEUTRINO verification against two unsafe operations: ●A overwrite original regs; ●B change execution flow. Figure 3.7: NEUTRINO workflow. Entry loads and JIT compiles (§3.4.3) probes, and in- jects hook driver. Hook driver (§3.4.1) captures GPU workloads, invokes probe engine (§3.4.2), allocates probe buffers, launches probed kernel, and dumps results. unsafe for probes as they may break the original execution order (Fig. 3.6B). Thus, NEUTRINO prohibits probes from instructions that change the execution flow. Shared Memory: As an important factor for acceleration, the shared memory has been highly optimized for storage [20, 106] and access efficiency [104]. Thus, additional shared memory usage from the probes may greatly affect or fail the execution if the original usage is already at the hardware limit. Thus, NEUTRINO prohibits probes from using shared memory. 3.4 NEUTRINO Implementation We implement NEUTRINO in Linux for NVIDIA GPU with CUDA driver and AMD GPU with ROCm/HIP runtime. Our implementation consists of three major com- ponents: ❶ a hook driver (§3.4.1, ≈2,500 lines of C code) to provide runtime sup- port for assembly tracking, code caching, etc; ❷ a probe engine (§3.4.2, ≈2,000 lines of Python code) to instrument parallel assemblies; ❸ a DSL compiler (§3.4.3, ≈1,000 lines of Python code) to translate probes in platform-agnostic Python Tracing DSL into platform-specific assemblies (PTX for CUDA and GCNAsm for ROCm/HIP). We im- plement the core probing engine and the DSL compiler in Python to make the infras- tructure more approachable and extensible for developers. Besides, we also provide utilities (§3.4.4), such as ecosystem integrations, analysis code generations, etc. 3.4. NEUTRINO Implementation Figure 3.8: NEUTRINO hook driver infrastructure. Hook driver catches load and launch API for loading images and launching kernels on GPU, respectively. Hook driver main- tains two hash-based [39] storage for image (upper) to map kernel to binary image, and kernel (lower) to avoid repeated probing. Finally, we wrap these modules as a command-line interface similar to bpftrace [41] and valgrind [87]. As shown in Fig. 3.7, when a user invokes neutrino with the probe dmat via -p/–probe argument, the entry will load, compile, and verify the probe (.py) into platform-specific assembly (.asm) wrapped in TOML [81]. Then the entry will set environment variables, such as NEUTRINO_PROBE for probe contents and the special LD_PRELOAD to inject the hook driver, and fork a child process to launch the workload. Throughout the execution, the hook driver will continuously capture the GPU work- load, particularly the GPU kernels launched. For each uncached GPU kernel, the hook driver will invoke the probe engine, which objdump, probe, and reassemble the ker- nel. After loading back the probed kernel, the hook driver allocates probe buffers on CPU and GPU, and launches the probed kernel. Upon completion, the hook driver will dump probe buffers containing metrics and give back control to user programs. 3.4.1 Hook Driver Though drivers in OS are mostly referred to kernel extensions exposed via read/write/ioctl syscall, such as nvidia.ko, most vendors also maintain higher-level user-space drivers as shared libraries such as libcuda.so or libamdhip.so in Linux. These driver shared libraries are often highly complex and closed-source. However, given that symbols in ELF are resolved via their signatures, we can build a clever hook driver by defining all functions with matching signatures and using dlfcn internally to locate and call the real function from the actual driver, like the following example: #define REAL_DRIVER ... // path to real driver static void* dlib = NULL; // dlopen handle CUresult cuInit(unsigned Flags) { // function of the same signature (from header) if (!dlib) {dlib = dlopen(REAL_DRIVER, RTLD_LAZY);} // open the real shared driver CUresult (*real)(unsigned) = dlsym(dlib, "cuInit"); // get the real function // insert code here := eBPF uprobe CUresult ret = real(Flags); // call the real function // insert code here := eBPF uretprobe return ret; // return the original results } Such a hook driver can be injected into the program via LD_PRELOAD for dynamic loading, e.g., PyTorch, or LD_LIBRARY for static linking, e.g., Triton. This can also be ex- tended to filter out proprietary products like cublas for legal safety, like the following: #define REAL_DRIVER ... // path/to/real/driver, filled in make #define HOOK_DRIVER ... // path/to/hook/driver, filled in make <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 100 in source list: http://www.itworld.com/nl/lnx_tip/05112001/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1095970219&n=1394&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">void* dlopen(const char *filename, int flags) { // dlopen</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> cannot be dlopen real_dlopen = dlsym(RTLD_NEXT, "dlopen"); // RTLD_NEXT -> the real dlopen of libc if (strstr(filename, "libcuda.so.1") != NULL) { // if try to open the driver void* tmp[STACK_TRACE_SIZE]; int size = backtrace(tmp, STACK_TRACE_SIZE); char** syms = backtrace_symbols(tmp, size); // check the callstack <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 54 in source list: https://theses.hal.science/tel-04913269/file/126758_FORCIOLI_2024_archivage.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=3877412810&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">for (int i = 0; i &lt; size; i++) { if</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> (strstr(syms[<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 54 in source list: https://theses.hal.science/tel-04913269/file/126758_FORCIOLI_2024_archivage.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=3877412810&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">i</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">], "cublas") != NULL) // filter proprietaries like cublas return dlopen(REAL_DRIVER, flags); } return dlopen(HOOK_DRIVER, flags); } return dlopen(filename, flags); } Compared with other approaches like eBPF uprobe [28], our hook driver is safer and more flexible as all code is executed in the user mode, supporting fork/wait that are important for interactions with the probe engine. We leverage the hook driver to provide the following supports: Code Tracking: Compared with CPU code implicitly loaded by the OS, GPU code, in the ELF[29] or FatBinary[65] format, requires an explicit load via cuModuleLoad. Other functions, such as cuModuleGetFunction may also be applied to locate the specific ker- nel from the module. We hook these APIs (Fig. 3.8) to capture all images loaded, ker- nels extracted, and the mapping from kernels to code. Each image is memcpyed into the image storage with size from its header to avoid being freed by resource management of user programs. Runtime Probing: As the execution is non-local, launching GPU kernel functions is not simply adding stack frames but requiring an explicit driver call to cuLaunchKernel or hipModuleLaunchKernel. We hook these APIs to provide runtime support: ❶ It searches for the probed kernel in the kernel storage via the original kernel (a pointer); ❷ It allocates probe buffer(s) according to the metadata; ❸ It launches the probed ker- nel and synchronizes for the finish, i.e., probe buffers on GPU are of metric readings; ❹ It memcpys probe buffer back to CPU, then fwrites and frees probe buffers. More importantly, when the probed kernel is not found in the kernel storage, the hook driver is also responsible for interacting with the probe engine: ❶ It searches for the binary containing the kernel in the image storage. ❷ It fwrites the binary in the directory and forks a subprocess to invoke the probe engine. ❸ After waiting, it looks up the directory and loads back the probed kernel and metadata, e.g., number of probes. ❹ Finally, the probed kernel and metadata will be added to kernel storage. Failed kernels will also be added to kernel storage with status=false to avoid repeating. Other functions are unhooked and we auto-generate them by parsing the header cuda.h/hip_runtime.h and the symbol table of the shared library, such as libcuda.so. 3.4.2 Probe Engine As shown in Fig. 3.9, NEUTRINO probe engine first objdumps the dumped GPU binary to extract parallel assemblies in text format. Then it will use the kernel name to match and prune the many-kernel raw assemblies into a single-kernel assembly while keeping global definitions and device functions. Next, NEUTRINO will process and add the probes read from environmental variables, involving the following steps: First, it plans probe map(s) that directs each warp or thread to its segment(s) of map(s) according to the map definition (§3.3.3, level/type/ size/cap) and thread in- dexes, e.g., threadIdx. Taking the block_sched probe (Fig. 3.11(a)) as an example, plan- ning mechanism is similar to the CUDA/HIP C++ code in Fig. 3.10(a) and in practice, it’s achieved by formatting a Python string of assemblies with name and no_bytes to be filled, like the example in Fig. 3.10(b). Next, for each probe , it coarsely parses the kernel assembly into parameters, register declarations, and instructions. Then it matches the tracepoints to specific in- struction(s). Then it thoroughly parses each matched line (e.g., ld.global.u64 %rd1, [%rd2];//%rd1=*%rd2) into tokens, such as opcode (ld.global.u64) and operands %rd1, %rd2. Then it fills the helpers in snippets, such as ADDR, to the real register %rd2. Finally, it places snippets before/after matched instructions, as well as the map addresses at the end of kernel parameters, and the assembly of map planning at the kernel beginning. After probing, it converts the probed assemblies into machine code via assemblers such as ptxas [73]. The probe engine will also save kernel metadata useful for the hook driver, such as the probes, maps, callbacks, etc. 3.4.3 Probe DSL and Compiler A practical issue of the probe engine is that probes are of assemblies, a low-level and hardware-dependent language. Direct assembly programming may be less friendly for general developers. Thus, to enhance NEUTRINO’s hardware independence and usabil- ity, we propose a minimalistic Python domain-specific language (DSL) as the high-level interface for NEUTRINO probes, similar to bpftrace [41] for eBPF [28]. Note that DSL is optional for NEUTRINO, experienced developers can still handcraft assemblies for advanced usages. As shown in Fig. 3.11(a), the NEUTRINO DSL closely follows the Python syntax, allowing users to declare probes with the @probe decorator over functions with trace- points specified as decorator arguments and the snippet as the function body. Similarly, Figure 3.9: NEUTRINO probe engine workflow. Probe engine objdumps and prunes the binary, and finally reassembles it. In probing, it uses map defns to plan probe buffers and tracepoints to match instructions. It also fills helpers in snippets with tokens before injecting them into assemblies. #define NO_BYTES ... // filled by datamodel __global__ void tmp(void* buff) { int thr_idx = (<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 92 in source list: Yi Yang, Chao Li, Huiyang Zhou. "CUDA-NP: Realizing Nested Thread-Level Parallelism in GPGPU Applications", Journal of Computer Science and Technology, 2015"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/s11390-015-1500-y', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">blockDim.y * threadIdx</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.z + \ threadIdx.<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 92 in source list: Yi Yang, Chao Li, Huiyang Zhou. "CUDA-NP: Realizing Nested Thread-Level Parallelism in GPGPU Applications", Journal of Computer Science and Technology, 2015"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/s11390-015-1500-y', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">y) * blockDim.x + threadIdx.x</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">; int blk_idx = (<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 66 in source list: Submitted to Birkbeck College  on 2010-10-08"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=81.4073703292785&svr=18&lang=en_us&oid=oid:2:7529796&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">gridDim.y * blockIdx</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.z + \ blockIdx.<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 66 in source list: Submitted to Birkbeck College  on 2010-10-08"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=81.4073703292785&svr=18&lang=en_us&oid=oid:2:7529796&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">y) * gridDim.x + blockIdx.x</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">; int blk_size = <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 66 in source list: Submitted to Birkbeck College  on 2010-10-08"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=81.4073703292785&svr=18&lang=en_us&oid=oid:2:7529796&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">blockDim</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.x * <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 66 in source list: Submitted to Birkbeck College  on 2010-10-08"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=81.4073703292785&svr=18&lang=en_us&oid=oid:2:7529796&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">blockDim.y \ * blockDim</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.z; int buf_idx = blk_idx * blk_size + thr_idx; } void* buf_loc = buff + buf_idx * NO_BYTES; (a) Map planning CUDA/HIP C++ example. mad.lo.s32 %loc7, %ntid.y, %tid.z, %tid.y; mad.lo.s32 %loc6, %loc7, %ntid.x, %tid.x; mad.lo.s32 %loc5, %nctaid.y, %ctaid.z, %ctaid.y; mad.lo.s32 %loc4, %loc5, %nctaid.x, %ctaid.x; mul.lo.s32 %loc3, %ntid.x, %ntid.y; mul.lo.s32 %loc2, %loc3, %ntid.z; mad.lo.s32 %loc1, %loc2, %loc4, %loc5; mul.wide.s32 %map_{name}4, %loc1, {no_bytes}; ld.param.u64 %map_{name}3, [param_{name}]; cvta.to.global.u64 %map_{name}<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 82 in source list: https://stackoverflow.com/questions/8877666/how-is-a-javascript-hash-map-implemented"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=71042413&n=3793&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">2, %map_{name}3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">; add.s64 %<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 82 in source list: https://stackoverflow.com/questions/8877666/how-is-a-javascript-hash-map-implemented"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=71042413&n=3793&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">map</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">_{name}1, %<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 82 in source list: https://stackoverflow.com/questions/8877666/how-is-a-javascript-hash-map-implemented"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=71042413&n=3793&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">map_{name</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">}2, %<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 82 in source list: https://stackoverflow.com/questions/8877666/how-is-a-javascript-hash-map-implemented"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=71042413&n=3793&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">map</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">_{name}<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 82 in source list: https://stackoverflow.com/questions/8877666/how-is-a-javascript-hash-map-implemented"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=71042413&n=3793&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">4</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">; (b) Real Map planning in Assembly. Figure 3.10: NEUTRINO Map planning mechanism. maps can be declared with @Map decorator with the structure defined as class members. Moreover, contexted probe registers shared across probes can be defined via value as- signment syntax with types annotated in the global scope. NEUTRINO probes are not allowed to use other functions like open. Instead, we provide helper operands like nl.addr for reading registers and helper functions like nl.clock() and Map.save() for getting device-side clocks and saving results. This DSL will be just-in-time compiled into the platform-specific assembly-based probes in two steps, with a compilation example of Fig. 3.11(a) demonstrated as fol- lows: ❶ It uses Python’s ast module to parse and transform the Tracing DSL to an intermediate representation (IR), as shown in Fig. 3.11(b) similar to the eBPF ISA [105]. ❷ The IR will be further translated (codegen) into platform-specific assemblies, i.e., PTX Assembly (Fig. 3.12(a)) and GCNAsm (Fig. 3.12(b)), and helper operands will be pre- served for the probe engine. We design the IR to be eBPF-like, potentially enabling reuse of mature eBPF toolchains, such as the reputable eBPF verifier [32]. 3.4.4 Utilities Ecosystem Integration: Solely hooking onto the driver or probing at the assembly would lack high-level info like tensor shapes that are useful for analysis. Thus, we also <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">from neutrino import probe, Map import neutrino.language as nl CALLBACK</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = "block_sched.py" # <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">for trace analysis # declare maps for persistence @Map(level</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">="warp", <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">type</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">="array", <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">size=16, cap=1) class block_sched</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">: start: nl.u64 elapsed: nl.u32 cuid: nl.u32 # <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">declare probe registers shared across probes start: nl.u64 = 0 # starting clock elapsed: nl.u64 = 0 # elapsed time</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, init <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">to 0 # define probes with decorator @probe(pos</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">="kernel", <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">level</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">="warp", <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">before=True) def thread_start(): start = nl.clock() @probe(pos</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">="kernel", <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">level</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">="warp") <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">def thread_end</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">(): elapsed = nl.clock() - start block_sched.save(start, elapsed, nl.cuid()) (a) NEUTRINO DSL probe example # registered callback for analysis <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">callback</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">="block_sched.py" # <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">map</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> metadata definition [map.<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">block_sched] type</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = "array" <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">level</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = "warp" <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=81.4073703292785&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">size</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = "16" <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">cap</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = "1" # <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">probe</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> of same position merged [<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">probe.thread_start_thread_end] position</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = "kernel" <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">level</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = "warp" <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">register</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = {"u32": <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, "u64": <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">} # IR of compiled function before = "clock PD0" after = """clock PD1 sub PD1, PD0 cvt32 P0, PD1 cuid P1 SAVE [block_sched] {PD0, P0, P1}""" (b) NEUTRINO IR example. Figure 3.11: NEUTRINO DSL probe and corresponding IR example. Each warp has probe register, e.g., start, and saves a block_sched. [probe.thread_start_thread_end] ... # other metadata truncated <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">before</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = """.reg .b64 %PD&lt;3&gt;; .reg .b32 %P&lt;2&gt;; mov.u64 %PD0, %clock64;""" <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">after</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = """mov.u64 %PD1, %clock64; sub.u64 %PD1, %PD1, %PD0; cvt.u32.u64 %P1, %PD1; mov.u32 %P2, %smid; SAVE [block_sched] {%PD0, %P1, %P2 };""" (a) <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">NEUTRINO</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> PTX Codegen example [<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">probe</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.thread_start_thread_end] ... # other metadata truncated register={"u32": 2, "u64": 3, "type ": "sgpr"} before = "s_memrealtime PD0" after = """s_memrealtime PD1 SUB64 PD1, PD1, PD0 CVT32 P0, PD1 s_getreg_b32 P1, hwreg(HW_REG_HW_ID ) SAVE [block_sched] {PD0, P0, P1}""" (b) NEUTRINO GCN Codegen example. Figure 3.12: NEUTRINO Codegen Example for NVIDIA (PTX) and AMD (GCN) GPU. implement utilities for ecosystem integrations like PyTorch[10] by Python sys.settrace to expose high-level tensor information. Benchmarking Mode: To evaluate system overhead and provide time alignment for heavy probes, NEUTRINO provides a benchmark mode that launches both the probed kernel and the pruned kernel (stripped of probes and assembled with identical config- urations) with CUDA/HIP event timers to benchmark the additional execution latency caused by probes. Analysis Codegen and Callback: To facilitate analysis, NEUTRINO supports generat- ing tracing parsing code in Python based on the map definition (such as Fig. 3.11(a)) to facilitate users extracting information from binary traces, like the following example: from neutrino import TraceHeader, TraceSection class block_sched(NamedTuple): start: int elapsed: int cuid: int def parse(path: str): with open(path, "rb") as f: header: TraceHeader = TraceHeader(struct.unpack("iiiiiiii", f.read(32))) sections: List[TraceSection] = [] for _ in range(header.numProbes): size, offset = struct.unpack("QQ", f.read(16)) sections.append(TraceSection(size, offset)) records: List[List[block_sched]] = [] for i in range(header.gridSize): records.append([]) for j in range(header.blockSize): records[i].append(block_sched(struct.unpack("QII", f.read(16)))) return header, sections, records Based on the reading code, developers can easily build analysis tools to integrate NEUTRINO in their workflow (with an example in Sec. 3.4.6). Moreover, NEUTRINO supports adding callbacks (such as Line 3 of Fig. 3.11(a)) for automated posterior anal- ysis. Source Code Annotation: To give more precise control, we implement a source code annotation tool in NVTX-like API [71]. The probe engine can look up the lineinfo (spe- cial comments, e.g., ".file 1 example.py" and ".loc 1 33 45") and cross-reference with the source code (line 33 of 1st file, example.py) to include or exclude the instruction. 3.4.5 Extending NEUTRINO to Other Platforms Though the current implementation only supports NVIDIA and AMD GPUs, NEU- TRINO can be extended to other platforms, such as Intel oneAPI [30]. NEUTRINO’s hardware independence originates from its design on the two common components across platforms: parallel assembly to accommodate rapid architecture-level evolution, and the driver to control the execution from the host OS. In practice, to extend NEUTRINO to other platforms, one needs to implement the hook driver, probe engine, and (optional) DSL compiler backend. For the hook driver, as most functionalities are standardized to platform-agnostic modules, we expect most changes to be around API renaming and debugging, e.g., cuLoadModule to hipLoadModule for ROCm/HIP support. Regarding probe engine, a new parser and matcher for the different assembly syntax (e.g., GCNAsm [5]) shall be needed, but the overall infras- tructure (Fig. 3.9) remains unchanged. The DSL compiler needs a backend to translate our eBPF-like IR into assembly. We expect this would be similar to how Triton [106] supports new hardware with extended codegen (like our probe engine and DSL com- piler) and launcher (like our hook driver). 3.4.6 Usage: Putting It All Together The above components shape a user-friendly and easy-to-use profiling tool of NEU- TRINO. Compatible with many frameworks such as PyTorch [10], Triton [106] and JAX [31], the usage of NEUTRINO is as simple as bpftrace, with many built-in tools such as block_sched (Fig. 3.11(a)) to check the block scheduling cost of kernels. NEUTRINO’s user-friendliness is best demonstrated through a simple example, where we try to pro- file the following line of PyTorch code and gain insights: torch.zeros((4096,4096),torch.float16,device="cuda") To do so, a user just needs to run the NEUTRINO CLI with the –probe/-p option: $ neutrino -p block_sched python -c "torch.zeros(... Then, when finished, traces will be placed in a directory with a print-out message from the analysis callback as follows: vectorized_elementwise: # kernel name, truncated No.block:32768 Exec:680869 Sched:142674 (cycle/SM) Here the vectorized_elementwise kernel [103], widely used by unary tensor opera- tions, is used for initializing allocated memory with zeros. We measure the scheduling time by simulating the block dispatching to CUs. For every recorded block on the CU, if its start clock is greater than any existing block’s end clock (start + elapsed), then a block replacement happens with scheduling cycles estimated by the next start - the previous end and execution cycles measured by the previous elapsed, as demonstrated in the following code: header, sections, records = parse(sys.argv[1]) # code in the previous listing num_cus = len(set([block[0].cuid for block in records])) cu_timelines, sched_times, work_times = [[]]*num_cus, [0.0]*num_cus, [0.0]*num_cus for cur in records: sched_out = False for prev in cu_timelines[cur[0].cuid]: if prev.start + prev.elapsed <= cur[0].start: sched_times[cur[0].cuid] += cur[0].start - (prev.start + prev.elapsed) cu_timelines[cur[0].cuid].remove(prev) cu_timelines[cur[0].cuid].append(cur[0]) work_times[cur[0].cuid] += cur[0].elapsed sched_out = True break if not sched_out: cu_timelines[cur[0].cuid].append(cur[0]) work_times[cur[0].cuid] += cur[0].elapsed print(f"No.block:{header.gridSize} Exec:{mean(sched_times)} Sched:{mean(work_times)}") The profiling results reveal a surprising ∼ 20% time spent on scheduling blocks to physical SMs as the kernel launches a huge number (32,768) of blocks and the exe- cution time of each block is relatively small. Based on the insights, one can <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 86 in source list: Lu, Xiaoyang. "Utilizing Concurrent Data Accesses for Data-Driven and AI Applications", Illinois Institute of Technology, 2024"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31235597&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">optimize the performance by reducing the number of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> blocks launched by the kernel. To do so, we can instruct LLMs to write a persistent kernel that fixes the number of blocks to the hardware limit, like the following: @triton.jit def kernel(output_ptr, numel, BLOCK_SIZE: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">tl.constexpr, NUM_SMS: tl.constexpr): start_pid</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, num_blocks = <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">tl.program_id(axis=0), tl.cdiv</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">(numel, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">BLOCK_SIZE</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">) blocks_<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">per_sm = num</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">_blocks // <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">NUM_SMS if start_pid &lt; num</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">_blocks % <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">NUM_SMS</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">: blocks_<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">per_sm += 1</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> block_<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">id = start_pid - NUM_SMS</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> for _ in range(blocks_per_sm): block_id += NUM_SMS offsets = block_<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 26 in source list: https://github.com/openai/triton/issues/441"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=738885047&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">id * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">) mask = <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 26 in source list: https://github.com/openai/triton/issues/441"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=738885047&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">offsets</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">&lt; numel <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 26 in source list: https://github.com/openai/triton/issues/441"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=738885047&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">tl</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.store(output_ptr + <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 26 in source list: https://github.com/openai/triton/issues/441"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=738885047&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">offsets</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, tl.zeros([BLOCK_SIZE], dtype=tl.float16), mask) def zero_persistent(x: torch.Tensor): numel, BLOCK_SIZE = x.numel(), 128 <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">NUM_SMS = torch.cuda.get_device_properties</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">("cuda").<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">multi_processor_count grid = lambda META: (min(NUM_SMS, triton.cdiv</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">(numel, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 29 in source list: https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=1067047214&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">META['BLOCK_SIZE</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">'])),) kernel[grid](x, numel, BLOCK_SIZE, NUM_SMS) Or for this simple example, we can use the memset primitive provided by driver. To apply customized initialization, we replace torch.zeros with torch.empty that al- locates memory without initialization, and add a line of cuMemset or zero_persistent. This modification offers ∼ 28% speedup: # Original kernel time: 34,493 ns torch.zeros((4096,4096),torch.float16,device="cuda") # Updated memset time: 24,630 ns t=torch.empty((4096,4096),torch.float16,device="cuda") driver.cuMemsetD16(t.data_ptr(), 0, 4096*4096) # Updated zero_persistent kernel: 24,891 ns zero_persistent(t) # code in Appendix F The above one-line debugging example demonstrates the capability and simplicity of NEUTRINO to pinpoint performance bottlenecks within the kernel. Note that NEU- TRINO also supports more advanced usage beyond the above example, including pro- filing the whole model with other interesting tools: $ neutrino -p tensorop_count # number of tensor op $ neutrino -p gmem_bytes # number of GEMM bytes used $ neutrino -p dmat # draw DMAT Plot $ neutrino -p <to/be/contributed/by/you> 3.5 NEUTRINO Visualization NEUTRINO DMAT can also be synchronized to the GPU-local timer, i.e., different com- pute units share the same synchronized timer, rather than CU-local cycle timer. DMAT of the same configuration as Fig. 3.1 under global synchronization becomes Fig. 3.14. Under global synchronization, DMAT becomes terraced-like and each "step" represents 3.5. NEUTRINO Visualization (a) Flash-Attn v2 (Triton) [23] (b) Flash-Attention-v1 [24] (c) Memory-Efficient- with shared block Attention [82] Figure 3.13: NEUTRINO DMAT plot (captured on RTX3080, Appendix A) for different attention algorithms, which exhibit distinct memory access patterns. (a) differs from Fig. 3.1 with exclusive SM. By comparing the DMAT of different algorithms, we can visually identify the improvement of (b) FlashAttn-v1 [24] w.r.t. (c) Memory Efficient Attention [82] comes from I/O efficiency, while the gain of (a) FlashAttn-v2 (Fig. 3.1) comes from better pipelining, both consistent with their respective claims. Figure 3.14: NEUTRINO DMAT aligned to the GPU-local clock. Left: The overview; Right: the Zoom-in view of selected small proportions highlighted in the red rectangles. a launch wave of virtual blocks, 32x128 in this case, to physical compute units (108 SM on A100). We recommend zooming in on each "step", for insightful analysis. The zoomed-in view (right part of Fig. 3.14, note the y-axis value difference) re- flects the actual memory access pattern applied to the hardware, and is insightful for hardware-level analysis and cache simulation. In this section, we introduce the Densified Memory Access Timeline (DMAT) plot, an insightful visualization of GPU runtime workload behavior, as presented in Fig. 3.1 and Fig. 3.13. DMAT plot is inspired by the page reference map [26, 13], which shows the virtual time <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 71 in source list: Ding, Ruyi. "Towards Robust and Secure Deep Learning: From Training Through Deployment to Inference.", Northeastern University"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31997093&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">as the x-axis and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> page accesses <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 71 in source list: Ding, Ruyi. "Towards Robust and Secure Deep Learning: From Training Through Deployment to Inference.", Northeastern University"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31997093&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">as the y-axis</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, where <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 71 in source list: Ding, Ruyi. "Towards Robust and Secure Deep Learning: From Training Through Deployment to Inference.", Northeastern University"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31997093&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">a</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> point represents an ac- cess to the page at the time. As a reference standard, page reference maps have proven to be a useful tool for research on virtual memory management [13] and replacement algorithms [12]. To accommodate the massive parallelism of GPU, DMAT extends the original page reference map in two perspectives: Physical Time: Page reference maps [26, 13] and general memory tracers [87, 78] commonly use a thread-local auto-incremental index as the virtual time denoting the access order. However, we find that the virtual time is insufficient under parallelism where each thread only holds part of the entire page ref- erence map. Because starting times and execution paces of threads diverge, there will be unavoidable misalignment among the virtual time when aggregating page reference maps from individual threads to form the complete trace. Hence, for DMAT we use the device-side physical time to provide reliable aggrega- tion. Specifically, we provide two types of DMAT: ❶ Normalized to the starting clock (Fig. 3.1, Fig. 3.13) of unsynchronized CU-level clocks, suitable for analyzing algo- rithm behavior; ❷ Synchronized to a less accurate (MHz) GPU-local timer (Fig. 3.14), representing actual memory access for hardware/cache analysis. Page Access Density: Previous page reference maps are in 2D, where a point denotes an access at the time to the page. However, for highly parallelized environments, there are likely many concurrent accesses to the same page at the same time from multiple threads. We record such parallel access intensity as density and mark it as color depth to distinguish it from the temporal frequency in traditional page reference maps [26, 13], highlighting the new informative dimension spanned for analyzing the effect of parallelism. The proposed DMAT not only facilitates traditional memory analysis on GPU (e.g., data races, access anomalies), but also features unique benefits for GPU runtime analy- sis: ■ Color Depth: The color depth in DMAT denotes the density of parallelization. When aligned to the GPU-local timer, it reflects the real memory load, with shallow regions pinpointing uncoalesced access among threads and excessive intensity indicating po- tential memory I/O contention. When aligned with the starting clock, color depth reflects the divergence among threads where pale patterns usually indicate divergent thread executions or imbalanced workloads that may waste the computing power. ■ Empty Holes: Empty holes in DMAT demonstrate that pages remain unused for a significant amount of time, which includes two cases (Fig. 3.13(b)): ❶ Discrete empty holes usually reflect computing within CUs. The duration reflects the operational inten- sity [110] per main loop, where a too long empty holes might be inefficient in pipelining [24]; ❷ Structured empty holes usually reflect algorithm improvements, while extra- large structural empty holes may reflect time fragmentation and optimization oppor- tunities. 3.6 NEUTRINO Evaluation We conduct evaluations <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 12 in source list: https://arxiv.org/pdf/2509.16857"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=4054047081&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">to answer the following questions</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> on <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 12 in source list: https://arxiv.org/pdf/2509.16857"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=4054047081&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> reliability <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 12 in source list: https://arxiv.org/pdf/2509.16857"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=4054047081&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> us- ability <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 12 in source list: https://arxiv.org/pdf/2509.16857"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=4054047081&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> NEUTRINO: Are NEUTRINO’s results trustworthy (§3.6.1)? How much per- formance and resource overhead does NEUTRINO introduce (§3.6.2)? How effective is 3.6. NEUTRINO Evaluation NEUTRINO in profiling real applications (§3.6.3)? Our evaluation is performed on two platforms, NVIDIA A100 80GB GPU and NVIDIA RTX4090 24GB GPU. NEUTRINO is compiled with gcc-11.4.0. Other software used includes Python 3.11.4, CUDA 12.6, PyTorch 2.5.0, Triton 3.1.0, CUTLASS 3.5.0, and Ubuntu 22.04. 3.6.1 Correctness Validation We identify and verify two types of correctness: ❶ Execution Correctness that ensures the probing will not alter the original execution flow; ❷ Profiling Accuracy that ensures the metric reading from NEUTRINO is reasonable and correct. Execution Correctness: We validate the execution correctness by comparing output differences between the probed and original kernels, as any difference in execution flow will likely change the output or corrupt the system. To do so, we run each test twice, one with NEUTRINO probes and one without probes (i.e., the original execution) under identical input and configurations. The results show no significant differences between the probed and original outputs. Profiling Accuracy: We verify the profiling accuracy from two perspectives. For met- rics overlapped with other profilers like Nsight Compute [69], (block_sched, gmem_bytes, and tensorop_count), we run the same program separately with NEUTRINO and Nsight Compute, and compare their metric readings. The captured results give consistent met- ric readings. Regarding new metrics beyond the scope of existing profilers, particularly DMAT (§3.5), we validate their correctness by profiling carefully designed "micro-benchmarking" kernels having expected theoretical metric values, and comparing with the actual met- ric readings. We design micro-benchmarking kernels using ld/st instructions with L1 cache disabled, for memory access, and spin-based sleeping to controllably simulate computation inside CUs, as demonstrated in Fig. 3.15(a). We implement several mem- ory access patterns: Linear, Strided, Gather, Scatter, and Random. We emulate these access patterns on the CPU, with addresses, normalized to base addresses, derived __global__ void random_kernel( const int* A, int* B, // A has been shuffled int M, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 62 in source list: Numerical Computations with GPUs, 2014."><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-319-06548-9', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">int N</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, unsigned <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 62 in source list: Numerical Computations with GPUs, 2014."><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-319-06548-9', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">int</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> NS) { <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 62 in source list: Numerical Computations with GPUs, 2014."><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-319-06548-9', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">int</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> col = <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 62 in source list: Numerical Computations with GPUs, 2014."><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-319-06548-9', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">blockIdx.x*blockDim.x+threadIdx.x; if</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> (col &gt;= M) <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 62 in source list: Numerical Computations with GPUs, 2014."><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-319-06548-9', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">return</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">; // boundary check <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 62 in source list: Numerical Computations with GPUs, 2014."><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-319-06548-9', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">int</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">* src = A + col; <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 65 in source list: https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=3415942250&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">for (int i = 0; i</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">&lt; M * <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 65 in source list: https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=3415942250&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">N; i</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> += M) { int <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 65 in source list: https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=3415942250&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">idx</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> = src[<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 65 in source list: https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=3415942250&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">i</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">]; // random <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 65 in source list: https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=3415942250&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">idx</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> from <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 65 in source list: https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=3415942250&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">A</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> B[<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 65 in source list: https://theses.gla.ac.uk/85229/2/2025szafarczykphd.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=88.3927704990501&svr=18&lang=en_us&sid=3415942250&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">idx] = i</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">; // write to B[idx] device_sleep(NS);}} // spinloop inside (a) Micro-benchmarking code for random. arr = fisher_yates_shuffle(...) # random algo for blockIdx in range(blocks): for threadIdx in range(threads): start = blockIdx * threads + threadIdx clock = LATENCY # 1st access doesn't sleep for recordIdx in range(records): index = start + recordIdx*blocks*threads addr_A = (index * size) #>>16=>page addr_B = (arr[index] * size) #>>16=>page clock += NS + LATENCY (b) Generating reference address for random. Figure 3.15: NEUTRINO Mirco-benchmarking example for verifying profiling accuracy. from the access pattern’s code, and intervals (in cycles) between consecutive accesses estimated by the sleeping time and memory latency, as shown in Fig. 3.15(b). We compare theoretical estimations and actual readings to evaluate: ❶ Address Consistency: Calculated as Hamming distance between emulated and profiled address sequences; ❷ Clock Errors: Measured as the differences of intervals between consecu- tive accesses within threads; ❸ DMAT Similarity: Computed as RMSE between DMAT (treated as matrices). Tab. 3.2 demonstrates that DMAT can correctly capture mem- ory addresses (with Hamming distances of zeros) and achieve less than 200 cycles time resolution (< 7% of the loop time). Accumulated clock errors will lead to a misaligned timeline for DMAT, resulting in high RMSE errors, which are marginal for coalesced accesses (e.g., stride), yet become considerable for uncoalesced accesses, e.g., ∼ 60% error for linear. It is because uncoalesced accesses have a lower average intensity (∼ 16) as normalization bases and experience more variable memory latencies (∼ 190 cy- cles clock errors). The critical challenge behind the large clock errors is the memory access latency (LATENCY in Fig. 3.15(b)), which will vary from cache hit/miss. To be fair, we disable the L1 (via cg cache operator [72]) and choose the L1 disabled latency (570 cycles on A100) as LATENCY. But in practice, different patterns have varying L1 hit rates (88% for linear and 0% for stride), resulting in unpredictable estimation errors, which we reserve for future work. 3.6.2 Profiling Overhead We evaluate two types of profiling overhead: ❶ Performance Overhead: the kernel slowdown due to probes can compromise the accuracy of time-related profiling; ❷ Re- source Overhead: additional registers from probes, which may affect block dispatching or even lead to register spilling. Performance Overhead: We formulate the kernel overhead as the slowdown from probe instructions <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 87 in source list: Luk Van Ertvelde. "Dispersing proprietary applications as benchmarks through code mutation", ACM SIGARCH Computer Architecture News, 3/25/2008"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/1353534.1346307', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">normalized to the execution time of the original</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> kernels. For better accuracy, we evaluate the kernel execution time via device event timers (§3.4.4). Re- sults presented in each left column of Tab. 3.3 demonstrate the efficiency of NEUTRINO with controllable latency (1.04x on average) on lightweight probes i.e., block_sched, Table 3.2: DMAT micro-benchmark w.r.t. theoretical metrics. Address Consistency Clock Errors DMAT Similarity Kernel Hamming Distance Mean (Normalized) RMSE (Normalized) linear stride gather broadcast random 0 190.1 (6.30%) 0 96.20 (3.42%) 0 58.11 (2.70%) 0 65.19 (3.01%) 0 179.8 (5.98%) 9.54 (59.62%) 277.4 (5.21%) 33.80 (0.44%) 192.5 (2.64%) 221.7 (4.86%) 3.6. NEUTRINO Evaluation Table 3.3: Kernel slowdown and additional physical register usage of NEUTRINO: Ker- nel slowdown is normalized to original kernel latency and additional register usages are averaged based on assembler [73] debug information. NEUTRINO might lead to kernel speedup on lightweight probes, e.g., 0.9868x speedup of gmem_bytes on GEMM, and we discuss this abnormal effect in §3.8. dmat probe leads to different degrees of slowdown on different kernels. block_sched gmem_bytes tensorop_count warp:array:16:1 thread:array:8:1 thread:array:8:1 Kernel Additional Kernel Additional Kernel Additional Slowdown Registers Slowdown Registers Slowdown Registers Kernel Slowdown mem_trace thread:array:16:count Additional Registers CUTLASS Standard GEMM Stream-K GEMM Conv2D 0.9997x 1.0050x 1.0327x +4 +12 +0 0.9868x 1.0022x 1.0934x +4 +12 +0 0.9873x 1.0034x 1.1061x +4 8.8933x +12 10.3709x +0 2.7463x +1 +6 +28 (spill) Triton Group-GEMM 0.9804x Flash-Attnv2 0.9999x +8 (spill) +2 0.9798x 1.0257x +8 (spill) +2 0.9796x 1.0256x +8 (spill) 8.3589x +516 (spill) +2 2.9392x +1.50 PyTorch Batch/LayerNorm SoftMax Sum Max/AvgPool Embedding Gather 1.0251x +4.58 1.0004x +4.5 1.0653x +4 1.0406x +3 1.0068x +6 0.9596x +5 1.0951x +3.54 1.0006x +3.5 1.0389x +2 1.3882x +2 1.0009x +4 0.9957x +2 1.0981x +3.25 1.0006x +3.5 1.0390x +2.67 1.3875x +2 0.9995x +2 0.9782x +2 5.4392x +4.67 13.1630x +8 4.4597x +8.67 7.2559x +4 9.1155x +6 5.5659x +6 gmem_bytes and tensorop_count , while heavy probes such as dmat introduce consider- able slowdown (7.12x on average). and degrees of slowdown depend <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 89 in source list: Rajeev Barua. "Segment protection for embedded systems using run-time checks", Proceedings of the 2005 international conference on Compilers architectures and synthesis for embedded systems - CASES 05 CASES 05, 2005"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/1086297.1086307', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">on the percentage of memory accesses</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> and kernel execution <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 89 in source list: Rajeev Barua. "Segment protection for embedded systems using run-time checks", Proceedings of the 2005 international conference on Compilers architectures and synthesis for embedded systems - CASES 05 CASES 05, 2005"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/1086297.1086307', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">time. Moreover</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, we identify that lightweight probes could abnormally accelerate the program, and our analysis (§3.8) finds that it is because probe instructions can lead assemblers to better instruction flow (+5.88% IPC) and thus better performance (up to 0.94x faster). To further understand the different degree of slowdown raised in heavy probes like dmat, we conduct a more insightful study involving memory access intensity and sampling the dmat savings by adding a sampling counter to save only 1/2 (save once per two memory accesses), 1/3, 1/4, 1/8, and measuring the kernel slowdown. Figure 3.16: NEUTRINO DMAT Slowdown versus kernels and sampling frequency. Results presented in Fig. 3.16 demonstrate that the slowdown of DMAT is mainly of a linear relationship w.r.t. the sampling frequency, highlighting that most DMAT cost comes from the I/O. Moreover, we also identify two major factors contributing to the exact slowdown ratio. First, smaller kernels, i.e., lower block time, suffer from larger slowdown as the proportion of dmat’s memory I/O would be larger w.r.t. the original block time (pool, ∼5555 cycles with 13x slowdown and attn, ∼205101 cycles with 2.75x slowdown). Second, for kernels of similar block time, the proportion of memory in- structions significantly affects the slowdown (attn, 11.03% memory instructions with 2.75x slowdown, and gemm, 17.57% memory instructions with 6.55x slowdown). Figure 3.17: Max probe memory usage of NEUTRINO in profiling model forward. Probe memory usage is log-scaled to original memory usage ((labeled in purple). gmem_bytes and tensorop_count have the same map definition and the same usage. Figure 3.18: Exposed latency comparison: NEUTRINO and Nsight Compute [69]. NEU- TRINO latency is decomposed into prologue (<1%), kernel and epilogue latency. Resource Overhead: We formulate the resource overhead as the difference in the num- ber of physical registers used by the probed kernels compared to the original kernels. Results shown in each right column of Tab. 3.3 demonstrates the low overhead for NEUTRINO probes with 3.78 more registers used in lightweight probes and 5.09 more registers used in the heavy dmat probe. The phenomenon that each probe defines the same number of logical registers but uses varying and fewer physical registers also con- firms the effectiveness of our design of using logical registers rather than physical ones, allowing potential optimization by the assembler. 3.7. Case Study with NEUTRINO Insights 3.6.3 Extensive Study We further conduct two extensive studies evaluating NEUTRINO’s applicability in eval- uating real-world workloads: GMEM Usage in Model Profiling: In practice, develop- ers need to profile the whole model, rather than a single kernel, to locate potential per- formance issues. GMEM usage becomes a constraint here as most GMEM is occupied by model parameters. Thus, we conduct an intensive test on NEUTRINO’s maximum GMEM usage in end-to-end profiling on the whole model inference pass. We select ResNet [40], Stable-Diffusion [84], Mamba-1.7B [35], and Llama3-1/3/8B [33]. The result shown in Fig. 3.17 demonstrates the efficiency of NEUTRINO’s memory usage, with lightweight probes being <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 96 in source list: https://docslib.org/doc/3881914/download-nvidia-com-pdf-tegra-tegra-x1-whitepaper"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=2420357664&n=3809&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">at least an order of magnitude</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> smaller <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 96 in source list: https://docslib.org/doc/3881914/download-nvidia-com-pdf-tegra-tegra-x1-whitepaper"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=2420357664&n=3809&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> the original <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 96 in source list: https://docslib.org/doc/3881914/download-nvidia-com-pdf-tegra-tegra-x1-whitepaper"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=2420357664&n=3809&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">memory</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> footprint, especially for transformers like Llama. GMEM usage of the heavy dmat is mostly remains within the original memory usage, even under a large batch size (256). Moreover, by comparing the results of Llama-1B/3B/8B, we observe that the proportion of NEUTRINO’s GMEM usage relative to the original usage decreases surprisingly as the model scales. This finding demonstrates that the growth of NEUTRINO’s memory requirements is slower than model size scaling and highlights the usability of NEUTRINO in profiling larger models. Profiler Exposed Latency: In addition to kernel slowdown, profilers also expose other noticeable latencies, including Prologue for allocating probe maps and calling the probe engine and Epilogue for copying back probe maps and saving traces to disk. The sum of these is the latency exposed to the upper layer. To evaluate the overall profiling efficiency of NEUTRINO, we compare their exposed latency with Nsight Compute [69] on overlapped metrics via application benchmarkers [10, 104, 106]. Results presented in Fig. 3.18 highlight the reduction of exposed latency and the efficiency of NEUTRINO’s system design and implementation. 3.7 Case Study with NEUTRINO Insights We envision NEUTRINO to be a useful tool for GPU performance engineering, paving the way for optimizing ML systems with fine-grained runtime insights. To showcase how one could exploit NEUTRINO and DMAT plots for previously unavailable insights, we carry out one case study on the impact of synchronization: Similar to hyper-threading on CPU, GPU SM Sub-Partition (the execution unit) also maintains multiple candidate warps (the scheduling unit in GPU), and in each cycle, one warp will be selected by the warp scheduler to run. Such a design can re- duce blocked waiting of instruction completion, particularly for non-local operations like memory I/O, as other candidates can be scheduled to utilize the core. In prac- tice, there could be two cases for these warps: ❶ All warps belong to the same block that might need synchronization; ❷ Warps belong to different blocks that are mutually independent. To identify the potential runtime difference with respect to the difference in syn- chronization, we create a controlled pair on Flash-Attn-v2 [23] implemented by Triton [106]. We leverage Triton auto-tuner to create two kernels: ❶ Exclusive blocks: 128x128 tile, 2 stages, 8 warps, 1 block per SM (2 warps on each SMSP are of the same block); ❷ Shared blocks: 128x64 tile, 2 stages, 4 warps, 2 blocks per SM (2 warps on each SMSP can be of different block). The DMAT plot (aligned with kernel start time) traced by NEUTRINO on A100 are presented in Fig. 3.1A and Fig. 3.13(a), respectively. Although these two configurations impose the same computational load on the SM and offer similar throughput, we can find that their memory access patterns are significantly dif- ferent. For exclusive blocks (Fig. 3.1A) with frequent synchronization, the memory ac- cess pattern is structured with a regular access pattern to K and V, confirming that the algorithm [23] uses one load for both and per main loop. However, for shared K V blocks with independent synchronization (Fig. 3.13(a)), the memory access pattern is unexpectedly unstructured with many tailing blocks (light-colored parts on the right). To validate the tailing effect, we conduct more in-depth analysis via the block_sched probe (Fig. 3.11(a)) to analyze the elapsed time of blocks. From the CDF of elapsed time in Fig. 3.19A, we identify that the elapsed time of exclusive blocks is highly consistent, but varies significantly for sharing blocks (Fig. 3.19B) with a tailing effect of up to 24.69%2. Figure 3.19: ●A CDF of elapsed latency in exclusive blocks; ●B CDF of elapsed latency in shared blocks; ●C GFLOP/s distribution w.r.t. execution progress from left to right; ●D Progress timeline of shared blocks, with slope denoting speed. Every warp in shared blocks first experiences a slow stage (∼ 1.8 TFLOP/s) then jumps into a fast stage (∼ 2.2 TFLOP/s). 2The differences in completion cycles in Fig. 3.19A (∼220000) and Fig. 3.19B (∼430000) is from the FlashAttn-v2 algorithm that N is the sequential dimension, so the latency of two 128x128 tiles (Fig. 3.1) is equivalent to that of two 128x64 tiles (Fig. 3.13(a)), both handling 256 feature dimensions (M). 3.7. Case Study with NEUTRINO Insights To further explore the tailing latency, we take a closer look at the program exe- cution progress via probing the bra instruction (Fig. 3.3) that redirects the program to form the main loop. This probe samples program execution via recording the timestamp at each branching, which can be used to recover the timeline of the block’s working progress as shown in Fig. 3.19D. Furthermore, by taking the difference between sam- pled timestamps, we can further recover the intra-block-level throughput (TFLOP/s) timeline (presented in Fig. 3.19C). From the sampled progress and throughput timeline, we observe an interesting phenomenon that every shared block experiences two stages: a slower stage at around 1.8 TFLOP/s followed by a faster stage at around 2.2 TFLOP/s till the termination. Moreover, by aligning the sampled timeline with start time and CU id, we identify that the transition from slow stage to fast stage is approximately when previously ar- rived shared block (executing at fast stage) terminates, suggesting an implicit FIFO-like prioritized scheduling policy. This finding explains the sparse-then-dense chaotic be- havior in Fig. 3.13(a) and violates the common understanding of structured launch waves shown in Fig. 3.1A based on the algorithm [23]. Furthermore, to justify the prevalence of the tailing effect in shared blocks, we also formulate two configurations of GEMM kernel (M=N=K=4096) issuing the same burden to the physical SM: ❶ 128x256x64 tile, 3 stages, 8 warps, 1 block per SM on A100; ❷ 128x128x64 tile, 3 stages, 4 warps, 2 blocks per SM on A100. And we present the CDF of block completion time <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 51 in source list: https://spiral.imperial.ac.uk/bitstream/10044/1/79631/1/WanAHamid-WLH-2019-PhD-Thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=620387434&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">in Fig. 3.20A and Fig. 3.20B, respectively. Figure 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.20: ●A CDF <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 51 in source list: https://spiral.imperial.ac.uk/bitstream/10044/1/79631/1/WanAHamid-WLH-2019-PhD-Thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=620387434&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> elapsed latency in exclusive blocks; ●B CDF of elapsed latency in shared blocks; ●C GFLOP/s distribution w.r.t. execution progress from left to right; ●D Progress timeline of shared blocks. We identify the same pattern as §3.7 that in GEMM, shared blocks suffered from tailing blocks for up to 50.93%. Similarly, by plotting the intra-block-level throughput timeline and the warp execution timeline <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 51 in source list: https://spiral.imperial.ac.uk/bitstream/10044/1/79631/1/WanAHamid-WLH-2019-PhD-Thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=620387434&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">in Fig. 3.20A and Fig. 3.20B</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, we recognize a jumping from ∼ 5 TFLOP/s to ∼ 7.5 TFLOP/s yielding similar finding as Fig. 3.19. But different from the previous, here BLOCK_N, 128 or 256, is a parallel dimension. Fig. 3.19 and Fig. 3.20 together demonstrate that the existence of tailing effects in shared blocks due to GPU synchronization and scheduling (§3.7) is general, regardless of kernels or tile organizations (parallel or sequential). Last but not least, regarding the performance, both exclusive and shared blocks are not optimal, yet have different performance statistics. Sharing blocks experience poor cache behavior <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 76 in source list: Liu, Zirui. "Lossy Computation for Large-Scale Machine Learning", Rice University"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:32010596&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">due to the random</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">-like <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 76 in source list: Liu, Zirui. "Lossy Computation for Large-Scale Machine Learning", Rice University"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:32010596&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">memory access pattern, which</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> can <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 76 in source list: Liu, Zirui. "Lossy Computation for Large-Scale Machine Learning", Rice University"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:32010596&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">be</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> verified by 5.85x higher stall cycles due to L1 miss from hardware profilers [64] in Tab. 3.4. Quite the opposite, exclusive blocks are so synchronized that they exhibit considerably peaked memory usage (Fig. 3.1B) and suffer from 4.47x higher exposed stall cycles due to memory bus busy and similarly, 1.45x more stall cycles for compute pipeline contention, both implying potential space for performance optimizations. Table 3.4: Exposed stall cycles and reasons of FlashAttn-v2 under exclusive and shared blocks, collected from the Nsight Compute [69] PC Sampling. Stall Reason Exclusive Block Shared Block long_scoreboard (Waiting Global Memory) mio_throttle (Memory I/O High Pressure) math_pipe_throttle (Compute Unit Busy) 41,055 303,694 (4.47x) 616,913 (1.45x) 268,941 (5.85x) 68,005 425,026 3.8 Discussion Completeness of Probe Verification: We identified and prohibited three key factors of unsafe probes in §3.3.4, yet the current verification is not complete. ❶ There remain un- covered security factors, such as unreachable synchronization points that could pause programs. ❷ Current verification might be too strong, e.g., jmp could be supported if the target is within the probe [28]. GPU-kernel verification itself remains an open research problem, and existing works only address several perspectives, such as synchroniza- tion [90] or data races [48]. Thus, we keep probe verification as future work. Abnormal Speedup of Probed Kernel: As shown in Tab. 3.3, NEUTRINO’s probed kernel might present better performance than the original kernel. To further justify this abnormal phenomenon, we conduct a case study on one significant case of such speedup, GEMM with M=N=K=2048, where block_sched can lead to up to 0.94x speedup on CUTLASS implementation and 0.96x speedup on Triton implementation. We pick the Triton implementation (<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 78 in source list: https://codeclimate.com/github/tensorflow/tensorflow/third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc/source"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=790274182&n=3805&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">BLOCK_M=128, BLOCK_N=128, BLOCK_K=32</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, STAGES=3, WARPS=4), and block_sched probe as it has the lowest interruption to the program (only thread start and end). We profiled the probed and original kernel (with the same -O3) with hardware profiler Nsight Compute [69] to validate their performance metrics, and the results suggest dramatic changes: Profiled metrics highlight a 5.88% IPC improvement with a 4.97% busier instruc- tion scheduling. Moreover, we also identified that NEUTRINO probed kernel has 10.22% 3.8. Discussion Metric Probed Original Executed IPC Elapsed Issue Slots Busy 1.08 (+5.88%) long_scoreboard (waiting global memory) 30.41% (+4.97%) 2,698,349 (-10.22%) mio_throttle (waiting memory inst queue) 665,885 (-32.8%) no_instruction (waiting instruction/register) 52,804 (-17.32%) short_scoreboard (waiting shared memory) 1,311,106 (+148%) 1.02 28.97% 3,005,844 990,653 63,868 528,495 less waiting time for global memory, 32.8% less waiting time for memory instruction queue, and 17.32% less waiting time for instructions or register cache. To further ad- dress the improvement, we checked the assembled machine code, particularly the main loop with tensor core (HMMA) and async copy (LDGSTS): /* Probed SASS */ LDGSTS.E.BYPASS ... IMAD R132, R236 ... HMMA.16816.F32 ... HMMA.16816.F32 ... HMMA.16816.F32 ... IMAD.MOV.U32 ... HMMA.16816.F32 ... IMAD.MOV.U32 ... IMAD R133, R236 ... HMMA.16816.F32 ... LDGSTS.E.BYPASS ... HMMA.16816.F32 ... HMMA.16816.F32 ... HMMA.16816.F32 ... IMAD R132, R236 ... IADD3 R134, P0, ... IMAD.MOV.U32 ... HMMA.16816.F32 ... /* Original SASS */ LDGSTS.E.BYPASS ... HMMA.16816.F32 ... LDGSTS.E.BYPASS ... HMMA.16816.F32 ... LDGSTS.E.BYPASS ... HMMA.16816.F32 ... IMAD.MOV.U32 ... HMMA.16816.F32 ... IMAD.MOV.U32 ... HMMA.16816.F32 ... LDGSTS.E.BYPASS ... IMAD.X R251, ... ISETP.LE.AND P5 ... HMMA.16816.F32 ... LDGDEPBAR ; ... IADD3 R138, ... HMMA.16816.F32 ... LDGSTS.E.BYPASS ... From the above truncated and optimized machine code, we can find the probed kernel’s HMMA instructions are more continuous, with more opportunities to reuse the register cache (as results are accumulated along K). Moreover, memory instructions LDGSTS are more distributed, possibly leading to a more balanced pressure on the mem- ory system. Based on in-depth experiments, we attribute the speedup to the assembler opti- mization. In addition to translating assembly into machine code, modern assemblers also incorporate many optimizations, such as reordering instructions for better execu- tion flow and merging reusable registers based on dependency tracking. Our analysis in Appendix demonstrates that NEUTRINO probe’s additional registers and instruc- tions may change register dependencies and can lead to better execution flow and better performance. We believe this counterintuitive observation promises new op- portunities since assemblers and machine code are not widely explored due to their hardware-oriented nature. For example, recently, DeepSeek’s DeepGEMM [115] re- ported 10% speedup by flipping a control bit in machine code. 3.9 Related Work GPU Hardware Profiler: Current GPU kernel profiling systems, such as NVIDIA NSight [69] / CUPTI [64] or AMD RGP [8] / GPA [6], are hardware-dependent that profiling fea- tures require corresponding hardware implementation support, such as performance counters like cache hit/miss rate. These features, though unique, are hard to adapt to new hardware, e.g., async tensor core that makes utilization metric [95] less reliable as computation is offloaded from threads to tensor cores. Moreover, they cannot be flex- ibly customized to meet the needs of developers. For example, hardware profilers can only profile the entire program in a sampling-based manner with low sampling frequency to control overhead in performance and resources, limiting its capability to trace user- specified events. Instead, NEUTRINO limits the profiling targets to only the desired tracepoints, achieving both fine-grained event tracing and low system overhead. GPU Software Profiler: Other framework-specific software profilers, such as the built- in profiler of PyTorch [102] and JAX [31], are kernel-exclusive and can only capture higher-level events, like measuring memory events (alloc/free) or timing the whole kernel (FLOP/s). Instead, NEUTRINO focuses on intra-kernel profiling at the instruc- tion level. GPU Micro-Benchmarking: Motivated to understand hardware design, GPU micro- benchmarking [1, 76, 60, 46, 100] tries to profile the idealized performance of specific hard- ware via specially designed workloads that only consist of interested instructions, such as mma to benchmark tensor core, without any other instructions (even those necessary in real workload, such as ld to read data) to reduce disturbance. Instead, NEUTRINO aims to measure the performance of real workloads, rather than idealized workloads. GPU Simulation: Another way to understand the performance is to use simulators [11, 58, 38, 107, 50] that emulate GPU execution at the cycle level on a CPU. The major problems of these simulators lie in the speed of both running simulations (which might need several days) and support for new hardware features and instructions (which might take several years). Moreover, various runtime dynamics, e.g., timing an instruc- tion, may not be accurately profiled on simulators. GPU Instrumentation: Binary instrumentation [87, 17, 59, 28] that injects code, functions or interrupts, with program states as parameters has been proven powerful in building performance tools on the CPU. There are also some GPU binary instrumentation tools in compile-time such as Ocelot [27], HIPAnalyzer [25], CUDAAdvisor [91], CUDAFlux [15], or in runtime such as SASSI[96], NVBit [108] and GTPin [94]. Though compiler- based approaches may benefit from additional information in compilation, they are bound to a specific compiler, module, or IR, lacking generalizability. They also require source codes, limiting its compatibility with existing frameworks. Runtime approaches 3.10. Conclusion directly operating on machine code lacks sufficient virtualization, so they mostly rely on the protection of the stack via injecting pure device function, which prohibits cooper- ation between probes for advanced usages, making them hard to perform tasks such as timing instruction (subtracting two clock readings) because the start time has been cleared on return and is not visible in the end timer’s context. NEUTRINO persists runtime, rather than compiler, to advance its generalizability and targets parallel as- semblies, other than machine code, to support more advanced and complex profiling tasks with cooperative probes. 3.10 Conclusion The rapid development of AI systems has fostered an urgent need for comprehensive insights through advanced GPU kernel profiling. To address this, we present NEU- TRINO, a GPU assembly probing infrastructure that enables fine-grained, versatile, and programmable GPU kernel runtime profiling with its distinct probe design of snip- pet, tracepoint, and map. We implement NEUTRINO, consisting of the hook driver, probe engine, and DSL compiler, for the CUDA and ROCm ecosystems. We introduce the novel Densified Memory Access Timeline (DMAT) to effectively visualize compre- hensive GPU memory access patterns. We conduct extensive experiments, validating NEUTRINO’s reliability, low overhead, and applicability. Additionally, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">we conduct a case study on the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> impacts <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> synchronization, successfully pinpointing performance bottlenecks with new insights gained by NEUTRINO. To maximize the potentials of NEUTRINO, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 57 in source list: Cong Guo, Rui Zhang, Jiale Xu, Jingwen Leng, Zihan Liu, Ziyu Huang, Minyi Guo, Hao Wu, Shouren Zhao, Junping Zhao, Ke Zhang. "GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching", Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, 2024"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3620665.3640423', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">we have open-sourced</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> it <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 57 in source list: Cong Guo, Rui Zhang, Jiale Xu, Jingwen Leng, Zihan Liu, Ziyu Huang, Minyi Guo, Hao Wu, Shouren Zhao, Junping Zhao, Ke Zhang. "GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching", Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, 2024"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3620665.3640423', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">at https://github.com</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/open-neutrino/neutrino and plan to build a collaborative community to support its continuous growth towards a unified framework for GPU kernel profiling. Chapter 4 MECCL 4.1 Introduction With the increasing need for training and serving deep learning models at scale, the un- derlying machine learning system have evolved significantly toward distributed sys- tems on multiple devices, nodes or even distributed clusters. Such the need of dis- tributed machine learning system opens many research problems and opportunities in building and optimizing computing kernels and systems across multiple accelerators, such as the workload scheduling, the communication-computation overlapping, and the networking. GPU networking are usually divided into two paradigm, the slow but wide Scale-Out network built on NICs and switches, and the small but fast Scale-Up network based on hardware interconnects like NvLink/UALink. In this work, we identify and try to resolve a long standing gap of our poor un- derstanding about the Scale-Up networking, as compared with the rich research efforts put on the Scale-Out network. In addition to the lack of understanding, we do not have a concrete model on these high bandwidth Scale-Up networks: what are their proto- cols? data planes? control planes? flow control? etc. It seems that the only thing we know about Scale-Up network is their extremely huge bandwidth of >100GB/s or even TB/s per device, the fastest in the communication paradigm. But under such a high bandwidth, Scale-Up networks and measurements upon are expected to pose new phe- nomenons and novel research opportunities, benefiting the networking community. Nevertheless, measuring the Scale-Up network in the existing computer communi- cation paradigm is a significant challenge for two major reasons: ❶ Scale-Up networks is built on hardware interconnects and eliminates the NICs/Switches, making most net- work measurement suites via reading NICs/Switches performance counter impossible to apply. ❷ Scale-Up networks runs natively on GPUs and is transparent from the CPU and the OS, which largely prevents the host network measurement stacks [3] based on CPU/OS profiling [28]. To bridge this gap, we presents MECCL, a MEasurement toolkit for Collective Communication Libraries over the Scale-Up networks. MECCL extends the GPU ker- nel probing approach proposed in NEUTRINO from computing kernels on single GPU Chapter 4. MECCL to communication kernels running concurrently on multiple GPU. Specifically, MECCL probes the memory instructions used for link layer communication to profile the net- work without NIC/Switch and build a bottom-up model for Scale-Up network analy- sis. Based on the measurement and the toolkit, we reveal many unexplored behaviors in the Scale-Up network, such as the channel imbalance, memory subsystem overuse, etc. To demonstrate the effectiveness of our measurement, we build MECCL, a Memory Efficient Collective Communications Library. As insipred by recent studies on the host network stack [3, 109, 56], we focus on the poor last-level cache (LLC) performance induced by the communication kernels, a key factor limiting the overall throughput of communication kernels, and build an optimized buffering and communication schedul- ing policy to improve the memory efficiency of communication kernels. MECCL’s contribution to the networking community are summarized as follows: Observability: MECCL presents the first fine-grained measurement toolkit for Scale- Up network over hardware interconnects without NICs/Switches, making this long ignored but important network observable for upcoming networking researches. Efficiency: MECCL is the first to systematically reveal the memory efficiency issue in existing Scale-Up networks and builds the first memory efficient collective communica- tion libraries, optimizing the performance of communications and co-locating compu- tations. 4.2 Background and Scope 4.2.1 Algorithms and Protocols in Scale-Up CCLs Optimized collective communications are often executed in ring, tree or hypercube al- gorithm, since they has been proven efficient in scaling, even when the full P2P connec- tivity is available. For example, the Ring-AllReduce algorithm can reduce the commu- nication complexity <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 49 in source list: https://escholarship.org/content/qt7ht7g77k/qt7ht7g77k.pdf?t=rytc5x"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=260664170&n=3804&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">from O</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">(N2) <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 49 in source list: https://escholarship.org/content/qt7ht7g77k/qt7ht7g77k.pdf?t=rytc5x"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=260664170&n=3804&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">to O(N) where N is the number of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> GPUs. However, these topology-involved algorithms break the communication to multiple steps that part of data are transmitted and aggregated, if need, in each step. The multi-step nature of communication collective algorithms pose challenges to the simple load/store-based native semantic in the Scale-Up networks. Since each step need to acknowledge and synchronize with the prev/next node for the completeness of receiving, processing and sending of the step. Moreover, with data distributed across multiple devices, enough control flags are also needed to recognize the source, leading to the appearance of protocols in the Scale-Up network. Now there are two widely used protocols, namely Simple and Low-Latency (LL): Simple uses a separate control plane that writes multiple <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 58 in source list: https://ece.northeastern.edu/groups/nucar/publications/Xiang_Gong_thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=902328234&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">memory requests at the same time and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> updates <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 58 in source list: https://ece.northeastern.edu/groups/nucar/publications/Xiang_Gong_thesis.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=902328234&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> data plane afterwards. Simple succeeds in better utilizing 4.3. Theoretical Estimation for Communication Kernel’s Memory Behavior the memory system by issuing multiple requests simultaneously, but the memory fence need for maintaining correct memory order poses additional traffic in the hardware. In practice, Simple performs well for large sizes with large latency. Low-Latency (LL) instead embed the control plane into the data transmitted. There- fore, receivers can recognize the receiving and start processing the each 8/128 byte message immediately. LL can greatly reduce the latency but sacrifice part of payload as protocol flag, leading to loss in communication throughput. 4.3 Theoretical Estimation for Communication Kernel’s Memory Behavior In this section, we try to formulate a theoretical model for estimating the memory be- havior of the communication kernels, from the three perspective, namely ideal memory traffic, synchronization overhead, and the cache behavior. 4.3.1 Communication Kernel Logic and Ideal Memory Traffic A Core 1 2 LLC DRAM Network Buffer User Buffer (SRC) SendRecv Core SRC DRAM Core B AllGather DRAM Core DST NvLink UALink 4 5 Network Buffer Network Buffer User Buffer User Buffer LLC 3 DRAM Network Buffer SRC DRAM Core C Scatter DRAM Core DST Reduce User Buffer (DST) Network Buffer User Buffer Network Buffer User Buffer Figure 4.1: Communication Kernel Logic includes both network buffer and user buffer, and read (blue) and write (red) flow. ●A SendRecv and AlltoAll logic; ●B AllGather logic under ring algorithm, having 1x read and 3x write flow; ●C ReduceScatter logic under ring algorithm, having 2x read and 2x write flow. Similar to the host network stack that the OS kernel maintains the socket buffers for protocol and caching usage, CCLs in GPU also maintains an internal buffer but in a more straightforward way. The network buffer (Fig. 4.1) used by CCLs, defaulted to be around 4MBs, are divided into segments that corresponds to a specific block. Each segment can be recognized as a sending and receiving pair between two GPUs. The buffer is reused as the ring buffer that when the sender finished the transmission, the receiver signals the sender to send from the head of the segment, which avoids memory allocations in the hot path. In this setup, the communication involves an internal copy from the internal buffer to the destination memory <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 88 in source list: Qiangyu Pei, Yongjie Yuan, Haichuan Hu, Qiong Chen, Fangming Liu. "AsyFunc", Proceedings of the 2023 ACM Symposium on Cloud Computing, 2023"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3620678.3624664', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">provided by the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> user. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 88 in source list: Qiangyu Pei, Yongjie Yuan, Haichuan Hu, Qiong Chen, Fangming Liu. "AsyFunc", Proceedings of the 2023 ACM Symposium on Cloud Computing, 2023"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3620678.3624664', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">It is worth noting that</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> CCLs handle many communication logic, such as protocol verification, or the necessary computa- tion, such as reduce, in this internal copy. Thus, though there have been some explo- rations like the user buffer registration, similar to kernel bypass in host networking, to avoid the internal copy, these efforts are usually limited to specific communication kernel like the AlltoAll. Based on the above communication logic, we started to estimate the ideal memory traffic from communication kernels. To sort out the impact of different communication kernels, we choose the bus bandwidth (busbw) in GB/s, the traffic of hardware inter- connects, which can be read from hardware profilers [69] or derived from CCL kernel performance [67], as the base of our theoretical model. We identify that for x busbw, the ideal memory traffic (membw) created to the receiver is, consistently, 3x as derived from the communication logic: ❶ Sender SMs writes to the receiver buffer through in- terconnect, creating x busbw writing traffic to the receiver; ❷ Receiver SMs reads from its buffer to check and validate, creating x busbw reading traffic; ❸ Receiver SMs writes the byte to the local destination buffer, creating x busbw writing traffic. Different collec- tive algorithms might have varying logic but the 3x estimation remains. For example, reducescatter (and as part of allreduce) have the step replaced by reading the local ❸ source buffer for reduction, but still creates theoretical 3x bytes memory traffic per x bytes interconnect traffic. Another source of memory pressure is sending, since most receiver in MPI col- lectives is also the sender. This usually creates x busbw writing traffic to the sender for interconnect transmission since most collective communications has the data to send read in registers. But for sendrecv and alltoall, this creates additional x busbw reading traffic because data is not in SMs and <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 83 in source list: Bao, Qinyang. "MPBRQ - A Framework for Mixed-Precision Quantization for Large Language Models.", University of Toronto (Canada), 2024"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31560775&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">need to be loaded from</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> DRAM. In conclusion, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 83 in source list: Bao, Qinyang. "MPBRQ - A Framework for Mixed-Precision Quantization for Large Language Models.", University of Toronto (Canada), 2024"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31560775&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> theoretical <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 83 in source list: Bao, Qinyang. "MPBRQ - A Framework for Mixed-Precision Quantization for Large Language Models.", University of Toronto (Canada), 2024"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31560775&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">memory traffic</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> of widely-used collective algorithms are 4x (3x recv + 1x send) busbw for reducescatter, allgather and allreduce collec- tives, as shown in Fig. 4.1B/C, and 5x (3x recv + 2x send) busbw for sendrecv (in ring/tree setup) and alltoall collectives, as illustrated in Fig. 4.1A. 4.3.2 Synchronization Overhead In communication, another additional source of unpredictable memory source is the synchronization that mostly are handled by the protocols to schedule buffers and acknowledge the receipt of packets. As discussed in Chapter 4.2.1, there are two major protocols, namely Simple and LL (Low-Latency), which handles the synchronization differently. As discussed in Chapter 2.1.5, due to the lack of programmable schedulers, syn- chronization on GPUs can only be conducted via spinning in the Compare-And-Swap (CAS) manner. For example, in the LL protocol with synchronization flags embed- ded in the packet, the synchronization between sender and receiver threads are per- formed as the pseudo-code in Fig. 4.2(b) that the sender that is responsible for encoding 4.3. Theoretical Estimation for Communication Kernel’s Memory Behavior __device__ void Simple_sendrecv( u64 *ptr, u64 *flagptr, /*separate data/flag*/ __device__ void LL_sendrecv( u64 *ptr, /*integrated data/flag*/ } u64 val, u64 flag, /* pre-agreed flag */ ) { if (send) { // sender *ptr = val; // send the data memoryfence_system(); // apply a fence *ptr = flag; } else if (recv) { // receiver while (*flagptr != flag) {}; // read the data, fence guarantees when flag // is updated, val in ptr has been updated val = *ptr; } (a) Simple Protocol. } u64 val, u64 flag, /* pre-agreed flag */ ) { if (send) { // sender asm("st.v2.u64 [%0], {%1, %2};" :: "l"(ptr), "l"(val), "l"(flag)); // flag and val embedded in one packet } else if (recv) { // receiver u64 flag_; do { asm("st.v2.u64 {%0, %1}, [%2];" :"l"(val), "l"(flag) : "l"(ptr)); } while (flag_ != flag); } (b) Low-Latency (LL) protocol. Figure 4.2: Existing Communication Protocols in Scale-Up Network. and writing the memory, and the receiver spins (polls) to read and compare the flag. When the flag matches with a pre-compromised value, receiver recognizes the receipt of packet and would move on to the next. In contrast, the Simple protocol uses a separated control plane, and therefore, the synchronization logic comes differently that the receiver spins on a control flag inde- pendent from the particular packet, as shown in the pseudo-code in Fig. 4.2(a). There- fore, senders would first write multiple packet to fill the segment, and signal the re- ceiver via the independent control flag. However, since the flag is not embedded, mem- ory fences (Chapter 2.1.4) are necessary <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 98 in source list: https://hal.inria.fr/tel-01597752/file/MONDELLI_Andrea.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=2279073709&n=3265&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">to maintain the correct memory order</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, creating additional <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 98 in source list: https://hal.inria.fr/tel-01597752/file/MONDELLI_Andrea.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=2279073709&n=3265&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> unpredictable <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 98 in source list: https://hal.inria.fr/tel-01597752/file/MONDELLI_Andrea.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=2279073709&n=3265&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">memory</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> traffic. 4.3.3 Cache Behavior Cache behavior is the core of memory system performance optimization since a cache hit could lower the access latency by 10x and the throughput of the cache (SRAM) is usually 5x faster than the memory (DRAM). And in GPU, most caches are managed by policies such as Least-Recently Used (LRU), requiring temporal locality. Regarding the communication, unfortunately, most reading and writing is in streaming manner since networking data is only transmitted once. Thus, the expected cache hit rate is ≈ 0%. However, the internal buffer is an exemption for the poor cache performance since the external writing flow (❸ in <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 85 in source list: I.K. Gavich. "Hydrogeodynamics", A.A. Balkema, Rotterdam, 2020"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=90.9815192048654&svr=18&lang=en_us&sid=823752729&n=1422&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">Fig. 4.1A) and the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> internal reading <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 85 in source list: I.K. Gavich. "Hydrogeodynamics", A.A. Balkema, Rotterdam, 2020"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=823752729&n=1422&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">flow</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> (❹ in <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 85 in source list: I.K. Gavich. "Hydrogeodynamics", A.A. Balkema, Rotterdam, 2020"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=823752729&n=1422&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">Fig. 4</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.1A) could be overlapped in some protocols. Nevertheless, as the buffer, they are expected to be read and written for many rounds since the communication, often involving MBs or GBs of data, takes multiple turns. Therefore, we identify the potentially ideal cache performance as the ≈ 100% hit rate. In conclusion, we summarize the ideal memory traffic estimation for different communication kernels as follows: Table 4.1: Theoretical Model of Memory Traffic from the Communication Kernels. SendRecv AllGather ReduceScatter Read MemBw 2x Write MemBw 3x <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 74 in source list: Abhishek Bhattacharjee, Daniel Lustig. "Architectural and Operating System Support for Virtual Memory", Springer Science and Business Media LLC, 2018"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-031-01757-5', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">L1 Hit Rate</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 0% <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 74 in source list: Abhishek Bhattacharjee, Daniel Lustig. "Architectural and Operating System Support for Virtual Memory", Springer Science and Business Media LLC, 2018"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-031-01757-5', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">L2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Read <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 74 in source list: Abhishek Bhattacharjee, Daniel Lustig. "Architectural and Operating System Support for Virtual Memory", Springer Science and Business Media LLC, 2018"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-031-01757-5', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">Hit Rate</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 50% <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 74 in source list: Abhishek Bhattacharjee, Daniel Lustig. "Architectural and Operating System Support for Virtual Memory", Springer Science and Business Media LLC, 2018"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-031-01757-5', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">L2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Write <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 74 in source list: Abhishek Bhattacharjee, Daniel Lustig. "Architectural and Operating System Support for Virtual Memory", Springer Science and Business Media LLC, 2018"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1007/978-3-031-01757-5', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">Hit Rate</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 33.33% 1x 3x 0% 100% 33.33% 2x 2x 0% 50% 50% 4.4 Practical Measurement of Memory Traffic in Commu- nication Kernels <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 97 in source list: https://ftp.cs.wisc.edu/sohi/theses/moshovos.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=343430340&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">In this section, we</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> broadly <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 97 in source list: https://ftp.cs.wisc.edu/sohi/theses/moshovos.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=343430340&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">measure</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> and characterize <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 97 in source list: https://ftp.cs.wisc.edu/sohi/theses/moshovos.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=343430340&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">the memory</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> traffic <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 97 in source list: https://ftp.cs.wisc.edu/sohi/theses/moshovos.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=343430340&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">of</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> communi- cation kernels that reveal the memory contention and performance degradation. Our key findings are: • Chapter 4.4.3 Communication kernels creates more memory traffic than the theo- retical model due to synchronization. • Chapter 4.4.4: Different blocks of communication kernels experiences varying communication throughput, pinpointing imbalance in communication. • Chapter 4.4.5: Communication kernels is highly LLC inefficient, with nearly 100% miss rate, in high bandwidth. 4.4.1 Environment Setup Table 4.2: Hardware configuration of the testbed used. L2, DRAM, Interconnect band- width are theoretical maximum values from vendors. Hopper GPU 4 x NVIDIA H100 SXM SMs (Cores) 144 @ 1.53GHz L2 (LLC) 60MB SRAM L2 Bw 5.5TB/s DRAM 80GB HBM3 DRAM BW 3.35TB/s Interconnect 18 x NvLink Gen 4 Interconnect BW 900GB/s Bidirectional Hardware: We use one testbed of the standard H100 SXM5 setup (Tab. 4.2), which is also <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 90 in source list: Size Zheng, Renze Chen, Yicheng Jin, Anjiang Wei, Bingyang Wu, Xiuhong Li, Shengen Yan, Yun Liang. "NeoFlow: A Flexible Framework for Enabling Efficient Compilation for High Performance DNN Training", IEEE Transactions on Parallel and Distributed Systems, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/TPDS.2021.3138862', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">widely used in</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> the <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 90 in source list: Size Zheng, Renze Chen, Yicheng Jin, Anjiang Wei, Bingyang Wu, Xiuhong Li, Shengen Yan, Yun Liang. "NeoFlow: A Flexible Framework for Enabling Efficient Compilation for High Performance DNN Training", IEEE Transactions on Parallel and Distributed Systems, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/TPDS.2021.3138862', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">deep learning</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> scenarios <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 90 in source list: Size Zheng, Renze Chen, Yicheng Jin, Anjiang Wei, Bingyang Wu, Xiuhong Li, Shengen Yan, Yun Liang. "NeoFlow: A Flexible Framework for Enabling Efficient Compilation for High Performance DNN Training", IEEE Transactions on Parallel and Distributed Systems, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/TPDS.2021.3138862', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">such as</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> LLM training <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 90 in source list: Size Zheng, Renze Chen, Yicheng Jin, Anjiang Wei, Bingyang Wu, Xiuhong Li, Shengen Yan, Yun Liang. "NeoFlow: A Flexible Framework for Enabling Efficient Compilation for High Performance DNN Training", IEEE Transactions on Parallel and Distributed Systems, 2021"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/TPDS.2021.3138862', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> serving. The testbed features a 3.5TB/s DRAM bandwidth with 900GB/s Interconnect bandwidth, and a 60MB LLC, one of the largest in existing GPUs. Software: We use NCCL [68] (v2.27.0), the de-facto framework for scale-up networks, as the communication workload, coupled with its standard test suite nccl-tests (v2.17.0). From all provided MPI collectives, we pick three representative, SendRecv, AllGather 4.4. Practical Measurement of Memory Traffic in Communication Kernels and ReduceScatter because SendRecv can be extended for AlltoAll, while AllGather and ReduceScatter can be composed to AllReaduce. Using these basic building block can avoid the impact from the composition. We includes both the Simple and LL128 protocol as introduced in Chapter 4.2.1 to study the different synchronization behavior. Since the user buffer only benefits SendRecv and AlltoAll collective, we disable it for consistency in the following analysis. To create comparative studies, we leverage the NCCL’s NCCL_CTAS envariable to configure the number of SMs participating in the communication in order to indirectly control communication and memory bandwidth, similar to the number of CPU cores used in HostCC [3] and CEIO [56]. 4.4.2 Measurement Tools for Communication Kernels We envision the measurement <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 95 in source list: https://conservancy.umn.edu/server/api/core/bitstreams/d6dda029-0d76-4b74-a560-54a3d01136cd/content"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=2045460492&n=3808&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">to validate the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> correctness <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 95 in source list: https://conservancy.umn.edu/server/api/core/bitstreams/d6dda029-0d76-4b74-a560-54a3d01136cd/content"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=2045460492&n=3808&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">of the theoretical</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> model built <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 95 in source list: https://conservancy.umn.edu/server/api/core/bitstreams/d6dda029-0d76-4b74-a560-54a3d01136cd/content"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=2045460492&n=3808&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">in Chapter</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 4.3 and uncover the potential performance issue of synchronization (Chap- ter 4.3.2) and cache (Chapter 4.3.3). Therefore, we need to measure the cache and memory subsystem, such as the hit rate of L2 (LLC in GPU), the bandwidth of XBAR and DRAM, the performance metric of hardware interconnects (NvLink), etc. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 13 in source list: https://arxiv.org/html/2402.13499v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=3952421177&n=3806&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">It is worth noting that we use the</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> percentage of DRAM bandwidth usage (the miss of L2), as compared with the XBAR bandwidth usage (the total input of L2) to measure the hit/miss rate. This percentile is the ag- gregated L2 usage of all different pipelines using memory and could help sort out the impact of different cache line size. We use hardware profilers (Nsight-Compute) to measure these. Moreover, to measure the spinning directly, we extend the NEUTRINO for multi- processing measurement. We identify that the spinning is centralized with the while statement to poll and compare the flag, which, in GPU, is compiled to bra (PTX) or S_CBRANCH (GCNAsm) in assembly. Therefore, we probe the corresponding bra op- eration to count the average number of spinning. We also extend necessary multi- threading support to NEUTRINO by adding enough mutex protection for thread-safety. Compared with indirect measurement such as the XBAR bandwidth, the direct mea- surement can help sort out the impact of varying cache and memory system perfor- mance. 4.4.3 Synchronization and Latency We first study the synchronization overhead, rooted from the spinning-based waiting for message arrival. We leverage the LL’s LL128 protocol, rather than the Simple, since LL protocols synchronize per 128 byte message instead of MBs segments. This also helps to study the exposed latency of hardware interconnects to communication ker- nels. Our experiments presented in Fig. 4.3 demonstrates that the spins taken for syn- chronizing a message arrival increases exactly as the network bandwidth increases, from the 1.1x spinning of 80GB/s to 2.4x spinning on 350GB/s. This finding high- lights two points: ❶ The exposed latency of hardware interconnects increases as the bandwidth, pinpointing a tradeoff between latency and bandwidth; ❷ Existing raw spinning-based implementation of LL protocols is highly inefficient that could create more than 2x memory pressure than the desired due to synchronization. 4.4.4 Imbalance of Communication Channels To further characterize the cause of high spinning count, we study the distribution, in addition to the average, of the spins by drawing the violin plot v.s. the SMs used. This helps to study the exposed latency of different channels more precisely. Our results, as presented in Fig. 4.4 suggests a highly imbalanced exposed latency, as represented by spinning counts, across different blocks (SMs). Some SMs would experience a 10x more spins than other SMs to receive and acknowledge a message. Moreover, we identify that the distribution becomes more dispersed as more SMs are used in the communication, leading to more unpredictable latency exposed. It is also worth noting that the imbalanced latency arise very early at 4 SMs with 80GB/s netbw, at which the hardware interconnect channels are far from saturation (usually 20 SMs with 300GB/s newbw). This unusual effect pinpoints two issues: ❶ There might be general design drawbacks of channel balancing in hardware intercon- nect communications, which the community lacks the correct modeling; ❷ For commu- nication kernel development, it is vital to classify and handle the imbalanced latency to reduce the memory pressure. 4.4.5 Cache Efficiency We further investigate the cache efficiency of communication kernels, as referred to the ideal cache performance in Tab. 4.1. Here we use both the LL128 and Simple protocol to investigate the impact from protocol design. (a) Average Spins of AllGather (b) Average Spins of ReduceScatter Figure 4.3: Averaged Spins Count v.s. No.SMs Used and Network Bandwidth. Spins count increases exactly as the network bandwidth. 4.5. Performance Under the Communication-Computation Overlapping (a) Spins Distribution of AllGather (b) Spins Distribution of ReduceScatter Figure 4.4: Spin counts distribution v.s. No.SMs Used. Noticed that the distribution is imbalanced with blocks of extremely high latency. Our results presented in Fig. 4.5 demonstrates a dramatically poor cache efficiency, particularly in the Simple protocol. In Simple protocol, we identified that under most setups the LLC hit rate, of both read and write, will decrease dramatically to ≈ 0%, which significantly underperforms the theoretical model that the internal buffer could be cached. Similarly, in LL128 protocol, we identify that most setups also have a poor cache performance, with ≈ 0% hit rate for write, and ≈ 40% hit rate for reading. How- ever, when sorting out the additional spinning memory access as discussed above, the corrected memory performance is still far from the optimal. Nevertheless, we identified that a better memory performance exists for both Simple and LL128 protocol at 4 SMs, at which the ≈ 50% hit rate in SendRecv and ReduceScatter reading, and ≥ 50% hit rate in AllGather’s reading roughly matches the theoretical model established. This 4.5 Performance Under the Communication-Computation Overlapping In this section, we add the computation kernel to co-locate with the communication kernels and conduct more in-depth measurement on the shared memory subsystem. Our key findings are: • There is a memory wall at around 70% limiting the performance of co-located communication and computation kernels. 4.5.1 Environment Setup We continue to use the hardware (H100 SXM5) and the software (NCCL v2.27.0) setup in Chapter 4.4. And we add the computation workload of FlashInfer [113] (v0.3.0), a collection of kernels for LLM inference that has been widely used in mature tech stack like vLLM [51] and SGLang [116] and comes with a comprehensive analysis of memory bandwidth utilization. We pick the BatchDecode kernel that can be configured via the seq_len and batch_size to create varying memory pressure for comparative analysis. (a) LLC Hit Rate of SendRecv and Simple (b) LLC Hit Rate of SendRecv and LL128 (c) LLC Hit Rate of AllGather and Simple (d) LLC Hit Rate of AllGather and LL128 (e) LLC Hit Rate of ReduceScatter and Simple (f) LLC Hit Rate of ReduceScatter and LL128 Figure 4.5: LLC Hit Rate of Read and Write v.s. No.SMs Used. With more SMs used, the cache performance decreased dramatically. Simple protocol even have ≈ 0% hit rate for read and write. To sort out other impact like the tailing effect of misaligned scheduling, we use the GreenContext API provided in CUDA Driver to separate the block scheduling of com- putation and communication kernels. Therefore, each kernel uses the full capability of core’s computing and memory pipes. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 72 in source list: https://digitallibrary.usc.edu/asset-management/2A3BF1Q9MEUD"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=342978654&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">Chapter 5 Conclusion and Future Works 5.1 Conclusion With</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> the emergence of artificial intelligence under the scaling law, the need of paral- lel computing exploits exponentially, pushing specialized hardware like GPU to the main stage of advanced computer systems. In this thesis, we identify that though these hardware platforms are powerful in computing, the underlying tradeoffs on other sys- tem capabilities, like the observability on fine-grained events within their kernels, limit our understanding on their runtime behaviors and our capability to build performant computing systems upon. However, profiling these specialized hardware has never been an easy task. We recognize that the fundamental challenge is the change of paradigm, rather than sim- ply having more threads that CPU. For example, in GPU computation, there is no more OS kernels, the provider of basic services and the source of observability in computer systems. Another example is the Scale-Up network which completely eliminates the NICs and traditional switches, the two cornerstones of computer networks. The com- puter system are more flatten and close to performance, making existing profilers either kernel-exclusive or sampling-based. To address this complicated systematic observability issue, we propose an effective assembly probing approach that selectively insert small probes into the user program to expose valuable runtime information along with execution. As inspired by previous efforts of probing in computer systems [28, 57] and instrumentation in programming languages [87, 59, 17], our approaches targets a fundamental commonness in comput- ers, including specialized hardware that they are expected to run code in their own assembly. Therefore, we places small probes into user program at the assembly level and when being executed, valuable fine-grained profiles would arise naturally. Since the approach is simple without additional architecture support, it can be applied to most hardware platforms, particularly on those lacking systematic support like GPUs. Moreover, based on the assembly, the fundamental and the lowest layer of the compiler paradigm, our approaches can also be applied to most software stacks, covering a huge range of tasks. Even more, since the probe is executed in the device Chapter 5. Conclusion and Future Works with other code, rather than the host, our approach inherently achieves fine granularity. Based on this effective model, we explores two interesting and meaningful use cases: NEUTRINO, a Fine-grained and Programmable Interface for GPU Kernel Pro- filing: We apply the assembly probing to profile GPU computing kernels, including but not limited to block/warp scheduling, memory access, etc. NEUTRINO achieves instruction-level fine granularity, profiling versatility across time and value domains, and hardware independence. We introduce the Densified Memory Access Timeline (DMAT), a novel representation that better visualize the rich details captured by NEU- TRINO. We implement NEUTRINO in Linux for both NVIDIA and AMD GPUs and conduct extensive evaluations and analyses, demonstrating NEUTRINO ’s superior ca- pabilities in GPU kernel profiling with low overhead. MECCL, a Measurement toolkit for Collective Communications and a Memory Efficient Communication Kernel Library for Scale-up Network and Communication Computation Overlapping: We extend the assembly probing used in NEUTRINO to another profiler, MECCL, for the GPU communication kernels running on multiple devices, specifically for the Scale-Up network building on hardware interconnects of TB/s rather than NICs. We leverage MECCL to explore the inefficiency of existing communication kernels like NCCL in memory system, e.g., in cache usage, spinning synchronization, and channel imbalance. Based on these observation, we are work- ing on an optimized communication kernel libraries with better peak performance and overall throughput when co-locating with computing kernels. Through applications in computing (NEUTRINO) and communication (MECCL), we address the advances of our assembly probing approach in high compatibility, fine granularity, and flexible programmability. However, it is worth noting that as a pure- software profiling system primarily based on the assembly layer, our approach also has some inherent drawbacks: it cannot profile unprogrammable hardware events such as the cache miss and stall cycles. Moreover, in addition to presented works, there are also many other interesting directions to explore that could further highlight the capability of our assembly probing approaches, as summarized below. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 99 in source list: https://repository.kaust.edu.sa/bitstream/handle/10754/693744/Tackling_the_Communication_Bottlenecks_of_Distributed_Deep_Learning_Training_Workloads.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=1357945809&n=3804&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">5.2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Future <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 99 in source list: https://repository.kaust.edu.sa/bitstream/handle/10754/693744/Tackling_the_Communication_Bottlenecks_of_Distributed_Deep_Learning_Training_Workloads.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=1357945809&n=3804&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">Work 5.2.1</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Unrevealing GPU <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 99 in source list: https://repository.kaust.edu.sa/bitstream/handle/10754/693744/Tackling_the_Communication_Bottlenecks_of_Distributed_Deep_Learning_Training_Workloads.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=1357945809&n=3804&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">Scheduling</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Traditionally, GPU <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 99 in source list: https://repository.kaust.edu.sa/bitstream/handle/10754/693744/Tackling_the_Communication_Bottlenecks_of_Distributed_Deep_Learning_Training_Workloads.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=1357945809&n=3804&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">scheduling</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> is hardware-implemented, unlike OS schedulers like CFS or EEVDF [112, 97], and is multi-level, including stream-level kernel scheduling, block-level core scheduling, and the finest warp-level instruction scheduling. More- over, with more asynchronous DSA and instructions, such as WGMMA and TMA, software scheduling [21, 106] becomes an important axis for optimization, However, our existing solutions (§3.4.6 and §3.7) and other research efforts [36] are still far from completely understanding the GPU scheduling policies. Therefore, we keep it as a 5.3. Vision: Towards a Unified Profiling Framework promising direction to explore GPU scheduling using the probing approach of NEU- TRINO and MECCL. 5.2.2 Understanding GPU Sharing GPU sharing, i.e., concurrently executing multiple kernels, becomes a practical solution to utilize the GPU, particularly on shared environments from cloud providers. Such sharing can be intra-process via CUDA/HIP streams, inter-process via MPS (Multi- Process Service), or with resource isolation via MIG (Multi-Instance GPU). With the multi-threading and multi-processing extension introduced in MECCL, NEUTRINO now can be used to profile multiple concurrent kernels with aligned time frame for joint analysis. We keep this as an interesting direction to explore in the future for in- depth understanding of practical GPU performance. 5.2.3 Incorporating More Hardware Advances NEUTRINO focuses on a classical single GPU setup, and MECCL extends it to multiple GPUs connected via hardware links within a node, a typical setup in existing machine learning system. However, in the past few years, the underlying system has been ad- vanced quickly, with more interesting ideas and setups introduced, opening more op- portunities for NEUTRINO. One example is the disaggregated memory system [37] by incorporating remote devices as external memory pool. Another example is the tensor computing unit who achieves more efficiency by giving up the PC execution model. These new system advances opens more challenges and research opportunities, which we believe our probing mechanism could also be extended to. Therefore, we keep this as an existing direction to explore in the future. 5.3 Vision: Towards a Unified Profiling Framework Last but not least, we envision NEUTRINO and MECCL to an excellent complements to current hardware-dependent and kernel-exclusive kernel profilers by fusing the miss- ing information on both sides. Moreover, from the big picture of observability, the multi-scale probing feature of NEUTRINO and MECCL makes it an intermediate to bridge the gap between architecture-level hardware profilers [8, 64, 69] and application- level software profilers [102, 14]. Hence, we aim to integrate platform-specific hard- ware profilers and framework-specific software profilers with our assembly probing approach, exemplified by NEUTRINO and MECCL, as the ultimate future directions toward building a unified framework for GPU kernel profiling. Appendix A <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 41 in source list: https://www.coursehero.com/file/63001382/g40docx/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=198175621&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">N E</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> U <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 41 in source list: https://www.coursehero.com/file/63001382/g40docx/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=198175621&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">T R I N O</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Artifact Appendix <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 41 in source list: https://www.coursehero.com/file/63001382/g40docx/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=198175621&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">A</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.1 Abstract The artifact of NEUTRINO is hosted at GitHub (in branch artifact), containing the source code, installation/collection/analysis scripts, collected traces that reproduce all the evaluation results in our paper. We also package the artifact evaluation as Jupyter Notebooks hosted on Google Colab, offering one-click results reproduction without local runtime setup. In addition, we also maintain an online documentation of NEU- TRINO containing project highlights, user guides, roadmaps, and references for evalu- ating the functionality. Artifact Claim: The collected traces and the codes are identical to our paper’s cor- responding description. You can replicate all the major results using the traces and analysis codes we provided (details in the Expected Results section below). We also pro- vide the trace collection code for you to collect your own traces on your own devices. It’s worth noticing that customized traces, particularly DMAT, can only yield similar results due to hardware and runtime dynamics. A.2 Scope (meta-information) • Design: NEUTRINO is a GPU assembly probing tool designed to attach small snippets (probes) to GPU kernels at runtime to expose runtime execution details (profiling). • System: NEUTRINO system consists of two parts, the probe engine to attach code snippets, and the hook driver to capture GPU kernels launched <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 81 in source list: https://jscholarship.library.jhu.edu/server/api/core/bitstreams/fc220554-fcf7-4d51-a355-829cfbc47626/content"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=693101199&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">at runtime. The source code is available at GitHub</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> and is installable as a Python package. • Probes: NEUTRINO probes are small TOML files that define the profiling task via snippet, datamodel, position, and callback. Probes used in the paper are available at Github. • Output: Fig. 1, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 70 in source list: https://www.mi.tj.chiba-u.jp/~tsumura/Tsumura/papers/BSPIJ2017kiyomitsu.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=3787729749&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">Fig. 10 (A/B/C), Fig. 11, Fig. 12, Fig. 13</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, and Table. 2 in the paper. • Evaluation: We arrange evaluations in notebooks structured linearly, allowing sim- ple click Runtime -> Run All execution. Please refer to the README, and instructions in each Jupyter Notebook (Colab). Appendix A. NEUTRINO Artifact Appendix • Special Requirements: No special requirements for static trace analysis, For dy- namic trace collection, a NVIDIA GPU, e.g., A100, and a PTX-included build of Py- Torch v2.5.0 and CUTLASS v3.5.0 are required. • Disk Space Requiremetns: Evaluating on Google Colab doesn’t require any disk space. Regarding local evaluation, please arrange 3GB for static traces and at least 10GB for collecting dynamic traces. • Experiment Time Less than 30 minutes for static evaluations analyzing collected traces on CPU, and ≈ 10 hours for dynamic evaluation collecting traces on GPU. • Environment Setup Time: For static evaluation, it takes ≈ 2 minutes to download traces. For dynamic evaluation, it takes ≈ 15 seconds to build NEUTRINO. Setting up PyTorch and CUTLASS might take ≈ 3 minutes. • Publicly Available: Yes. • License: We use the Apache License, Version 2.0 for the system source code and the CC BY 4.0 license for probes used in the paper. A.3 Contents NEUTRINO ’s artifact evaluation is arranged in 6 parts, corresponding to different fig- ures or tables in the paper: 1. block_sched: §3.4.6 2. dmat: Fig. 3.1, Fig. 3.13 3. kernel_overhead: Tab. 3.3 4. max_mem: Fig. 3.17 5. exposed_latency: Fig. 3.18 6. warp_sched: Fig. 3.19 We arrange each part to correspond to a section in the Jupyter Notebook. More- over, each evaluation is provided in two modes: the static that parses collected traces, suitable for Getting Started on local CPU-only devices without special hardware/soft- ware requirements, and the dynamic that collects the traces on the real GPU-enabled environment, suitable for Full Evaluation. A.4 Hosting and Requirements Please choose one of the following to access the artifact: • Github: 1. Static evaluation: artifact/static.ipynb 2. Dynamic evaluation: artifact/dynamic.ipynb • Colab: 1. Static evaluation (Use CPU as Runtime) is here. 2. Dynamic evaluation (Use GPU as Runtime) is here. A.5. Evaluation Workflow Hardware Requirement For static evaluation, only a CPU machine with Python 3 runtime is needed. You don’t need to install NEUTRINO for static evaluation. For dynamic evaluation, you will need a NVIDIA GPU with the CUDA driver installed. Please note: 1. The choice of hardware will significantly affect results: • Please use RTX3080 for all DMAT plot (Part. 2). • Please use A100 for all the rest (Part. 1, Part. 3-6). 2. Please make sure no other workload is executing on the same GPU. 3. Please arrange enough disk space, at least 10GB, for dynamic traces collection. Software Requirements NEUTRINO system only depends on GNU toolchain (gcc, file, git, nm), CUDA toolchain (cuobjdump, ptxas) and Python 3.12 (pip, toml). But evaluation workload needs a PTX- included build of PyTorch and CUTLASS. We package the dependency checking and installation in prepare_env.py for one-click installation. Installation It’s recommended to use virtual environments, e.g., <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 5 in source list: https://arxiv.org/html/2509.10371v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=3690798481&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">conda create</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> -y -<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 5 in source list: https://arxiv.org/html/2509.10371v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=3690798481&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">n ae</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">_env <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 5 in source list: https://arxiv.org/html/2509.10371v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=3690798481&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">python=3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.11 &amp;&amp;<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 5 in source list: https://arxiv.org/html/2509.10371v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=3690798481&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">conda activate ae</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">_env, for installation when not using Colab. Automatic Installation:: We provide a helper script prepare_env.py that one can python prepare_env.py to install all dependencies and neutrino. Jupyter Notebooks (also Google Colab) use this way. Manual Installation:: 1. Clone the repo: git clone -b artifact https://github.com/open-neutrino/neutrino.git 2. Build and install: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">cd neutrino &amp;&amp; python setup.py install &amp;&amp; cd</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> .. 3. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">Test installation</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> with <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 25 in source list: https://github.com/open-neutrino/neutrino"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=73.3721903308645&svr=18&lang=en_us&sid=1159513746&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">neutrino</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> –help Please refer to the README file for detailed descriptions on installing PTX-included builds of PyTorch and CUTLASS. A.5 Evaluation Workflow A.5.1 Getting Started Instructions Getting started instructions, taking <30 min, consist of: 1. All static evaluation that reproduces all figures and tables in the paper based on collected traces. 2. The block_sched section (1st part) of the dynamic evaluation that collects and an- alyzes the block scheduling traces. This part takes <1 minute and helps justify the correct environment setup for detailed instructions. Appendix A. NEUTRINO Artifact Appendix You can use Colab to execute the evaluation scripts. To do this, first select the correct Runtime (CPU or GPU as stated above), then click the Runtime button at the top of the Colab web page, and click the Run All button in the dropdown menu to execute the scripts. Each section (of several blocks) can be executed independently. Statistics or figures will be displayed below each cell when execution finishes. If you choose to evaluate locally, please download the Jupyter Notebooks and fol- low the same steps as the Colab execution instructions above. A.5.2 Expected Results Static evaluation on collected traces are expected to closely fit the figures and tables presented in the paper. To save disk space, we mistakenly deleted the original traces for these results. And because these results capture the finest runtime dynamics of the GPU, exact reproduction will be impossible. Our later experiments can only reproduce similar results. Please accept our apologies for the inconvenience, and we will update the revised paper to include the latest results. Dynamic evaluation on customized traces is expected to produce similar results, i.e., similar numbers or figure shapes. A.5.3 Further Evaluation After completing the above evaluation and reading the documentation, we recommend several ways for further evaluation: 1. Test your workloads: NEUTRINO supports most GPU workloads. You can import your GPU kernels (CUDA C++, Triton, etc) and test them via neutrino <your workload>. Check more on NEUTRINO’s support here. 2. Test your workloads: First, read the Programmable Probe guide, write and save your probe in .toml locally, and apply it using neutrino -p <path/to/probe>. 3. Investigate Implementation: NEUTRINO’s implementation is well organized, and it’s a good entry to understand how GPU code dispatches from OS. You can find the implementation of hook driver in neutrino/src/ and the probe engine in neutrino/probe/. A.5.4 Experiments Added in Shepherding In the shepherding process, we have added several more experiments to address tech- nical comments by reviewers. Though not required by AE, we also prepare the repro- duction code: • Microbenchmark (Tab. 3.2): microbench.ipynb • Global DMAT (Fig. 3.14): dmat_global.ipynb • DMAT Slowdown (Fig. 3.16): dmat_slowdown.ipynb • Abnormal Speedup (§3.8): speedup.ipynb Bibliography [1] H. Abdelkhalik, Y. Arafa, N. Santhi, and A.-H. Badawy. Demystifying the Nvidia Ampere Architecture through Microbenchmarking and Instruction-level Analysis. 2022. arXiv: 2208.11174 [cs.AR]. URL: https://arxiv.org/abs/2208.11174. [2] C.-C. Y. Adnan Hoque Less Wright. Deep Dive on the Hopper TMA Unit for FP8 GEMMs. https://pytorch.org/blog/hopper-tma-unit/, 2024. [3] S. Agarwal, A. Krishnamurthy, and R. Agarwal. “Host Congestion Control”. In: Proceedings of the ACM SIGCOMM 2023 Conference. ACM SIGCOMM ’23. New York, NY, USA: Association for Computing Machinery, 2023, pp. 275–287. ISBN: 9798400702365. DOI: 10 . 1145 / 3603269 . 3604878. URL: https : / / doi . org / 10 . 1145/3603269.3604878. [4] A. Agrawal, N. Kedia, A. Panwar, J. Mohan, N. Kwatra, B. Gulavani, A. Tu- manov, and R. Ramjee. “Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve”. In: 18th USENIX Symposium on Operating Systems Design and Implementation. OSDI ’24. Santa Clara, CA, July 2024, pp. 117–134. ISBN: 978- 1-939133-40-3. URL: https://www.usenix.org/conference/osdi24/presentation/ agrawal. [5] AMD. GCN Assembly. https://gpuopen.com/learn/amdgcn-assembly/, 2024. [6] AMD. GPU Performance API. https://gpuopen.com/gpuperfapi/, 2024. [7] AMD. HCC Compiler for ROCm. https://github.com/ROCm/hcc, 2024. [8] AMD. Radeon GPU Profiler. https://gpuopen.com/rgp/, 2024. [9] AMD. ROCm OpenSHMEM Library. https://github.com/ROCm/rocSHMEM, 2025. [10] J. Ansel et al. “PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation”. In: the 29th ACM Interna- tional Conference on Architectural Support for Programming Languages and Operat- ing Systems, Volume 2. ASPLOS ’24. La Jolla, CA, USA, 2024, pp. 929–947. ISBN: 9798400703850. DOI: 10 . 1145 / 3620665 . 3640366. URL: https : / / doi . org / 10 . 1145/3620665.3640366. [11] Y. Bao, Y. Sun, Z. Feric, M. T. Shen, M. Weston, J. L. Abellán, T. Baruah, J. Kim, A. Joshi, and D. Kaeli. “NaviSim: A Highly Accurate GPU Simulator for AMD RDNA GPUs”. In: the International Conference on Parallel Architectures and Compi- lation Techniques. PACT ’22. Chicago, Illinois, 2023, pp. 333–345. ISBN: 9781450398688. DOI: 10 . 1145 / 3559009 . 3569666. URL: https : / / doi . org / 10 . 1145 / 3559009 . 3569666. [12] L. A. Belady. “A study of replacement algorithms for a virtual-storage com- puter”. In: IBM Systems Journal 5.2 (1966), pp. 78–101. DOI: 10.1147/sj.52.0078. Bibliography [13] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 38 in source list: https://www.scribd.com/document/393623513/sistemas-operativos-pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3183830369&n=3783&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">L. A. Belady, R. A. Nelson</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, and <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 38 in source list: https://www.scribd.com/document/393623513/sistemas-operativos-pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3183830369&n=3783&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">G. S. Shedler</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “An anomaly in space-time charac- teristics of certain programs running in a paging machine”. In: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 38 in source list: https://www.scribd.com/document/393623513/sistemas-operativos-pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3183830369&n=3783&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">Commun. ACM 12.6</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> (June 1969), pp. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 38 in source list: https://www.scribd.com/document/393623513/sistemas-operativos-pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3183830369&n=3783&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">349–353. ISSN: 0001-0782. DOI: 10 . 1145 / 363011 . 363155. URL</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">: https://<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 38 in source list: https://www.scribd.com/document/393623513/sistemas-operativos-pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3183830369&n=3783&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#cc0066" class="#cc0066">doi.org/10.1145/363011.363155</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [14] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 80 in source list: https://inria.hal.science/hal-04984000v1/file/KV_Cache_Characterization_IPDPS25.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=240841480&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">E. D. Berger, S. Stern, and J. A. Pizzorno</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Triangulating Python Performance Is- sues with Scalene”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 27 in source list: https://ses.library.usyd.edu.au/bitstream/handle/2123/33717/Final_Thesis (10).pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3622670581&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">In: 17th USENIX Symposium on Operating Systems Design and Implementation. OSDI ’23. Boston, MA, July 2023, pp</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. 51–64. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 27 in source list: https://ses.library.usyd.edu.au/bitstream/handle/2123/33717/Final_Thesis (10).pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3622670581&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">ISBN: 978-1-939133- 34-2. URL: https://www.usenix.org/conference/osdi23/presentation</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/berger. [15] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 37 in source list: https://d-nb.info/1341835669/34"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3940747343&n=3809&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">L. Braun and H. Fröning</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “CUDA Flux: A Lightweight Instruction Profiler for CUDA Applications”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 37 in source list: https://d-nb.info/1341835669/34"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3940747343&n=3809&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#A85503" class="#A85503">In: 2019 IEEE/ACM Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS). 2019, pp. 73–81. DOI: 10.1109/PMBS49563.2019.00014</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [16] [17] A. Brooks, P. Marshall, D. Ozog, M. W.-u. Rahman, L. Stewart, and R. Tom. In- tel(R) SHMEM: GPU-initiated OpenSHMEM using SYCL. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 28 in source list: https://ses.library.usyd.edu.au/bitstream/handle/2123/33986/Thesis_Lyu, Qingcheng 520326323.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3183403945&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">2024. arXiv: 2409</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.20476 [<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 28 in source list: https://ses.library.usyd.edu.au/bitstream/handle/2123/33986/Thesis_Lyu, Qingcheng 520326323.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3183403945&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">cs</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.DC]. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 28 in source list: https://ses.library.usyd.edu.au/bitstream/handle/2123/33986/Thesis_Lyu, Qingcheng 520326323.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=3183403945&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">URL: https://arxiv.org/abs/2409</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.20476. D. Bruening, T. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 44 in source list: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-217.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1291567265&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">Garnett, and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> S. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 44 in source list: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-217.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1291567265&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">Amarasinghe</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “An infrastructure for adaptive dynamic optimization”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 44 in source list: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-217.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1291567265&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">In: the International Symposium on Code</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Generation <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 44 in source list: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-217.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1291567265&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">and Optimization: Feedback-Directed and Runtime Optimization. CGO ’03. San</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Fran- cisco, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 44 in source list: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-217.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1291567265&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">California</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, USA, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 44 in source list: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-217.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1291567265&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">2003, pp. 265–275. ISBN</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">: 076951913X. [18] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 59 in source list: Submitted to Georgia Institute of Technology Main Campus on 2024-04-26"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=72.5844049583863&svr=18&lang=en_us&oid=oid:1:2901024345&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">B. Chapman, T. Curtis, S. Pophale, S. Poole, J. Kuehn, C. Koelbel, and L. Smith</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Introducing OpenSHMEM: SHMEM for the PGAS community”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 31 in source list: https://api.drum.lib.umd.edu/server/api/core/bitstreams/a2c5e70d-17b7-44b5-a797-2ecf14df57f2/content"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=4050052178&n=3804&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">In: Proceedings of the Fourth Conference on</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Partitioned <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 31 in source list: https://api.drum.lib.umd.edu/server/api/core/bitstreams/a2c5e70d-17b7-44b5-a797-2ecf14df57f2/content"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=4050052178&n=3804&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">Global Address Space Programming Model. PGAS ’10. New York, New York, USA: Association for Computing Machinery, 2010. ISBN: 9781450304610. DOI: 10.1145/2020373.2020375. URL: https://doi. org/10.1145/2020373.2020375</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [19] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 33 in source list: Ng, Kelvin K. W.. "Resource Sharing for Machine Learning Serving", University of Pennsylvania, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:32002945&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">C. Chen, X. Li, Q. Zhu, J. Duan, P. Sun, X. Zhang, and C. Yang</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Centauri: En- abling Efficient Scheduling for Communication-Computation Overlap in Large Model Training via Communication Partitioning”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 33 in source list: Ng, Kelvin K. W.. "Resource Sharing for Machine Learning Serving", University of Pennsylvania, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:32002945&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">In: the 29th ACM</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Interna- tional <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 33 in source list: Ng, Kelvin K. W.. "Resource Sharing for Machine Learning Serving", University of Pennsylvania, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:32002945&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">Conference on Architectural Support for Programming Languages and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Oper- ating <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 33 in source list: Ng, Kelvin K. W.. "Resource Sharing for Machine Learning Serving", University of Pennsylvania, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:32002945&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">Systems, Volume 3. ASPLOS ’24</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. La Jolla, CA, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 33 in source list: Ng, Kelvin K. W.. "Resource Sharing for Machine Learning Serving", University of Pennsylvania, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:32002945&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">USA</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, 2024, pp. 178–191. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 4 in source list: http://arxiv.org/pdf/2505.24298"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=2584271281&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">ISBN: 9798400703867. DOI: 10 . 1145 / 3620666</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> . 3651379. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 4 in source list: http://arxiv.org/pdf/2505.24298"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=2584271281&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">URL: https : / / doi . org / 10 . 1145/3620666</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.3651379. [20] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 30 in source list: https://deepai.org/publication/breaking-the-computation-and-communication-abstraction-barrier-in-distributed-machine-learning-workloads"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1772439105&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">T. Chen, T. Moreau, Z. Jiang, L. Zheng, E. Yan, M. Cowan, H. Shen, L. Wang, Y. Hu, L. Ceze, C. Guestrin, and A. Krishnamurthy</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “TVM: an automated end-to- end optimizing compiler for deep learning”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 30 in source list: https://deepai.org/publication/breaking-the-computation-and-communication-abstraction-barrier-in-distributed-machine-learning-workloads"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1772439105&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">In: the 13th USENIX Conference on Operating Systems Design and Implementation. OSDI’18</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Carlsbad, CA, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 30 in source list: https://deepai.org/publication/breaking-the-computation-and-communication-abstraction-barrier-in-distributed-machine-learning-workloads"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1772439105&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">USA</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, 2018, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 30 in source list: https://deepai.org/publication/breaking-the-computation-and-communication-abstraction-barrier-in-distributed-machine-learning-workloads"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1772439105&n=3799&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#CB0099" class="#CB0099">pp. 579–594. ISBN: 9781931971478</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [21] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 15 in source list: Submitted to University of Hong Kong on 2025-06-27"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=72.5844049583863&svr=18&lang=en_us&oid=oid:1:3285974792&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">Y. Cheng, L. Wang, Y. Shi, Y. Xia, L. Ma, J. Xue, Y. Wang, Z. Mo, F. Chen, F. Yang, M. Yang, and Z. Yang</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “PipeThreader: Software-Defined Pipelining for Efficient DNN Execution”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 15 in source list: Submitted to University of Hong Kong on 2025-06-27"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=72.5844049583863&svr=18&lang=en_us&oid=oid:1:3285974792&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">In: 19th USENIX Symposium on Operating Systems Design and Implementation. OSDI ’25</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 84 in source list: Hongzheng Chen, Jiahao Zhang, Yixiao Du, Shaojie Xiang, Zichao Yue, Niansong Zhang, Yaohui Cai, Zhiru Zhang. "Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference", ACM Transactions on Reconfigurable Technology and Systems, 2024"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3656177', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">Boston, MA</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, July 2025. URL: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 84 in source list: Hongzheng Chen, Jiahao Zhang, Yixiao Du, Shaojie Xiang, Zichao Yue, Niansong Zhang, Yaohui Cai, Zhiru Zhang. "Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference", ACM Transactions on Reconfigurable Technology and Systems, 2024"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3656177', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">https : / / www . usenix . org/conference</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/osdi25/<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 84 in source list: Hongzheng Chen, Jiahao Zhang, Yixiao Du, Shaojie Xiang, Zichao Yue, Niansong Zhang, Yaohui Cai, Zhiru Zhang. "Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference", ACM Transactions on Reconfigurable Technology and Systems, 2024"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1145/3656177', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">presentation</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/cheng. Bibliography [22] I. Cho, S. J. Park, A. Saeed, M. Alizadeh, and A. Belay. “LDB: An Efficient La- tency Profiling Tool for Multithreaded Applications”. In: 21st USENIX Sympo- sium on Networked Systems Design and Implementation. NSDI ’24. Santa Clara, CA, Apr. 2024, pp. 1497–1510. ISBN: 978-1-939133-39-7. URL: https://www.usenix. org/conference/nsdi24/presentation/cho. [23] T. Dao. “FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning”. In: International Conference on Learning Representations. ICLR ’24. 2024. [24] T. Dao, D. Y. Fu, S. Ermon, A. Rudra, and C. Ré. FlashAttention: Fast and Memory- Efficient Exact Attention with IO-Awareness. 2022. arXiv: 2205.14135 [cs.LG]. URL: https://arxiv.org/abs/2205.14135. [25] S. Darche and M. R. Dagenais. “Low-Overhead Trace Collection and Profiling on GPU Compute Kernels”. In: ACM Trans. Parallel Comput. 11.2 (June 2024). ISSN: 2329-4949. DOI: 10.1145/3649510. URL: https://doi.org/10.1145/3649510. [26] P. J. Denning. “Working Set Analytics”. In: ACM Comput. Surv. 53.6 (Feb. 2021). ISSN: 0360-0300. DOI: 10 . 1145 / 3399709. URL: https : / / doi . org / 10 . 1145 / 3399709. [27] G. F. Diamos, A. R. Kerr, S. Yalamanchili, and N. Clark. “Ocelot: a dynamic op- timization framework for bulk-synchronous applications in heterogeneous sys- tems”. In: the 19th International Conference on Parallel Architectures and Compilation Techniques. PACT ’10. Vienna, Austria, 2010, pp. 353–364. ISBN: 9781450301787. DOI: 10 . 1145 / 1854273 . 1854318. URL: https : / / doi . org / 10 . 1145 / 1854273 . 1854318. [28] eBPF. https://ebpf.io, 2024. [29] Executable and L. Format. https://en.wikipedia.org/wiki/Executable_and_ Linkable_Format, 2024. [30] U. A. Foundation. oneAPI Programming Model. https://oneapi.io/, 2025. [31] R. Frostig, M. J. Johnson, and C. Leary. “Compiling machine learning programs via high-level tracing”. In: Systems for Machine Learning 4.9 (2018). [32] E. Gershuni, N. Amit, A. Gurfinkel, N. Narodytska, J. A. Navas, N. Rinetzky, L. Ryzhyk, and M. Sagiv. “Simple and precise static analysis of untrusted Linux kernel extensions”. In: the 40th ACM SIGPLAN Conference on Programming Lan- guage Design and Implementation. PLDI ’19. Phoenix, AZ, USA, 2019, pp. 1069– 1084. ISBN: 9781450367127. DOI: 10.1145/3314221.3314590. URL: https://doi. org/10.1145/3314221.3314590. [33] A. Grattafiori, A. Dubey, A. Jauhri, and A. P. et.al. The Llama 3 Herd of Models. 2024. arXiv: 2407.21783 [cs.AI]. URL: https://arxiv.org/abs/2407.21783. [34] K. Group. SPIR: The Standard IR for Parallel Compute and Graphics. https://www. khronos.org/spir/, 2024. [35] A. Gu and T. Dao. Mamba: Linear-Time Sequence Modeling with Selective State Spaces. 2024. arXiv: 2312.00752 [cs.LG]. URL: https://arxiv.org/abs/2312. 00752. [36] Y. Guan, Y. Fang, K. Zhou, C. Robeck, M. Ren, Z. Yu, Y. Ding, and A. Aziz. “KPerfIR: Towards a Open and Compiler-centric Ecosystem for GPU Kernel Performance Tooling on Modern AI Workloads”. In: 19th USENIX Symposium on Operating Systems Design and Implementation. OSDI ’25. Boston, MA, July 2025. URL: https://www.usenix.org/conference/osdi25/presentation/guan. [37] Y. Guan, X. Qiang, Z. Pan, D. Johnson, Y. Fang, K. Zhou, Y. Wang, W. Li, Y. Ding, and A. Aziz. “Mercury: Unlocking Multi-GPU Operator Optimization for LLMs via Remote Memory Scheduling”. In: Proceedings of the ACM SIGOPS 31st Symposium on Operating Systems Principles. SOSP ’25. Lotte Hotel World, Seoul, Republic of Korea: Association for Computing Machinery, 2025, pp. 1046–1061. ISBN: 9798400718700. DOI: 10.1145/3731569.3764798. URL: https://doi.org/ 10.1145/3731569.3764798. [38] A. Gutierrez, B. M. Beckmann, A. Dutu, J. Gross, M. LeBeane, J. Kalamatianos, O. Kayiran, M. Poremba, B. Potter, S. Puthoor, M. D. Sinclair, M. Wyse, J. Yin, X. Zhang, A. Jain, and T. Rogers. “Lost in Abstraction: Pitfalls of Analyzing GPUs at the Intermediate Language Level”. In: 2018 IEEE International Symposium on High Performance Computer Architecture. HPCA ’18. 2018, pp. 608–619. DOI: 10. 1109/HPCA.2018.00058. [39] T. D. Hanson and A. O’Dwyer. uthash. https : / / troydhanson . github . io / uthash/, 2024. [40] K. He, X. Zhang, S. Ren, and J. Sun. Deep Residual Learning for Image Recognition. 2015. arXiv: 1512.03385 [cs.CV]. URL: https://arxiv.org/abs/1512.03385. [41] bpftrace: High-level tracing language for Linux. https://github.com/bpftrace/ bpftrace, 2025. [42] G. Huang, Y. Bai, L. Liu, Y. Wang, B. Yu, Y. Ding, and Y. Xie. “ALCOP: Auto- matic Load-Compute Pipelining in Deep Learning Compiler for AI-GPUs”. In: the Machine Learning and Systems. Ed. by D. Song, M. Carbin, and T. Chen. Vol. 5. Curan, 2023, pp. 680–694. URL: https://proceedings.mlsys.org/paper_files/ paper/2023/file/d6cde2c1b161daa31be560d062cf2251-Paper-mlsys2023.pdf. [43] Intel. Intel Process Trace. https : / / man7 . org / linux / man - pages / man1 / perf - intel-pt.1.html, 2025. [44] A. Jangda, J. Huang, G. Liu, A. H. N. Sabet, S. Maleki, Y. Miao, M. Musuvathi, T. Mytkowicz, and O. Saarikivi. “Breaking the computation and communica- tion abstraction barrier in distributed machine learning workloads”. In: the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. ASPLOS ’22. Lausanne, Switzerland, 2022, pp. 402–416. ISBN: 9781450392051. DOI: 10.1145/3503222.3507778. URL: https://doi.org/ 10.1145/3503222.3507778. [45] S. Jayaram Subramanya, D. Arfeen, S. Lin, A. Qiao, Z. Jia, and G. R. Ganger. “Sia: Heterogeneity-aware, goodput-optimized ML-cluster scheduling”. In: the 29th Symposium on Operating Systems Principles. SOSP ’23. Koblenz, Germany, 2023, pp. 642–657. ISBN: 9798400702297. DOI: 10.1145/3600006.3613175. URL: https://doi.org/10.1145/3600006.3613175. [46] Z. Jia, M. Maggioni, J. Smith, and D. P. Scarpazza. Dissecting the NVidia Turing T4 GPU via Microbenchmarking. 2019. arXiv: 1903.07486 [cs.DC]. URL: https: //arxiv.org/abs/1903.07486. [47] S. Jourdan, R. Ronen, M. Bekerman, B. Shomar, and A. Yoaz. “A novel renam- ing scheme to exploit value temporal locality through physical register reuse and unification”. In: the 31st Annual ACM/IEEE International Symposium on Mi- croarchitecture. MICRO ’98. 1998, pp. 216–225. DOI: 10.1109/MICRO.1998.742783. [48] A. K. Kamath and A. Basu. “iGUARD: In-GPU Advanced Race Detection”. In: the ACM SIGOPS 28th Symposium on Operating Systems Principles. SOSP ’21. Vir- tual Event, Germany, 2021, pp. 49–65. ISBN: 9781450387095. DOI: 10.1145/3477132. 3483545. URL: https://doi.org/10.1145/3477132.3483545. [49] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei. Scaling Laws for Neural Language Models. 2020. arXiv: 2001.08361 [cs.LG]. URL: https://arxiv.org/abs/2001.08361. [50] M. Khairy, Z. Shen, T. M. Aamodt, and T. G. Rogers. “Accel-sim: an extensible simulation framework for validated GPU modeling”. In: the ACM/IEEE 47th An- nual International Symposium on Computer Architecture. ISCA ’20. Virtual Event: IEEE Press, 2020, pp. 473–486. ISBN: 9781728146614. DOI: 10.1109/ISCA45697. 2020.00047. URL: https://doi.org/10.1109/ISCA45697.2020.00047. [51] W. Kwon, Z. Li, S. Zhuang, Y. Sheng, L. Zheng, C. H. Yu, J. Gonzalez, H. Zhang, and I. Stoica. “Efficient Memory Management for Large Language Model Serv- ing with PagedAttention”. In: the 29th Symposium on Operating Systems Princi- ples. SOSP ’23. Koblenz, Germany, 2023, pp. 611–626. ISBN: 9798400702297. DOI: 10.1145/3600006.3613165. URL: https://doi.org/10.1145/3600006.3613165. [52] C. Lattner and V. Adve. “LLVM: A Compilation Framework for Lifelong Pro- gram Analysis & Transformation”. In: the International Symposium on Code Gen- eration and Optimization: Feedback-Directed and Runtime Optimization. CGO ’04. Palo Alto, California, 2004, p. 75. ISBN: 0769521029. [53] C. Lattner, M. Amini, U. Bondhugula, A. Cohen, A. Davis, J. Pienaar, R. Riddle, T. Shpeisman, N. Vasilache, and O. Zinenko. “MLIR: Scaling Compiler Infras- tructure for Domain Specific Computation”. In: 2021 IEEE/ACM International Symposium on Code Generation and Optimization. CGO ’21. 2021, pp. 2–14. DOI: 10.1109/CGO51591.2021.9370308. [54] A. H. Less Wright. Deep Dive on Cutlass Ping-Pong GEMM Kernel. https : / / pytorch.org/blog/cutlass-ping-pong-gemm-kernel/, 2024. [55] Z. Li, L. Zheng, Y. Zhong, V. Liu, Y. Sheng, X. Jin, Y. Huang, Z. Chen, H. Zhang, J. E. Gonzalez, and I. Stoica. “AlpaServe: Statistical Multiplexing with Model Parallelism for Deep Learning Serving”. In: 17th USENIX Symposium on Operat- ing Systems Design and Implementation. OSDI ’23. Boston, MA, July 2023, pp. 663– 679. ISBN: 978-1-939133-34-2. URL: https : / / www . usenix . org / conference / osdi23/presentation/li-zhouhan. [56] B. Liu, X. Huang, Q. Li, Z. Huang, Y. Sun, W. Li, J. Zhang, P. Yin, and K. Chen. “CEIO: A Cache-Efficient Network I/O Architecture for NIC-CPU Data Paths”. In: Proceedings of the ACM SIGCOMM 2025 Conference. SIGCOMM ’25. São Fran- cisco Convent, Coimbra, Portugal: Association for Computing Machinery, 2025, pp. 381–394. ISBN: 9798400715242. DOI: 10.1145/3718958.3750488. URL: https: //doi.org/10.1145/3718958.3750488. [57] C. Liu, B. Tak, and L. Wang. “Understanding Performance of eBPF Maps”. In: the ACM SIGCOMM 2024 Workshop on EBPF and Kernel Extensions. eBPF ’24. Sydney, NSW, Australia, 2024, pp. 9–15. ISBN: 9798400707124. DOI: 10 . 1145 / 3672197.3673430. URL: https://doi.org/10.1145/3672197.3673430. [58] C. Liu, Y. Sun, and T. E. Carlson. “Photon: A Fine-grained Sampled Simula- tion Methodology for GPU Workloads”. In: the 56th Annual IEEE/ACM Interna- tional Symposium on Microarchitecture. MICRO ’23. Toronto, ON, Canada, 2023, pp. 1227–1241. ISBN: 9798400703294. DOI: 10.1145/3613424.3623773. URL: https: //doi.org/10.1145/3613424.3623773. [59] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood. “Pin: building customized program analysis tools with dynamic instrumentation”. In: the 2005 ACM SIGPLAN Conference on Pro- gramming Language Design and Implementation. PLDI ’05. Chicago, IL, USA, 2005, pp. 190–200. ISBN: 1595930566. DOI: 10 . 1145 / 1065010 . 1065034. URL: https : //doi.org/10.1145/1065010.1065034. [60] X. Mei and X. Chu. “Dissecting GPU Memory Hierarchy Through Microbench- marking”. In: IEEE Transactions on Parallel and Distributed Systems 28.1 (2017), pp. 72–86. DOI: 10.1109/TPDS.2016.2549523. [61] K. K. W. Ng, H. M. Demoulin, and V. Liu. “Paella: Low-latency Model Serv- ing with Software-defined GPU Scheduling”. In: the 29th Symposium on Oper- ating Systems Principles. SOSP ’23. Koblenz, Germany, 2023, pp. 595–610. ISBN: 9798400702297. DOI: 10 . 1145 / 3600006 . 3613163. URL: https : / / doi . org / 10 . 1145/3600006.3613163. [62] NVIDIA. CUDA C++. hhttps://docs.nvidia.com/cuda/cuda-c-programming- guide/, 2024. [63] NVIDIA. CUDA Compiler Driver NVCC. https://docs.nvidia.com/cuda/cuda- compiler-driver-nvcc/, 2024. [64] NVIDIA. CUDA Profiling Tools Interface. https : / / docs . nvidia . com / cupti / index.html, 2024. [65] NVIDIA. Fat Binaries. https://docs.nvidia.com/cuda/nvfatbin/index.html, 2024. [66] NVIDIA. Instruction Set Reference. https : / / docs . nvidia . com / cuda / cuda - binary-utilities/index.html, 2024. [67] NVIDIA. NCCL Tests. https://github.com/NVIDIA/nccl-tests, 2025. [68] NVIDIA. NCCL: Optimized primitives for interGPU communication. https://github. com/NVIDIA/nccl, 2024. [69] NVIDIA. NSight Compute System. https : / / developer . nvidia . com / nsight - compute, 2024. [70] NVIDIA. NVIDIA OpenSHMEM Library. https://github.com/NVIDIA/nvshmem, 2025. [71] NVIDIA. NVTX: NVIDIA Tools Extension SDK. https://github.com/NVIDIA/ NVTX, 2025. [72] NVIDIA. PTX ISA 8.5. https://docs.nvidia.com/cuda/parallel- thread- execution, 2024. [73] NVIDIA. PTXAS. https://docs.nvidia.com/cuda/cuda-compiler-driver- nvcc/, 2024. [74] NVIDIA. TensorRT. https://developer.nvidia.com/tensorrt, 2024. [75] M. Osama, D. Merrill, C. Cecka, M. Garland, and J. D. Owens. “Stream-K: Work- Centric Parallel Decomposition for Dense Matrix-Matrix Multiplication on the GPU”. In: the 28th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming. PPoPP ’23. Montreal, QC, Canada, 2023, pp. 429–431. ISBN: 9798400700156. DOI: 10.1145/3572848.3577479. URL: https://doi.org/ 10.1145/3572848.3577479. [76] M.-M. Papadopoulou, M. Sadooghi-Alvandi, and H. Wong. “Micro-benchmarking the GT200 GPU”. In: Computer Group, ECE, University of Toronto, Tech. Rep (2009). [77] J. H. Park, G. Yun, C. M. Yi, N. T. Nguyen, S. Lee, J. Choi, S. H. Noh, and Y.-r. Choi. “HetPipe: Enabling Large DNN Training on (Whimpy) Heteroge- neous GPU Clusters through Integration of Pipelined Model Parallelism and Data Parallelism”. In: 2020 USENIX Annual Technical Conference. ATC ’20. July 2020, pp. 307–321. ISBN: 978-1-939133-14-4. URL: https://www.usenix.org/ conference/atc20/presentation/park. [78] M. Payer, E. Kravina, and T. R. Gross. “Lightweight Memory Tracing”. In: 2013 USENIX Annual Technical Conference. ATC ’13. San Jose, CA, June 2013, pp. 115– 126. ISBN: 978-1-931971-01-0. URL: https://www.usenix.org/conference/atc13/ technical-sessions/presentation/payer. [79] Y. Peng, Y. Zhu, Y. Chen, Y. Bao, B. Yi, C. Lan, C. Wu, and C. Guo. “A generic communication scheduler for distributed DNN training acceleration”. In: the 27th ACM Symposium on Operating Systems Principles. SOSP ’19. Huntsville, On- tario, Canada, 2019, pp. 16–29. ISBN: 9781450368735. DOI: 10.1145/3341301. 3359642. URL: https://doi.org/10.1145/3341301.3359642. [80] P. von Platen, S. Patil, A. Lozhkov, P. Cuenca, N. Lambert, K. Rasul, M. Davaadorj, D. Nair, S. Paul, W. Berman, Y. Xu, S. Liu, and T. Wolf. Diffusers: State-of-the-art diffusion models. https://github.com/huggingface/diffusers. 2022. [81] T. Preston-Werner and P. Gedam. TOML. https://toml.io/en/, 2024. [82] M. N. Rabe and C. Staats. Self-attention Does Not Need O(n2) Memory. 2022. arXiv: 2112.05682 [cs.LG]. URL: https://arxiv.org/abs/2112.05682. [83] S. Rajbhandari, J. Rasley, O. Ruwase, and Y. He. “ZeRO: memory optimizations toward training trillion parameter models”. In: the International Conference for High Performance Computing, Networking, Storage and Analysis. SC ’20. Atlanta, Georgia: IEEE Press, 2020. ISBN: 9781728199986. [84] [85] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 34 in source list: https://elib.uni-stuttgart.de/server/api/core/bitstreams/d6db3876-262a-464b-bed8-6aaba66d7e7b/content"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=762189350&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">R. Rombach, A. Blattmann, D. Lorenz, P. Esser</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, and <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 34 in source list: https://elib.uni-stuttgart.de/server/api/core/bitstreams/d6db3876-262a-464b-bed8-6aaba66d7e7b/content"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=762189350&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#ce0031" class="#ce0031">B. Ommer. High-Resolution Image Synthesis with Latent Diffusion Models. 2022. arXiv: 2112 . 10752 [cs.CV]. URL: https://arxiv.org/abs/2112.10752</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 103 in source list: V. Petric, A. Bracy, A. Roth. "Three extensions to register integration", 35th Annual IEEE/ACM International Symposium on Microarchitecture, 2002. (MICRO-35). Proceedings., 2002"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/MICRO.2002.1176237', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">A. Roth and G. Sohi</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Register integration: a simple and efficient implementa- tion of squash reuse”. In: the <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 56 in source list: https://www.engineering.pitt.edu/people/faculty/jun-yang/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1105430339&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">33rd Annual IEEE/ACM International Symposium on Microarchitecture. MICRO ’33. 2000, pp</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. 223–234. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 56 in source list: https://www.engineering.pitt.edu/people/faculty/jun-yang/"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=1105430339&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">DOI: 10 . 1109 / MICRO . 2000</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> . 898073. [86] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 32 in source list: https://mediatum.ub.tum.de/doc/1775107/1775107.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=755298283&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">G. Schieffer, D. A. De Medeiros, J. Faj, A. Marathe, and I. Peng</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “On the Rise of AMD Matrix Cores: Performance, Power Efficiency, and Programmability”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 32 in source list: https://mediatum.ub.tum.de/doc/1775107/1775107.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=755298283&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">In: 2024 IEEE International Symposium on Performance Analysis of Systems and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Soft- ware. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 32 in source list: https://mediatum.ub.tum.de/doc/1775107/1775107.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=755298283&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">ISPASS</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> ’24. 2024, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 32 in source list: https://mediatum.ub.tum.de/doc/1775107/1775107.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=755298283&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">pp. 132–143. DOI: 10.1109/ISPASS61541.2024.00022</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [87] J. Seward <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 32 in source list: https://mediatum.ub.tum.de/doc/1775107/1775107.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=72.5844049583863&svr=18&lang=en_us&sid=755298283&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">and N</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 40 in source list: István-Attila Császár, Radu Razvan Slavescu. "Building fast and reliable reverse engineering tools with Frida and Rust", 2022 IEEE 18th International Conference on Intelligent Computer Communication and Processing (ICCP), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/ICCP56966.2022.10053941', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">Nethercote</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Using Valgrind to Detect Undefined Value Errors with Bit-Precision”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 40 in source list: István-Attila Császár, Radu Razvan Slavescu. "Building fast and reliable reverse engineering tools with Frida and Rust", 2022 IEEE 18th International Conference on Intelligent Computer Communication and Processing (ICCP), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/ICCP56966.2022.10053941', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">In: 2005 USENIX Annual Technical Conference. ATC ’05</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Ana- heim, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 40 in source list: István-Attila Császár, Radu Razvan Slavescu. "Building fast and reliable reverse engineering tools with Frida and Rust", 2022 IEEE 18th International Conference on Intelligent Computer Communication and Processing (ICCP), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/ICCP56966.2022.10053941', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">CA, Apr. 2005</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. URL: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 40 in source list: István-Attila Császár, Radu Razvan Slavescu. "Building fast and reliable reverse engineering tools with Frida and Rust", 2022 IEEE 18th International Conference on Intelligent Computer Communication and Processing (ICCP), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/ICCP56966.2022.10053941', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">https://www.usenix.org/conference/2005-usenix- annual- technical- conference/using- valgrind- detect- undefined- value- errors-bit</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [88] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">A. Shah, V. Chidambaram, M. Cowan, S. Maleki, M. Musuvathi, T. Mytkowicz, J. Nelson, O. Saarikivi, and R. Singh</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “TACCL: Guiding Collective Algorithm Synthesis using Communication Sketches”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">In: 20th USENIX Symposium on</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Net- worked <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">Systems Design and Implementation (NSDI 23). Boston, MA: USENIX</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> As- sociation, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 3 in source list: https://arxiv.org/html/2404.06114v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2835115499&n=3807&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">Apr. 2023, pp. 593–612</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 5 in source list: https://arxiv.org/html/2509.10371v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3690798481&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">ISBN: 978-1-939133-33-5. URL: https://www. usenix.org/conference/nsdi23/presentation/shah</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [89] [90] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 2 in source list: http://arxiv.org/pdf/2506.20686"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3608319805&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">J. Shah, G. Bikshandi, Y. Zhang, V. Thakkar, P. Ramani, and T. Dao. FlashAttention- 3: Fast and Accurate Attention with Asynchrony and Low-precision. 2024. arXiv</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 75 in source list: Gwilliam, Matthew. "Understanding and Modeling Explicit and Implicit Representations of the Visual World", University of Maryland, College Park, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31933808&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">2407</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.08608 [<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 75 in source list: Gwilliam, Matthew. "Understanding and Modeling Explicit and Implicit Representations of the Visual World", University of Maryland, College Park, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31933808&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">cs</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.LG]. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 75 in source list: Gwilliam, Matthew. "Understanding and Modeling Explicit and Implicit Representations of the Visual World", University of Maryland, College Park, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31933808&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">URL: https://arxiv.org/abs/2407</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.08608. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 75 in source list: Gwilliam, Matthew. "Understanding and Modeling Explicit and Implicit Representations of the Visual World", University of Maryland, College Park, 2025"><a href="javascript:void(0);" onClick="window.open('https://gateway.proquest.com/openurl?res_dat=xri:pqm&rft_dat=xri:pqdiss:31933808&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&url_ver=Z39.88-2004', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">R</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Sharma, M. Bauer, and A. Aiken. “Verification of producer-consumer syn- chronization in GPU programs”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 46 in source list: Submitted to Vrije Universiteit Brussel on 2024-08-26"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:2990970781&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">In: SIGPLAN Not. 50.6 (June 2015), pp</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. 88–98. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 46 in source list: Submitted to Vrije Universiteit Brussel on 2024-08-26"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:2990970781&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">ISSN: 0362-1340. DOI: 10.1145/2813885</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.2737962. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 46 in source list: Submitted to Vrije Universiteit Brussel on 2024-08-26"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:2990970781&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">URL: https://doi.org/10. 1145/2813885</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.2737962. [91] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 43 in source list: Submitted to University of Colorado, Colorado Springs on 2018-10-14"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:1019459859&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">D. Shen, S. L. Song, A. Li, and X. Liu</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “CUDAAdvisor: LLVM-based runtime profiling for modern GPUs”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 43 in source list: Submitted to University of Colorado, Colorado Springs on 2018-10-14"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:1019459859&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">In: the 2018 International Symposium on Code</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Genera- tion <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 43 in source list: Submitted to University of Colorado, Colorado Springs on 2018-10-14"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:1019459859&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">and Optimization. CGO</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> ’18. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 43 in source list: Submitted to University of Colorado, Colorado Springs on 2018-10-14"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:1019459859&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">Vienna, Austria</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, 2018, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 43 in source list: Submitted to University of Colorado, Colorado Springs on 2018-10-14"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:1019459859&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">pp. 214–227</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. ISBN: 9781450356176. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 11 in source list: https://arxiv.org/pdf/2301.04020.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2223871276&n=3806&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">DOI: 10.1145</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/3168831. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 11 in source list: https://arxiv.org/pdf/2301.04020.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2223871276&n=3806&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">URL: https://doi-org</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.eproxy.<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 11 in source list: https://arxiv.org/pdf/2301.04020.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2223871276&n=3806&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">lib</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.hku.<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 11 in source list: https://arxiv.org/pdf/2301.04020.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2223871276&n=3806&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#006331" class="#006331">hk/10.1145</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/ 3168831. [92] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 52 in source list: https://ar5iv.labs.arxiv.org/html/2407.20018"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=342488084&n=3810&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#795AB9" class="#795AB9">Y. Shi, Z. Yang, J. Xue, L. Ma, Y. Xia, Z. Miao, Y. Guo, F. Yang, and L. Zhou</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Welder: Scheduling Deep Learning Memory Access via Tile-graph”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 27 in source list: https://ses.library.usyd.edu.au/bitstream/handle/2123/33717/Final_Thesis (10).pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3622670581&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">In: 17th USENIX Symposium on Operating Systems Design and Implementation. OSDI ’23. Boston, MA, July 2023, pp</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. 701–718. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 27 in source list: https://ses.library.usyd.edu.au/bitstream/handle/2123/33717/Final_Thesis (10).pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3622670581&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">ISBN: 978-1-939133-34-2. URL: https://www. usenix.org/conference/osdi23/presentation</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/shi. [93] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 6 in source list: https://arxiv.org/html/2408.14158v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2346000248&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">M. Shoeybi, M. Patwary, R. Puri, P. LeGresley, J. Casper, and B. Catanzaro. Megatron-LM: Training Multi-Billion Parameter Language Models Using Model</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Par- allelism. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 6 in source list: https://arxiv.org/html/2408.14158v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2346000248&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">2020. arXiv: 1909.08053 [cs</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.CL]. URL: https://<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 6 in source list: https://arxiv.org/html/2408.14158v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2346000248&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#630000" class="#630000">arxiv.org/abs/1909. 08053</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [94] A. Skaletsky, K. Levit-Gurevich, M. Berezalsky, Y. Kuznetcova, and H. Yakov. “Flexible Binary Instrumentation Framework to Profile Code Running on Intel GPUs”. In: 2022 IEEE International Symposium on Performance Analysis of Systems and Software. ISPASS ’22. 2022, pp. 109–120. DOI: 10.1109/ISPASS55109.2022. 00011. [95] B. Spector, A. Singhal, S. Arora, and C. Re. GPUs Go Brrr. https://hazyresearch. stanford.edu/blog/2024-05-12-tk, 2024. [96] M. Stephenson, S. K. S. Hari, Y. Lee, E. Ebrahimi, D. R. Johnson, D. Nellans, M. O’Connor, and S. W. Keckler. “Flexible software profiling of GPU architectures”. In: 2015 ACM/IEEE 42nd Annual International Symposium on Computer Architec- ture. ISCA ’15. 2015, pp. 185–197. DOI: 10.1145/2749469.2750375. [97] I. Stoica and H. Abdel-Wahab. Earliest Eligible Virtual Deadline First : A Flexible and Accurate Mechanism for Proportional Share Resource Allocation. Tech. rep. USA: Old Dominion University, 1995. [98] J. Street. Diagnosing tricky performance issues easily with intel processor trace. https: //blog.janestreet.com/magic-trace/, 2022. [99] H. Sun and Z. Su. “Validating the eBPF Verifier via State Embedding”. In: 18th USENIX Symposium on Operating Systems Design and Implementation. OSDI ’24. Santa Clara, CA, July 2024, pp. 615–628. ISBN: 978-1-939133-40-3. URL: https: //www.usenix.org/conference/osdi24/presentation/sun-hao. [100] W. Sun, A. Li, T. Geng, S. Stuijk, and H. Corporaal. “Dissecting Tensor Cores via Microbenchmarks: Latency, Throughput and Numeric Behaviors”. In: IEEE Transactions on Parallel and Distributed Systems 34.1 (Jan. 2023), pp. 246–261. ISSN: 2161-9883. DOI: 10.1109/tpds.2022.3217824. URL: http://dx.doi.org/10. 1109/TPDS.2022.3217824. [101] L. Team. LLVM PTX Backend. https://llvm.org/docs/NVPTXUsage.html, 2024. [102] P. Team. PyTorch Profiler. https://pytorch.org/tutorials/recipes/recipes/ profiler_recipe.html, 2024. [103] P. Team. PyTorch Vectorized Elementwise Kernel. https://github.com/pytorch/ pytorch/blob/main/aten/src/ATen/native/cuda/CUDALoops.cuh, 2024. [104] V. Thakkar, P. Ramani, C. Cecka, A. Shivam, H. Lu, E. Yan, J. Kosaian, M. Hoem- men, H. Wu, A. Kerr, M. Nicely, D. Merrill, D. Blasig, F. Qiao, P. Majcher, P. Springer, M. Hohnerbach, J. Wang, and M. Gupta. CUTLASS. Version 3.0.0. Jan. 2023. URL: https://github.com/NVIDIA/cutlass. [105] D. Thaler. BPF Instruction Set Architecture (ISA). https : / / www . rfc - editor . org / info / rfc9669, 2024. DOI: 10 . 17487 / RFC9669. URL: https : / / www . rfc - editor.org/info/rfc9669. [106] P. Tillet, H. T. Kung, and D. Cox. “Triton: an intermediate language and compiler for tiled neural network computations”. In: the 3rd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages. MAPL ’19. Phoenix, AZ, USA, 2019, pp. 10–19. ISBN: 9781450367196. DOI: 10.1145/3315508.3329973. URL: https://doi.org/10.1145/3315508.3329973. [107] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 35 in source list: Renzo Andri, Beatrice Bussolino, Antonio Cipolletta, Lukas Cavigelli, Zhe Wang. "Going Further With Winograd Convolutions: Tap-Wise Quantization for Efficient Inference on 4x4 Tiles", 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/MICRO56248.2022.00048', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">O. Villa, D. Lustig, Z. Yan, E. Bolotin, Y. Fu, N. Chatterjee, N. Jiang, and D</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Nel- lans. “Need for Speed: Experiences Building a Trustworthy System-Level GPU Simulator”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 35 in source list: Renzo Andri, Beatrice Bussolino, Antonio Cipolletta, Lukas Cavigelli, Zhe Wang. "Going Further With Winograd Convolutions: Tap-Wise Quantization for Efficient Inference on 4x4 Tiles", 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/MICRO56248.2022.00048', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">In: 2021 IEEE International Symposium on High-Performance Computer Architecture. HPCA</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> ’21. 2021, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 35 in source list: Renzo Andri, Beatrice Bussolino, Antonio Cipolletta, Lukas Cavigelli, Zhe Wang. "Going Further With Winograd Convolutions: Tap-Wise Quantization for Efficient Inference on 4x4 Tiles", 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/MICRO56248.2022.00048', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#866712" class="#866712">pp. 868–880</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. DOI: 10.1109/HPCA51647.2021.00077. [108] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 45 in source list: Konstantin Levit-Gurevich, Alex Skaletsky, Michael Berezalsky, Yulia Kuznetcova, Hila Yakov. "Profiling Intel Graphics Architecture with Long Instruction Traces", 2022 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/ISPASS55109.2022.00001', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">O. Villa, M. Stephenson, D. Nellans, and S. W. Keckler</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “NVBit: A Dynamic Binary Instrumentation Framework for NVIDIA GPUs”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 45 in source list: Konstantin Levit-Gurevich, Alex Skaletsky, Michael Berezalsky, Yulia Kuznetcova, Hila Yakov. "Profiling Intel Graphics Architecture with Long Instruction Traces", 2022 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), 2022"><a href="javascript:void(0);" onClick="window.open('https://doi.org/10.1109/ISPASS55109.2022.00001', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#B64B01" class="#B64B01">In: the 52nd Annual IEEE/ACM International Symposium on Microarchitecture. MICRO ’52. Columbus, OH</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, USA, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 53 in source list: https://minds.wisconsin.edu/bitstream/handle/1793/80527/DESIGNING EFFICIENT BARRIERS AND SEMAPHORES - Rohan Mahapatra.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1580304049&n=3791&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#935F32" class="#935F32">2019, pp. 372–383. ISBN: 9781450369381. DOI: 10 . 1145 / 3352460 . 3358307. URL: https://doi.org/10.1145/3352460.3358307</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [109] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 63 in source list: https://hal.science/hal-04683563v2/document"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3431334228&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">M. Vuppalapati, S. Agarwal, H. Schuh, B. Kasikci, A. Krishnamurthy, and R. Agarwal</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Understanding the Host Network”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 36 in source list: https://csd.cs.cmu.edu/sites/default/files/phd-thesis/CMU-CS-24-135.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1138150858&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">In: Proceedings of the ACM</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> SIG- COMM <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 36 in source list: https://csd.cs.cmu.edu/sites/default/files/phd-thesis/CMU-CS-24-135.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1138150858&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">2024 Conference. ACM SIGCOMM ’24. Sydney, NSW, Australia</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">: Associ- ation <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 36 in source list: https://csd.cs.cmu.edu/sites/default/files/phd-thesis/CMU-CS-24-135.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1138150858&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">for Computing Machinery, 2024</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, pp. 581–594. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 36 in source list: https://csd.cs.cmu.edu/sites/default/files/phd-thesis/CMU-CS-24-135.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1138150858&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">ISBN: 9798400706141. DOI: 10.1145/3651890</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.3672271. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 36 in source list: https://csd.cs.cmu.edu/sites/default/files/phd-thesis/CMU-CS-24-135.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1138150858&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#63009c" class="#63009c">URL: https://doi.org/10.1145/3651890</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.3672271. [110] S. Williams, A. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 9 in source list: http://arxiv.org/pdf/2505.03531"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1264395019&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">Waterman, and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> D. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 9 in source list: http://arxiv.org/pdf/2505.03531"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1264395019&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">Patterson</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Roofline: an insightful visual per- formance model for multicore architectures”. In: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 9 in source list: http://arxiv.org/pdf/2505.03531"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1264395019&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">Commun. ACM 52.4</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> (Apr. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 9 in source list: http://arxiv.org/pdf/2505.03531"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1264395019&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">2009</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">), pp. 65–76. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 9 in source list: http://arxiv.org/pdf/2505.03531"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1264395019&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#227967" class="#227967">ISSN: 0001-0782. DOI: 10.1145/1498765.1498785. URL: https</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">://<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 1 in source list: https://arxiv.org/html/2509.25853v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=345849368&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">doi. org/10.1145</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">/1498765.1498785. [111] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 1 in source list: https://arxiv.org/html/2509.25853v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=345849368&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf, M. Funtowicz, J. Davison, S. Shleifer, P. von Platen, C. Ma, Y. Jernite, J. Plu, C. Xu, T. L. Scao, S. Gugger, M. Drame, Q. Lhoest, and A. M. Rush</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Trans- formers: State-of-the-Art Natural Language Processing”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 1 in source list: https://arxiv.org/html/2509.25853v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=345849368&n=3814&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#D10A0A" class="#D10A0A">In: the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. On- line, <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 24 in source list: Submitted to University of Hong Kong on 2025-07-27"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:3303207720&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">Oct. 2020, pp. 38–45. URL: https://www.aclweb.org/anthology/2020. emnlp-demos.6</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [112] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 48 in source list: https://dspace.cuni.cz/bitstream/handle/20.500.11956/83719/140052848.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1024265251&n=3722&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">C. S. Wong, I. Tan, R. D. Kumari</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, and <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 48 in source list: https://dspace.cuni.cz/bitstream/handle/20.500.11956/83719/140052848.pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1024265251&n=3722&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">F. Wey</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Towards achieving fairness in the Linux scheduler”. In: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 47 in source list: https://www.microsoft.com/en-us/research/uploads/prod/2021/03/gebara21panama.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1909193462&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">SIGOPS Oper. Syst. Rev. 42.5 (July 2008</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">), pp. 34–43. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 47 in source list: https://www.microsoft.com/en-us/research/uploads/prod/2021/03/gebara21panama.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1909193462&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">ISSN: 0163-5980. DOI: 10.1145/1400097</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.1400102. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 47 in source list: https://www.microsoft.com/en-us/research/uploads/prod/2021/03/gebara21panama.pdf"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=1909193462&n=3800&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">URL: https://doi.org/10.1145/ 1400097</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.1400102. [113] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 2 in source list: http://arxiv.org/pdf/2506.20686"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3608319805&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">Z. Ye, L. Chen, R. Lai, W. Lin, Y. Zhang, S. Wang, T. Chen, B. Kasikci, V. Grover, A. Krishnamurthy, and L. Ceze</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “FlashInfer: Efficient and Customizable At- tention Engine for LLM Inference Serving”. In: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 2 in source list: http://arxiv.org/pdf/2506.20686"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3608319805&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">arXiv preprint arXiv:2501.01005 (2025</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">). URL: <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 2 in source list: http://arxiv.org/pdf/2506.20686"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3608319805&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">https://arxiv.org/abs/2501.01005</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [114] G.-I. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 8 in source list: http://arxiv.org/pdf/2507.06608"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=176790190&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">Yu</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, J. S. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 8 in source list: http://arxiv.org/pdf/2507.06608"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=176790190&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">Jeong</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, G.-W. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 8 in source list: http://arxiv.org/pdf/2507.06608"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=176790190&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">Kim</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">, S. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 8 in source list: http://arxiv.org/pdf/2507.06608"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=176790190&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">Kim, and</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> B.-G. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 8 in source list: http://arxiv.org/pdf/2507.06608"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=176790190&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">Chun</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. “Orca: A Distributed Serving System for Transformer-Based Generative Models”. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 8 in source list: http://arxiv.org/pdf/2507.06608"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=176790190&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">In: 16th USENIX Symposium on Operating Systems Design and Implementation. OSDI</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> ’22. <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 8 in source list: http://arxiv.org/pdf/2507.06608"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=176790190&n=3813&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#330099" class="#330099">Carlsbad, CA, July</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 27 in source list: https://ses.library.usyd.edu.au/bitstream/handle/2123/33717/Final_Thesis (10).pdf?isAllowed=y&sequence=1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=3622670581&n=3811&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">2022, pp. 521–538. ISBN: 978-1-939133-28-1. URL: https://www.usenix. org/conference/osdi22/presentation/yu</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. [115] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 7 in source list: https://arxiv.org/html/2506.05007v1"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2739563819&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#0270B6" class="#0270B6">C. Zhao, L. Zhao, J. Li, and Z. Xu. DeepGEMM: clean and efficient FP8 GEMM kernels with fine-grained scaling. https://github.com/deepseek-ai/DeepGEMM</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. 2025. [116] <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 4 in source list: http://arxiv.org/pdf/2505.24298"><a href="javascript:void(0);" onClick="window.open('newreport_context.asp?r=98.328249764835&svr=18&lang=en_us&sid=2584271281&n=3812&svr=26&session-id=6732f5ab21294b5596b00f04515832f2', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:brown" class="brown">L. Zheng, L. Yin, Z. Xie, C. Sun, J. Huang, C. H. Yu, S. Cao, C. Kozyrakis, I. Stoica, J. E. Gonzalez, C. Barrett, and Y. Sheng. SGLang: Efficient Execution of Structured</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Language Model Programs. 2024. arXiv: 2312.07104 [cs.AI]. URL: https://arxiv. org/abs/2312.07104. [117] Y. Zhou, Z. Chen, Z. Mao, C. Lao, S. Yang, P. G. Kannan, J. Gao, Y. Zhao, Y. Wu, K. You, F. Ren, Z. Xu, C. Raiciu, and I. Stoica. “An Extensible Software Transport Layer for GPU Networking”. In: arXiv preprint arXiv:2504.17307 (2025). <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 22 in source list: Submitted to University of Hong Kong on 2024-04-18"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:2890319192&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">3 5 6 7 8 Chapter 2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Background <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 22 in source list: Submitted to University of Hong Kong on 2024-04-18"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=98.328249764835&svr=18&lang=en_us&oid=oid:1:2890319192&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">9 10 Chapter 2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Background <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 22 in source list: Submitted to University of Hong Kong on 2024-04-18"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2890319192&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">11 12 Chapter 2</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Background <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 22 in source list: Submitted to University of Hong Kong on 2024-04-18"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2890319192&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">13 14</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">HASH(0x560da341d270)<img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 22 in source list: Submitted to University of Hong Kong on 2024-04-18"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2890319192&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 22 in source list: Submitted to University of Hong Kong on 2024-04-18"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2890319192&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">17 18 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 22 in source list: Submitted to University of Hong Kong on 2024-04-18"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2890319192&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">19 20 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 22 in source list: Submitted to University of Hong Kong on 2024-04-18"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2890319192&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#287B28" class="#287B28">21 22</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 23 in source list: Submitted to University of Hong Kong on 2021-06-15"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2068328302&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 23 in source list: Submitted to University of Hong Kong on 2021-06-15"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2068328302&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">23 24 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 23 in source list: Submitted to University of Hong Kong on 2021-06-15"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2068328302&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.4. NEUTRINO Implementation <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 23 in source list: Submitted to University of Hong Kong on 2021-06-15"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2068328302&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">25 26 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 23 in source list: Submitted to University of Hong Kong on 2021-06-15"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2068328302&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.4. NEUTRINO Implementation <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 23 in source list: Submitted to University of Hong Kong on 2021-06-15"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2068328302&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">27 28 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 23 in source list: Submitted to University of Hong Kong on 2021-06-15"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2068328302&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:blue" class="blue">3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">.4. NEUTRINO Implementation <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 39 in source list: Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:2:811286824&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">29 30 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 39 in source list: Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:2:811286824&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">31 32 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 39 in source list: Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:2:811286824&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">33 34 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 39 in source list: Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:2:811286824&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">35 36 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 39 in source list: Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:2:811286824&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">37 38 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 39 in source list: Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:2:811286824&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">39 40 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 39 in source list: Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:2:811286824&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">41 42 Chapter 3</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. Neutrino <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 39 in source list: Submitted to Imperial College of Science, Technology and Medicine   on 2025-06-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:2:811286824&n=2&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#21785B" class="#21785B">43</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 45 46 <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 20 in source list: Submitted to University of Hong Kong on 2025-05-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:3257050767&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">47 48 Chapter 4</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. MECCL <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 20 in source list: Submitted to University of Hong Kong on 2025-05-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:3257050767&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">49 50 Chapter 4</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. MECCL <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 20 in source list: Submitted to University of Hong Kong on 2025-05-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:3257050767&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">51 52 Chapter 4</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. MECCL <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 20 in source list: Submitted to University of Hong Kong on 2025-05-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:3257050767&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">53 54 Chapter 4</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match">. MECCL <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 20 in source list: Submitted to University of Hong Kong on 2025-05-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:3257050767&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">55</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 56 57 <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 20 in source list: Submitted to University of Hong Kong on 2025-05-22"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:3257050767&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">59 60</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> 61 62 63 64 65 66 <img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" height="1" width="1" alt="Begin Match to source 60 in source list: Submitted to Associatie K.U.Leuven on 2021-05-12"><a href="javascript:void(0);" onClick="window.open('/paperInfo.asp?r=47.0925554481951&svr=18&lang=en_us&oid=oid:1:2043662935&n=1&perc=0', 'context', 'location=no,menubar=no,resizable=yes,scrollbars=yes,titlebar=no,toolbar=no,status=no')" style="color:#336699" class="#336699">Bibliography Bibliography 67 68 Bibliography Bibliography 69 70 Bibliography Bibliography 71 72 Bibliography</a><img src="/r/build/images/new_dynamic/df3e567d6f16d040326c7a0ea29a4f41cb_spacer.gif" alt="End Match"> Bibliography 73 </p></div></body></html>
